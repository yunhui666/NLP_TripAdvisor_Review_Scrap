{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yunhui666/NLP_TripAdvisor_Review_Scrap/blob/main/Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abe5512e",
      "metadata": {
        "id": "abe5512e"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4e3ce84",
      "metadata": {
        "id": "d4e3ce84",
        "outputId": "6232be0e-5f82-4124-d6e6-b81485654bad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0    My boyfriend and I spent the night here awhile...\n",
            "1    Myself and my fianc茅e stayed at this hotel ove...\n",
            "2    Had a staycation to just relax for a couple da...\n",
            "3    Our 3rd visit back to New York, this time just...\n",
            "4    My husband and I along with our two children h...\n",
            "Name: reviews_text, dtype: object\n",
            "0    Well from the min we arrived on the eve of tha...\n",
            "1    To be clear, there is no access to any gym con...\n",
            "2    When traveling alone gets scary 馃う馃徑馃槼. I stay...\n",
            "3    I was disappointed at this place to be honest ...\n",
            "4    I stayed at the Sanctuary hotel this past week...\n",
            "Name: reviews_text, dtype: object\n"
          ]
        }
      ],
      "source": [
        "df_H1_pre=pd.read_excel('/Users/siang-linghsu/Downloads/Sanctuary Hotel-.xlsx','Sanctuary_Pre')\n",
        "df_H1_aft=pd.read_excel('/Users/siang-linghsu/Downloads/Sanctuary Hotel-.xlsx','Sanctuary_Post')\n",
        "print(df_H1_pre['reviews_text'].head())\n",
        "\n",
        "df_H1_pre2 = df_H1_pre['reviews_text'].tolist()\n",
        "df_H1_aft2 = df_H1_aft['reviews_text'].tolist()\n",
        "\n",
        "print(df_H1_aft['reviews_text'].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6edd715f",
      "metadata": {
        "id": "6edd715f"
      },
      "outputs": [],
      "source": [
        "#nltk.download('punkt')\n",
        "df_H1_pre3 =[]\n",
        "a_list = []\n",
        "# use nltk sentence tokenize\n",
        "for i in range(len(df_H1_pre2)):\n",
        "    try:\n",
        "        a_list = nltk.tokenize.sent_tokenize(df_H1_pre2[i])\n",
        "        df_H1_pre3.extend(a_list)\n",
        "    except:\n",
        "        print(i)\n",
        "\n",
        "#for grammerly error : let it go\n",
        "# '!We also spent New Years in the haven rooftop bar which was a lovely finish to our holiday',\n",
        "# ' would highly recommend this hotel.',\n",
        "# I would disappear\n",
        "df_H1_pre4 =[]\n",
        "for j in df_H1_pre3:   \n",
        "    df_H1_pre4.extend( re.split( '[\\.][a-zA-Z]+',j))\n",
        "# turn into nested list\n",
        "\n",
        "df_H1_pre5 = []\n",
        "\n",
        "for k in df_H1_pre4:\n",
        "    temp_list = []\n",
        "    temp_list.append(k)\n",
        "    df_H1_pre5.append(temp_list)\n",
        "    \n",
        "#------------------------------------------AFTER-------------------------------------------------    \n",
        "#nltk.download('punkt')\n",
        "df_H1_aft3 =[]\n",
        "a_list = []\n",
        "# use nltk sentence tokenize\n",
        "for i in range(len(df_H1_aft2)):\n",
        "    try:\n",
        "        a_list = nltk.tokenize.sent_tokenize(df_H1_aft2[i])\n",
        "        df_H1_aft3.extend(a_list)\n",
        "    except:\n",
        "        print(i)\n",
        "\n",
        "#for grammerly error : let it go\n",
        "# '!We also spent New Years in the haven rooftop bar which was a lovely finish to our holiday',\n",
        "# ' would highly recommend this hotel.',\n",
        "# I would disappear\n",
        "df_H1_aft4 =[]\n",
        "for j in df_H1_aft3:   \n",
        "    df_H1_aft4.extend( re.split( '[\\.][a-zA-Z]+',j))\n",
        "# turn into nested list\n",
        "\n",
        "df_H1_aft5 = []\n",
        "\n",
        "for k in df_H1_aft4:\n",
        "    temp_list = []\n",
        "    temp_list.append(k)\n",
        "    df_H1_aft5.append(temp_list)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c0659ab",
      "metadata": {
        "id": "8c0659ab"
      },
      "outputs": [],
      "source": [
        "    \n",
        "stopword_list = ['u','ma', 'herself', 'before', 'have', 'about', 'll','from', 'does', 'd', \"should've\"\n",
        "                 , 'should','such', 'i', 'below','ours', 'being', 'with', 't', 'has', 'ain', 'these', 'it',\n",
        "                 'a', 'yourselves', 'now','too', 'through', 'up', 'against', \"you're\", 'can', 'just', 'the',\n",
        "                 \"that'll\", 'so', 'during','only','under', 'had', 'of', 'your', 'yourself', 'myself', 'their',\n",
        "                 'was', 'y', 'why','any','while','himself', 'once', 'until', 'she', 'off', 'all', 'o','this',\n",
        "                 'when', 'been', 'won', 'are', 'then','as','or', 'itself', 'if', 'than', 'above', 'theirs', \n",
        "                 'whom', 'that','for', \"she's\",'an', 'few', 'her','those', 'because', 'further', 'having', \n",
        "                 'ourselves', 'over', 'most', 's', 'between', \"hadn't\", \"weren't\", 'each', 'didn', 'yours',\n",
        "                 'be', 'but', 'to', 'do', \"won't\", 'on', 'his', 'shan', 'own', \"you'd\", 'were', 'them', 'm',\n",
        "                 've', 'by', 'where', 'some','same', 're', 'am', 'hers', 'him', 'there', 'me', 'and', 'who',\n",
        "                 'its', 'down', 'in', 'isn', 'haven', 'other', 'did', 'he', 'after', 'what', 'themselves',\n",
        "                 'both', 'at', \"you've\", 'into', \"you'll\", 'will', 'our', 'they', 'doing',\"it's\", 'my',\n",
        "                 'which', 'how', 'is', 'here', 'don', 'we', 'more', 'very', 'out', 'again', 'you']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c095510",
      "metadata": {
        "id": "1c095510",
        "outputId": "e7f41cc1-228a-43fe-bffc-e0dcc1a75154"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[('boyfriend', 'NN'), ('spent', 'VBD'), ('night', 'NN'), ('awhile', 'NN'), ('ago', 'IN'), ('couldnt', 'NN'), ('happier', 'NN'), ('stay', 'NN')], [('hotel', 'NN'), ('feels', 'NNS'), ('sexy', 'VBP'), ('perfect', 'JJ'), ('little', 'JJ'), ('staycation', 'NN')], [('right', 'RB'), ('next', 'JJ'), ('Times', 'NNP'), ('Square', 'NNP'), ('got', 'VBD'), ('tourist', 'JJ'), ('city', 'NN')], [('rooftop', 'NN'), ('gorgeous', 'JJ')], [('king', 'VBG'), ('suite', 'NN'), ('overlooking', 'VBG'), ('street', 'NN'), ('wall', 'NN'), ('wall', 'NN'), ('windows', 'NNS')]]\n",
            "[[('Well', 'RB'), ('min', 'RB'), ('arrived', 'VBN'), ('eve', 'VBP'), ('thanksgiving', 'VBG'), ('Uk', 'NNP'), ('welcomed', 'VBD'), ('couldn', 'NN'), ('asked', 'VBD')], [('checked', 'VBN'), ('another', 'DT'), ('hotel', 'NN'), ('earlier', 'RBR'), ('wasn', 'JJ'), ('happy', 'JJ'), ('rooms', 'NNS'), ('decided', 'VBD'), ('move', 'NN'), ('sanctuary', 'NN')], [('clean', 'JJ'), ('tidy', 'NN'), ('bed', 'VBD'), ('comfortable', 'JJ'), ('fridge', 'JJ'), ('tv', 'NN'), ('shower', 'NN'), ('good', 'JJ'), ('small', 'JJ'), ('plenty', 'NN'), ('space', 'NN'), ('adults', 'NNS')], [('Breakfast', 'NNP'), ('brought', 'VBD'), ('every', 'DT'), ('morning', 'NN'), ('decided', 'VBD'), ('not', 'RB'), ('take', 'VB'), ('nd', 'JJ'), ('day', 'NN'), ('wanted', 'VBD'), ('experience', 'NN'), ('American', 'JJ'), ('dinners', 'NNS')], [('closed', 'VBD'), ('unfortunately', 'JJ'), ('reservations', 'NNS'), ('rooftop', 'VB'), ('nice', 'JJ'), ('words', 'NNS'), ('reception', 'NN'), ('went', 'VBD'), ('drinks', 'NNS')]]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# hotel1 pre review pre-processing\n",
        "\n",
        "hotel1_pre_review_no_punctuations = []\n",
        "\n",
        "for review in df_H1_pre5:\n",
        "    hotel1_pre_review_no_punctuations.append( re.sub('[^a-zA-Z ]+', '', str(review)))\n",
        "\n",
        "# tokenize\n",
        "#nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "hotel1_review_pre_tokenizing = []\n",
        "for review in hotel1_pre_review_no_punctuations:\n",
        "    hotel1_review_pre_tokenizing.append(word_tokenize(review))\n",
        "\n",
        "# remove stop words\n",
        "\"\"\"\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk_stop_words = stopwords.words('english')\n",
        "\n",
        "hotel1_review_pre_no_stopword = []\n",
        "\n",
        "for review in hotel1_review_pre_tokenizing :\n",
        "    for text in review:\n",
        "        if text.lower() not in nltk_stop_words :\n",
        "            hotel1_review_pre_no_stopword.append(text) \n",
        "\"\"\"\n",
        "\n",
        "\n",
        "hotel1_review_pre_no_stopword = []\n",
        "for review in hotel1_review_pre_tokenizing :\n",
        "    temp_list = []\n",
        "    for text in review:\n",
        "        if text.lower() not in stopword_list :\n",
        "            temp_list.append(text) \n",
        "    hotel1_review_pre_no_stopword.append(temp_list)\n",
        "\n",
        "    \n",
        "# review : \n",
        "#['My', 'boyfriend', 'and', 'I', 'spent', 'the', 'night', 'here', 'awhile', 'ago', \n",
        "#'and', 'we', 'couldnt', 'be', 'happier', 'with', 'our', 'stay']\n",
        "\n",
        "# pos-tagging\n",
        "# ref : https://thinkinfi.com/extract-custom-keywords-using-nltk-pos-tagger-in-python/\n",
        "#from nltk import pos_tag\n",
        "#nltk.download('averaged_perceptron_tagger')\n",
        "hotel1_review_pre_pos= []\n",
        "# sentence :['boyfriend', 'spent', 'night', 'awhile', 'ago', 'couldnt', 'happier', 'stay']\n",
        "for sent_list in hotel1_review_pre_no_stopword:\n",
        "    word_pos=[]\n",
        "    temp_list= [' '.join([str(c) for c in sent_list])]\n",
        "    for sent in temp_list:\n",
        "        try:\n",
        "            word_pos = pos_tag(sent.split(' '))\n",
        "        except:\n",
        "            print('error')\n",
        "    hotel1_review_pre_pos.append(word_pos)\n",
        "\n",
        "print(hotel1_review_pre_pos[0:2])\n",
        "\n",
        "# hotel1 AFT review pre-processing---------------------------------------------------\n",
        "\n",
        "hotel1_aft_review_no_punctuations = []\n",
        "\n",
        "for review in df_H1_aft5:\n",
        "    hotel1_aft_review_no_punctuations.append( re.sub('[^a-zA-Z ]+', '', str(review)))\n",
        "\n",
        "# tokenize\n",
        "\n",
        "hotel1_review_aft_tokenizing = []\n",
        "for review in hotel1_aft_review_no_punctuations:\n",
        "    hotel1_review_aft_tokenizing.append(word_tokenize(review))\n",
        "\n",
        "# remove stop words\n",
        "\n",
        "\n",
        "hotel1_review_aft_no_stopword = []\n",
        "for review in hotel1_review_aft_tokenizing :\n",
        "    temp_list = []\n",
        "    for text in review:\n",
        "        if text.lower() not in stopword_list :\n",
        "            temp_list.append(text) \n",
        "    hotel1_review_aft_no_stopword.append(temp_list)\n",
        "\n",
        "    \n",
        "# review : \n",
        "#['My', 'boyfriend', 'and', 'I', 'spent', 'the', 'night', 'here', 'awhile', 'ago', \n",
        "#'and', 'we', 'couldnt', 'be', 'happier', 'with', 'our', 'stay']\n",
        "\n",
        "# pos-tagging\n",
        "# ref : https://thinkinfi.com/extract-custom-keywords-using-nltk-pos-tagger-in-python/\n",
        "\n",
        "\n",
        "hotel1_review_aft_pos= []\n",
        "# sentence :['boyfriend', 'spent', 'night', 'awhile', 'ago', 'couldnt', 'happier', 'stay']\n",
        "for sent_list in hotel1_review_aft_no_stopword:\n",
        "    word_pos=[]\n",
        "    temp_list= [' '.join([str(c) for c in sent_list])]\n",
        "    for sent in temp_list:\n",
        "        try:\n",
        "            word_pos = pos_tag(sent.split(' '))\n",
        "        except:\n",
        "            print('error')\n",
        "    hotel1_review_aft_pos.append(word_pos)\n",
        "\n",
        "print(hotel1_review_aft_pos[0:2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7eb2f09e",
      "metadata": {
        "id": "7eb2f09e"
      },
      "outputs": [],
      "source": [
        "hotel1_review_pre_pos2 = []\n",
        "for sent_tag in hotel1_review_pre_pos:\n",
        "    temp_list = []\n",
        "    temp_list= [word for word,pos in sent_tag \\\n",
        "            if (pos == 'NN' or pos == 'NNP' or pos == 'NNS' or pos == 'NNPS'or \n",
        "                pos == 'JJ' or pos == 'JJR' or pos == 'JJS' or\n",
        "                pos == 'VB' or pos == 'VBD' or pos == 'VBG' or pos == 'VBN'or pos == 'VBP'or pos == 'VBZ'\n",
        "                or pos == 'ADV')]\n",
        "    hotel1_review_pre_pos2.append(temp_list)\n",
        "    \n",
        "#hotel1_review_pre_pos2    \n",
        "\n",
        "\n",
        "hotel1_review_aft_pos2 = []\n",
        "for sent_tag in hotel1_review_aft_pos:\n",
        "    temp_list = []\n",
        "    temp_list= [word for word,pos in sent_tag \\\n",
        "            if (pos == 'NN' or pos == 'NNP' or pos == 'NNS' or pos == 'NNPS'or \n",
        "                pos == 'JJ' or pos == 'JJR' or pos == 'JJS' or\n",
        "                pos == 'VB' or pos == 'VBD' or pos == 'VBG' or pos == 'VBN'or pos == 'VBP'or pos == 'VBZ'\n",
        "                or pos == 'ADV')]\n",
        "    hotel1_review_aft_pos2.append(temp_list)\n",
        "    \n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0795c5a1",
      "metadata": {
        "id": "0795c5a1"
      },
      "outputs": [],
      "source": [
        "Service_list = ['desk','front','checkin','checkout','reliable','fast','convenient','service']\n",
        "Facility_list = ['rooftop','elevator','floor','bar','spa','wifi','pool','gym','gymnasium','internet','ample','parking','wireless','broken']\n",
        "Room_list = ['bed','bedroom','dirty','clean','toilet','bathroom','shower','dryer','fridge','view','water']\n",
        "Quility_list =['satisfactory','ample','hygienic','proper','ambience','odour','smell','sound','stay']\n",
        "Staff_list = ['good','nice','polite','friendly','helpful','reliable','quick']\n",
        "Surrounding_list = ['restaurant','times','squre','dinner','lunch','market','park','mall','landmark','location']\n",
        "Meal_list= ['breakfast','bar','drink','food','spicy','tasty','buffet','restaurant','dinner','lunch','brunch','delicious']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c081db95",
      "metadata": {
        "id": "c081db95",
        "outputId": "80c53fe8-302e-4f94-f326-e2163a32084f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                            new_senc      Tag  Positive  \\\n",
            "0  Amazing hospitality bellman front desk houseke...  Service     0.388   \n",
            "1                     front desk staff helpful times  Service     0.412   \n",
            "2                                    service helpful  Service     0.737   \n",
            "3  experience friendliness helpfulness front desk...  Service     0.737   \n",
            "4                                checked desk status  Service     0.000   \n",
            "\n",
            "   Negative  Neutral  Compound  \n",
            "0       0.0    0.612    0.5859  \n",
            "1       0.0    0.588    0.4215  \n",
            "2       0.0    0.263    0.4215  \n",
            "3       0.0    0.263    0.9501  \n",
            "4       0.0    1.000    0.0000  \n",
            "             Positive  Negative   Neutral  Compound\n",
            "Tag                                                \n",
            "Facility     0.292687  0.040433  0.666881  0.359185\n",
            "Meal         0.324864  0.046778  0.628352  0.397586\n",
            "Quality      0.318891  0.034143  0.646966  0.385626\n",
            "Room         0.334066  0.040522  0.625410  0.378552\n",
            "Service      0.316732  0.038278  0.644985  0.389953\n",
            "Staff        0.504766  0.022425  0.472807  0.605545\n",
            "Surrounding  0.348154  0.030297  0.621553  0.450944\n",
            "7            0.362132  0.034892  0.602975  0.439593\n",
            "                                            new_senc      Tag  Positive  \\\n",
            "0  strange thing happens call front desk saying s...  Service       0.0   \n",
            "1                    refused provide said front desk  Service       0.0   \n",
            "2                              mins front desk calls  Service       0.0   \n",
            "3                          front desk says thats odd  Service       0.0   \n",
            "4  Maintenance said reported lights room flickeri...  Service       0.0   \n",
            "\n",
            "   Negative  Neutral  Compound  \n",
            "0     0.141    0.859   -0.2023  \n",
            "1     0.355    0.645   -0.2960  \n",
            "2     0.000    1.000    0.0000  \n",
            "3     0.365    0.635   -0.3182  \n",
            "4     0.000    1.000    0.0000  \n",
            "             Positive  Negative   Neutral  Compound\n",
            "Tag                                                \n",
            "Facility     0.231400  0.067633  0.701000  0.271293\n",
            "Meal         0.248182  0.029659  0.722114  0.348491\n",
            "Quality      0.367714  0.045457  0.586829  0.385643\n",
            "Room         0.248679  0.048089  0.703214  0.283246\n",
            "Service      0.144139  0.071222  0.784611  0.122178\n",
            "Staff        0.495460  0.045420  0.459160  0.530414\n",
            "Surrounding  0.383357  0.017321  0.599321  0.497496\n",
            "7            0.305928  0.046373  0.647695  0.350110\n"
          ]
        }
      ],
      "source": [
        "H1_pre_S =[]\n",
        "H1_pre_F =[]\n",
        "H1_pre_R =[]\n",
        "H1_pre_Q =[]\n",
        "H1_pre_Staff =[]\n",
        "H1_pre_Surr =[]\n",
        "H1_pre_M = []\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for senc in hotel1_review_pre_pos2:\n",
        "    i = 0\n",
        "    while i < len(senc):\n",
        "        if senc[i] in Service_list:\n",
        "            if senc not in H1_pre_S:\n",
        "                #print(f'senc[i] in Service_list')\n",
        "                H1_pre_S.append(senc)            \n",
        "        elif senc[i] in Facility_list:\n",
        "            if senc not in H1_pre_F:\n",
        "            #print(f'senc[i] in Facility_list')\n",
        "                H1_pre_F.append(senc)\n",
        "        elif senc[i] in Room_list:\n",
        "            if senc not in H1_pre_R:\n",
        "                #print(f'senc[i] in Room_list')\n",
        "                H1_pre_R.append(senc)\n",
        "        elif senc[i] in Quility_list:\n",
        "            if senc not in H1_pre_Q:\n",
        "            #print(f'senc[i] in Quility_list')\n",
        "                H1_pre_Q.append(senc)\n",
        "        elif senc[i] in Staff_list:\n",
        "            if senc not in H1_pre_Staff:\n",
        "            #print(f'senc[i] in Staff_list')\n",
        "                H1_pre_Staff.append(senc)\n",
        "        elif senc[i] in Surrounding_list:\n",
        "            if senc not in H1_pre_Surr:\n",
        "            #print(f'senc[i] in Surrounding_list')\n",
        "                H1_pre_Surr.append(senc)\n",
        "        elif senc[i] in Meal_list:\n",
        "            if senc not in H1_pre_M:\n",
        "            #print(f'senc[i] in Surrounding_list')\n",
        "                H1_pre_M.append(senc)\n",
        "        i+=1\n",
        "H1_pre_S2 =[' '.join([str(c) for c in lst]) for lst in H1_pre_S]\n",
        "H1_pre_F2 =[' '.join([str(c) for c in lst]) for lst in H1_pre_F]\n",
        "H1_pre_R2 =[' '.join([str(c) for c in lst]) for lst in H1_pre_R]\n",
        "H1_pre_Q2 =[' '.join([str(c) for c in lst]) for lst in H1_pre_Q]\n",
        "H1_pre_Staff2 =[' '.join([str(c) for c in lst]) for lst in H1_pre_Staff]\n",
        "H1_pre_Surr2 =[' '.join([str(c) for c in lst]) for lst in H1_pre_Surr]  \n",
        "H1_pre_M2 = [' '.join([str(c) for c in lst]) for lst in H1_pre_M] \n",
        "H1_pre_S3 = pd.DataFrame(H1_pre_S2, columns = ['new_senc'])\n",
        "H1_pre_F3 = pd.DataFrame(H1_pre_F2, columns = ['new_senc'])\n",
        "H1_pre_R3 = pd.DataFrame(H1_pre_R2, columns = ['new_senc'])\n",
        "H1_pre_Q3 = pd.DataFrame(H1_pre_Q2, columns = ['new_senc'])\n",
        "H1_pre_Staff3 = pd.DataFrame(H1_pre_Staff2, columns = ['new_senc'])\n",
        "H1_pre_Surr3 = pd.DataFrame(H1_pre_Surr2, columns = ['new_senc'])\n",
        "H1_pre_M3 = pd.DataFrame(H1_pre_M2, columns = ['new_senc'])\n",
        "\n",
        "H1_pre_S3['Tag'] = 'Service'\n",
        "H1_pre_F3['Tag'] = 'Facility'\n",
        "H1_pre_R3['Tag'] = 'Room'\n",
        "H1_pre_Q3['Tag'] = 'Quality'\n",
        "H1_pre_Staff3['Tag'] = 'Staff'\n",
        "H1_pre_Surr3['Tag'] = 'Surrounding'\n",
        "H1_pre_M3['Tag'] = 'Meal'\n",
        "\n",
        "H1_pre_review = pd.concat([H1_pre_S3,H1_pre_F3,H1_pre_R3,H1_pre_Q3,H1_pre_Staff3,H1_pre_Surr3,H1_pre_M3])\n",
        "\n",
        "#nltk.downoad('vader_lexicon')\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "sentiments = SentimentIntensityAnalyzer()            \n",
        "H1_pre_review[\"Positive\"] = [sentiments.polarity_scores(i)[\"pos\"] for i in H1_pre_review[\"new_senc\"]]\n",
        "H1_pre_review[\"Negative\"] = [sentiments.polarity_scores(i)[\"neg\"] for i in H1_pre_review[\"new_senc\"]]\n",
        "H1_pre_review[\"Neutral\"] = [sentiments.polarity_scores(i)[\"neu\"] for i in H1_pre_review[\"new_senc\"]]\n",
        "H1_pre_review[\"Compound\"] = [sentiments.polarity_scores(i)[\"compound\"] for i in H1_pre_review[\"new_senc\"]]\n",
        "print(H1_pre_review.head())  \n",
        "\n",
        "H1_pre_score = H1_pre_review.groupby('Tag').mean()\n",
        "H1_pre_score.loc[len(H1_pre_score.index)] = [H1_pre_review.mean(axis = 0)[0],\n",
        "                                             H1_pre_review.mean(axis = 0)[1],\n",
        "                                               H1_pre_review.mean(axis = 0)[2],\n",
        "                                             H1_pre_review.mean(axis = 0)[3]]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(H1_pre_score)\n",
        "\n",
        "#------------------------------------------AFTER--------------------------------------------------------------------\n",
        "\n",
        "\n",
        "\n",
        "H1_aft_S =[]\n",
        "H1_aft_F =[]\n",
        "H1_aft_R =[]\n",
        "H1_aft_Q =[]\n",
        "H1_aft_Staff =[]\n",
        "H1_aft_Surr =[]\n",
        "H1_aft_M = []\n",
        "\n",
        "\n",
        "\n",
        "for senc in hotel1_review_aft_pos2:\n",
        "    i = 0\n",
        "    while i < len(senc):\n",
        "        if senc[i] in Service_list:\n",
        "            if senc not in H1_aft_S:\n",
        "                #print(f'senc[i] in Service_list')\n",
        "                H1_aft_S.append(senc)            \n",
        "        elif senc[i] in Facility_list:\n",
        "            if senc not in H1_aft_F:\n",
        "            #print(f'senc[i] in Facility_list')\n",
        "                H1_aft_F.append(senc)\n",
        "        elif senc[i] in Room_list:\n",
        "            if senc not in H1_aft_R:\n",
        "                #print(f'senc[i] in Room_list')\n",
        "                H1_aft_R.append(senc)\n",
        "        elif senc[i] in Quility_list:\n",
        "            if senc not in H1_aft_Q:\n",
        "            #print(f'senc[i] in Quility_list')\n",
        "                H1_aft_Q.append(senc)\n",
        "        elif senc[i] in Staff_list:\n",
        "            if senc not in H1_aft_Staff:\n",
        "            #print(f'senc[i] in Staff_list')\n",
        "                H1_aft_Staff.append(senc)\n",
        "        elif senc[i] in Surrounding_list:\n",
        "            if senc not in H1_aft_Surr:\n",
        "            #print(f'senc[i] in Surrounding_list')\n",
        "                H1_aft_Surr.append(senc)\n",
        "        elif senc[i] in Meal_list:\n",
        "            if senc not in H1_aft_M:\n",
        "            #print(f'senc[i] in Surrounding_list')\n",
        "                H1_aft_M.append(senc)\n",
        "        i+=1\n",
        "\n",
        "H1_aft_S2 =[' '.join([str(c) for c in lst]) for lst in H1_aft_S]\n",
        "H1_aft_F2 =[' '.join([str(c) for c in lst]) for lst in H1_aft_F]\n",
        "H1_aft_R2 =[' '.join([str(c) for c in lst]) for lst in H1_aft_R]\n",
        "H1_aft_Q2 =[' '.join([str(c) for c in lst]) for lst in H1_aft_Q]\n",
        "H1_aft_Staff2 =[' '.join([str(c) for c in lst]) for lst in H1_aft_Staff]\n",
        "H1_aft_Surr2 =[' '.join([str(c) for c in lst]) for lst in H1_aft_Surr]  \n",
        "H1_aft_M2 = [' '.join([str(c) for c in lst]) for lst in H1_aft_M]  \n",
        "\n",
        "H1_aft_S3 = pd.DataFrame(H1_aft_S2, columns = ['new_senc'])\n",
        "H1_aft_F3 = pd.DataFrame(H1_aft_F2, columns = ['new_senc'])\n",
        "H1_aft_R3 = pd.DataFrame(H1_aft_R2, columns = ['new_senc'])\n",
        "H1_aft_Q3 = pd.DataFrame(H1_aft_Q2, columns = ['new_senc'])\n",
        "H1_aft_Staff3 = pd.DataFrame(H1_aft_Staff2, columns = ['new_senc'])\n",
        "H1_aft_Surr3 = pd.DataFrame(H1_aft_Surr2, columns = ['new_senc'])\n",
        "H1_aft_M3 =  pd.DataFrame(H1_aft_M2, columns = ['new_senc'])\n",
        "\n",
        "H1_aft_S3['Tag'] = 'Service'\n",
        "H1_aft_F3['Tag'] = 'Facility'\n",
        "H1_aft_R3['Tag'] = 'Room'\n",
        "H1_aft_Q3['Tag'] = 'Quality'\n",
        "H1_aft_Staff3['Tag'] = 'Staff'\n",
        "H1_aft_Surr3['Tag'] = 'Surrounding'\n",
        "H1_aft_M3['Tag'] = 'Meal'\n",
        "\n",
        "H1_aft_review = pd.concat([H1_aft_S3,H1_aft_F3,H1_aft_R3,H1_aft_Q3,H1_aft_Staff3,H1_aft_Surr3,H1_aft_M3])\n",
        "\n",
        "#nltk.downoad('vader_lexicon')\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "sentiments = SentimentIntensityAnalyzer()            \n",
        "H1_aft_review[\"Positive\"] = [sentiments.polarity_scores(i)[\"pos\"] for i in H1_aft_review[\"new_senc\"]]\n",
        "H1_aft_review[\"Negative\"] = [sentiments.polarity_scores(i)[\"neg\"] for i in H1_aft_review[\"new_senc\"]]\n",
        "H1_aft_review[\"Neutral\"] = [sentiments.polarity_scores(i)[\"neu\"] for i in H1_aft_review[\"new_senc\"]]\n",
        "H1_aft_review[\"Compound\"] = [sentiments.polarity_scores(i)[\"compound\"] for i in H1_aft_review[\"new_senc\"]]\n",
        "print(H1_aft_review.head())  \n",
        "\n",
        "H1_aft_score = H1_aft_review.groupby('Tag').mean()\n",
        "H1_aft_score.loc[len(H1_aft_score.index)] = [H1_aft_review.mean(axis = 0)[0],\n",
        "                                             H1_aft_review.mean(axis = 0)[1],\n",
        "                                               H1_aft_review.mean(axis = 0)[2],\n",
        "                                            H1_aft_review.mean(axis = 0)[3]]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(H1_aft_score)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e9e8125",
      "metadata": {
        "id": "2e9e8125",
        "outputId": "357699d8-13a8-4fbd-8c91-498d2ed1d373"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}"
            ]
          },
          "execution_count": 375,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sentiments.polarity_scores('checked desk status')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa96bd39",
      "metadata": {
        "id": "aa96bd39",
        "outputId": "b9c0a40e-30c7-4e53-bcb3-88c15e850789"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Positive</th>\n",
              "      <th>Negative</th>\n",
              "      <th>Neutral</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tag</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Facility</th>\n",
              "      <td>0.316663</td>\n",
              "      <td>0.039924</td>\n",
              "      <td>0.643410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Quality</th>\n",
              "      <td>0.318891</td>\n",
              "      <td>0.034143</td>\n",
              "      <td>0.646966</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Room</th>\n",
              "      <td>0.334066</td>\n",
              "      <td>0.040522</td>\n",
              "      <td>0.625410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Service</th>\n",
              "      <td>0.316732</td>\n",
              "      <td>0.038278</td>\n",
              "      <td>0.644985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Staff</th>\n",
              "      <td>0.504766</td>\n",
              "      <td>0.022425</td>\n",
              "      <td>0.472807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Surrounding</th>\n",
              "      <td>0.348154</td>\n",
              "      <td>0.030297</td>\n",
              "      <td>0.621553</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.372404</td>\n",
              "      <td>0.032973</td>\n",
              "      <td>0.594622</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Positive  Negative   Neutral\n",
              "Tag                                      \n",
              "Facility     0.316663  0.039924  0.643410\n",
              "Quality      0.318891  0.034143  0.646966\n",
              "Room         0.334066  0.040522  0.625410\n",
              "Service      0.316732  0.038278  0.644985\n",
              "Staff        0.504766  0.022425  0.472807\n",
              "Surrounding  0.348154  0.030297  0.621553\n",
              "6            0.372404  0.032973  0.594622"
            ]
          },
          "execution_count": 358,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "H1_pre_score "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bcaa9d23",
      "metadata": {
        "id": "bcaa9d23",
        "outputId": "40579f38-a2be-4e7a-d328-dbbe6bbc9ac0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0    My husband and I first stayed at Hotel Edison ...\n",
            "1    First, the location of this hotel is incredibl...\n",
            "2    The hotel location couldn't be any closer to T...\n",
            "3    We stayed here for 3 nights during a Multi-Cit...\n",
            "4    Had a lovely stay here back in December 2017. ...\n",
            "Name: reviews_text, dtype: object\n",
            "0    We stayed at the Edison during our trip to New...\n",
            "1    Thank you to hotel staff Shkurte, Marcos, and ...\n",
            "2    The Hotel Edison was very central right at Tim...\n",
            "3    Recently stayed at the Edison Hotel celebratin...\n",
            "4    The hotel is conveniently located in the cente...\n",
            "Name: reviews_text, dtype: object\n"
          ]
        }
      ],
      "source": [
        "####----Hotel 2--------\n",
        "df_H2_pre=pd.read_excel('/Users/siang-linghsu/Downloads/Edison_Clean.xls','Edison_Pre')\n",
        "df_H2_aft=pd.read_excel('/Users/siang-linghsu/Downloads/Edison_Clean.xls','Edison_Post')\n",
        "print(df_H2_pre['reviews_text'].head())\n",
        "\n",
        "df_H2_pre2 = df_H2_pre['reviews_text'].tolist()\n",
        "df_H2_aft2 = df_H2_aft['reviews_text'].tolist()\n",
        "\n",
        "print(df_H2_aft['reviews_text'].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d2457fb",
      "metadata": {
        "id": "4d2457fb"
      },
      "outputs": [],
      "source": [
        "#nltk.download('punkt')\n",
        "df_H2_pre3 =[]\n",
        "a_list = []\n",
        "# use nltk sentence tokenize\n",
        "for i in range(len(df_H2_pre2)):\n",
        "    try:\n",
        "        a_list = nltk.tokenize.sent_tokenize(df_H2_pre2[i])\n",
        "        df_H2_pre3.extend(a_list)\n",
        "    except:\n",
        "        print(i)\n",
        "\n",
        "#for grammerly error : let it go\n",
        "# '!We also spent New Years in the haven rooftop bar which was a lovely finish to our holiday',\n",
        "# ' would highly recommend this hotel.',\n",
        "# I would disappear\n",
        "df_H2_pre4 =[]\n",
        "for j in df_H2_pre3:   \n",
        "    df_H2_pre4.extend( re.split( '[\\.][a-zA-Z]+',j))\n",
        "# turn into nested list\n",
        "\n",
        "df_H2_pre5 = []\n",
        "\n",
        "for k in df_H2_pre4:\n",
        "    temp_list = []\n",
        "    temp_list.append(k)\n",
        "    df_H2_pre5.append(temp_list)\n",
        "    \n",
        "#------------------------------------------AFTER-------------------------------------------------    \n",
        "#nltk.download('punkt')\n",
        "df_H2_aft3 =[]\n",
        "a_list = []\n",
        "# use nltk sentence tokenize\n",
        "for i in range(len(df_H2_aft2)):\n",
        "    try:\n",
        "        a_list = nltk.tokenize.sent_tokenize(df_H2_aft2[i])\n",
        "        df_H2_aft3.extend(a_list)\n",
        "    except:\n",
        "        print(i)\n",
        "\n",
        "#for grammerly error : let it go\n",
        "# '!We also spent New Years in the haven rooftop bar which was a lovely finish to our holiday',\n",
        "# ' would highly recommend this hotel.',\n",
        "# I would disappear\n",
        "df_H2_aft4 =[]\n",
        "for j in df_H2_aft3:   \n",
        "    df_H2_aft4.extend( re.split( '[\\.][a-zA-Z]+',j))\n",
        "# turn into nested list\n",
        "\n",
        "df_H2_aft5 = []\n",
        "\n",
        "for k in df_H2_aft4:\n",
        "    temp_list = []\n",
        "    temp_list.append(k)\n",
        "    df_H2_aft5.append(temp_list)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35ba2dc6",
      "metadata": {
        "id": "35ba2dc6",
        "outputId": "3cdfc635-58c5-4280-c775-5d94325a7d8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[('husband', 'NN'), ('first', 'RB'), ('stayed', 'VBD'), ('Hotel', 'NNP'), ('Edison', 'NNP'), ('years', 'NNS'), ('ago', 'RB'), ('eloped', 'VBD'), ('NYC', 'NNP')], [('Picture', 'NN'), ('ufff', 'NN')]]\n",
            "[[('stayed', 'VBN'), ('Edison', 'NNP'), ('trip', 'NN'), ('New', 'NNP'), ('York', 'NNP')], [('happy', 'JJ'), ('location', 'NN'), ('minute', 'NN'), ('walk', 'VBP'), ('away', 'RB'), ('times', 'NNS'), ('square', 'JJ'), ('subway', 'JJ'), ('station', 'NN')]]\n"
          ]
        }
      ],
      "source": [
        "# hotel2 pre review pre-processing\n",
        "\n",
        "hotel2_pre_review_no_punctuations = []\n",
        "\n",
        "for review in df_H2_pre5:\n",
        "    hotel2_pre_review_no_punctuations.append( re.sub('[^a-zA-Z ]+', '', str(review)))\n",
        "\n",
        "# tokenize\n",
        "#nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "hotel2_review_pre_tokenizing = []\n",
        "for review in hotel2_pre_review_no_punctuations:\n",
        "    hotel2_review_pre_tokenizing.append(word_tokenize(review))\n",
        "\n",
        "# remove stop words\n",
        "\"\"\"\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk_stop_words = stopwords.words('english')\n",
        "\n",
        "hotel2_review_pre_no_stopword = []\n",
        "\n",
        "for review in hotel2_review_pre_tokenizing :\n",
        "    for text in review:\n",
        "        if text.lower() not in nltk_stop_words :\n",
        "            hotel2_review_pre_no_stopword.append(text) \n",
        "\"\"\"\n",
        "\n",
        "\n",
        "hotel2_review_pre_no_stopword = []\n",
        "for review in hotel2_review_pre_tokenizing :\n",
        "    temp_list = []\n",
        "    for text in review:\n",
        "        if text.lower() not in stopword_list :\n",
        "            temp_list.append(text) \n",
        "    hotel2_review_pre_no_stopword.append(temp_list)\n",
        "\n",
        "    \n",
        "# review : \n",
        "#['My', 'boyfriend', 'and', 'I', 'spent', 'the', 'night', 'here', 'awhile', 'ago', \n",
        "#'and', 'we', 'couldnt', 'be', 'happier', 'with', 'our', 'stay']\n",
        "\n",
        "# pos-tagging\n",
        "# ref : https://thinkinfi.com/extract-custom-keywords-using-nltk-pos-tagger-in-python/\n",
        "#from nltk import pos_tag\n",
        "#nltk.download('averaged_perceptron_tagger')\n",
        "hotel2_review_pre_pos= []\n",
        "# sentence :['boyfriend', 'spent', 'night', 'awhile', 'ago', 'couldnt', 'happier', 'stay']\n",
        "for sent_list in hotel2_review_pre_no_stopword:\n",
        "    word_pos=[]\n",
        "    temp_list= [' '.join([str(c) for c in sent_list])]\n",
        "    for sent in temp_list:\n",
        "        try:\n",
        "            word_pos = pos_tag(sent.split(' '))\n",
        "        except:\n",
        "            print('error')\n",
        "    hotel2_review_pre_pos.append(word_pos)\n",
        "\n",
        "print(hotel2_review_pre_pos[0:2])\n",
        "\n",
        "# hotel2 AFT review pre-processing---------------------------------------------------\n",
        "\n",
        "hotel2_aft_review_no_punctuations = []\n",
        "\n",
        "for review in df_H2_aft5:\n",
        "    hotel2_aft_review_no_punctuations.append( re.sub('[^a-zA-Z ]+', '', str(review)))\n",
        "\n",
        "# tokenize\n",
        "\n",
        "hotel2_review_aft_tokenizing = []\n",
        "for review in hotel2_aft_review_no_punctuations:\n",
        "    hotel2_review_aft_tokenizing.append(word_tokenize(review))\n",
        "\n",
        "# remove stop words\n",
        "\n",
        "\n",
        "hotel2_review_aft_no_stopword = []\n",
        "for review in hotel2_review_aft_tokenizing :\n",
        "    temp_list = []\n",
        "    for text in review:\n",
        "        if text.lower() not in stopword_list :\n",
        "            temp_list.append(text) \n",
        "    hotel2_review_aft_no_stopword.append(temp_list)\n",
        "\n",
        "    \n",
        "# review : \n",
        "#['My', 'boyfriend', 'and', 'I', 'spent', 'the', 'night', 'here', 'awhile', 'ago', \n",
        "#'and', 'we', 'couldnt', 'be', 'happier', 'with', 'our', 'stay']\n",
        "\n",
        "# pos-tagging\n",
        "# ref : https://thinkinfi.com/extract-custom-keywords-using-nltk-pos-tagger-in-python/\n",
        "\n",
        "\n",
        "hotel2_review_aft_pos= []\n",
        "# sentence :['boyfriend', 'spent', 'night', 'awhile', 'ago', 'couldnt', 'happier', 'stay']\n",
        "for sent_list in hotel2_review_aft_no_stopword:\n",
        "    word_pos=[]\n",
        "    temp_list= [' '.join([str(c) for c in sent_list])]\n",
        "    for sent in temp_list:\n",
        "        try:\n",
        "            word_pos = pos_tag(sent.split(' '))\n",
        "        except:\n",
        "            print('error')\n",
        "    hotel2_review_aft_pos.append(word_pos)\n",
        "\n",
        "print(hotel2_review_aft_pos[0:2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20c5764e",
      "metadata": {
        "id": "20c5764e"
      },
      "outputs": [],
      "source": [
        "hotel2_review_pre_pos2 = []\n",
        "for sent_tag in hotel2_review_pre_pos:\n",
        "    temp_list = []\n",
        "    temp_list= [word for word,pos in sent_tag \\\n",
        "            if (pos == 'NN' or pos == 'NNP' or pos == 'NNS' or pos == 'NNPS'or \n",
        "                pos == 'JJ' or pos == 'JJR' or pos == 'JJS' or\n",
        "                pos == 'VB' or pos == 'VBD' or pos == 'VBG' or pos == 'VBN'or pos == 'VBP'or pos == 'VBZ'\n",
        "                or pos == 'ADV')]\n",
        "    hotel2_review_pre_pos2.append(temp_list)\n",
        "    \n",
        "#hotel2_review_pre_pos2    \n",
        "\n",
        "\n",
        "hotel2_review_aft_pos2 = []\n",
        "for sent_tag in hotel2_review_aft_pos:\n",
        "    temp_list = []\n",
        "    temp_list= [word for word,pos in sent_tag \\\n",
        "            if (pos == 'NN' or pos == 'NNP' or pos == 'NNS' or pos == 'NNPS'or \n",
        "                pos == 'JJ' or pos == 'JJR' or pos == 'JJS' or\n",
        "                pos == 'VB' or pos == 'VBD' or pos == 'VBG' or pos == 'VBN'or pos == 'VBP'or pos == 'VBZ'\n",
        "                or pos == 'ADV')]\n",
        "    hotel2_review_aft_pos2.append(temp_list)\n",
        "    \n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d53fe6de",
      "metadata": {
        "id": "d53fe6de",
        "outputId": "5d5a5be0-0081-4bb1-d8c4-513337f625c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                            new_senc      Tag  Positive  \\\n",
            "0  Bottom line want clean safe friendly convenien...  Service     0.529   \n",
            "1  location fantastic Times Square convenient tou...  Service     0.340   \n",
            "2  Experienced good customer service upgraded gre...  Service     0.437   \n",
            "3  checkin process housekeeping restaurants front...  Service     0.000   \n",
            "4  stayed hotel impressed service received staff ...  Service     0.524   \n",
            "\n",
            "   Negative  Neutral  Compound  \n",
            "0       0.0    0.471    0.8442  \n",
            "1       0.0    0.660    0.5574  \n",
            "2       0.0    0.563    0.7351  \n",
            "3       0.0    1.000    0.0000  \n",
            "4       0.0    0.476    0.6705  \n",
            "             Positive  Negative   Neutral  Compound\n",
            "Tag                                                \n",
            "Facility     0.182036  0.062284  0.755680  0.183586\n",
            "Meal         0.332798  0.019864  0.647338  0.448464\n",
            "Quality      0.281179  0.041751  0.677073  0.310387\n",
            "Room         0.319022  0.056708  0.624266  0.316035\n",
            "Service      0.285876  0.044619  0.669524  0.346860\n",
            "Staff        0.512173  0.018305  0.469518  0.602717\n",
            "Surrounding  0.351289  0.029005  0.619708  0.429361\n",
            "7            0.342834  0.038940  0.618228  0.391917\n",
            "                                            new_senc      Tag  Positive  \\\n",
            "0  front desk staff accommodating check process took  Service     0.000   \n",
            "1  booked paid Singapore nights stay hotel insist...  Service     0.000   \n",
            "2  said unpleasant start vacation NYC stay good s...  Service     0.207   \n",
            "3                Requested service heater start fire  Service     0.000   \n",
            "4  informed problems experienced check desk perso...  Service     0.093   \n",
            "\n",
            "   Negative  Neutral  Compound  \n",
            "0     0.000    1.000    0.0000  \n",
            "1     0.000    1.000    0.0000  \n",
            "2     0.221    0.571   -0.0516  \n",
            "3     0.375    0.625   -0.3400  \n",
            "4     0.209    0.698   -0.3612  \n",
            "             Positive  Negative   Neutral  Compound\n",
            "Tag                                                \n",
            "Facility     0.191674  0.061163  0.747128  0.220508\n",
            "Meal         0.348425  0.049657  0.601881  0.389349\n",
            "Quality      0.313804  0.030387  0.655800  0.347350\n",
            "Room         0.383898  0.043480  0.572610  0.418759\n",
            "Service      0.322153  0.050441  0.627390  0.340090\n",
            "Staff        0.517787  0.024503  0.457700  0.583304\n",
            "Surrounding  0.338376  0.034812  0.626812  0.402140\n",
            "7            0.370799  0.038454  0.590734  0.414853\n"
          ]
        }
      ],
      "source": [
        "H2_pre_S =[]\n",
        "H2_pre_F =[]\n",
        "H2_pre_R =[]\n",
        "H2_pre_Q =[]\n",
        "H2_pre_Staff =[]\n",
        "H2_pre_Surr =[]\n",
        "H2_pre_M = []\n",
        "\n",
        "\n",
        "\n",
        "for senc in hotel2_review_pre_pos2:\n",
        "    i = 0\n",
        "    while i < len(senc):\n",
        "        if senc[i] in Service_list:\n",
        "            if senc not in H2_pre_S:\n",
        "                #print(f'senc[i] in Service_list')\n",
        "                H2_pre_S.append(senc)            \n",
        "        elif senc[i] in Facility_list:\n",
        "            if senc not in H2_pre_F:\n",
        "            #print(f'senc[i] in Facility_list')\n",
        "                H2_pre_F.append(senc)\n",
        "        elif senc[i] in Room_list:\n",
        "            if senc not in H2_pre_R:\n",
        "                #print(f'senc[i] in Room_list')\n",
        "                H2_pre_R.append(senc)\n",
        "        elif senc[i] in Quility_list:\n",
        "            if senc not in H2_pre_Q:\n",
        "            #print(f'senc[i] in Quility_list')\n",
        "                H2_pre_Q.append(senc)\n",
        "        elif senc[i] in Staff_list:\n",
        "            if senc not in H2_pre_Staff:\n",
        "            #print(f'senc[i] in Staff_list')\n",
        "                H2_pre_Staff.append(senc)\n",
        "        elif senc[i] in Surrounding_list:\n",
        "            if senc not in H2_pre_Surr:\n",
        "            #print(f'senc[i] in Surrounding_list')\n",
        "                H2_pre_Surr.append(senc)\n",
        "                \n",
        "        elif senc[i] in Meal_list:\n",
        "            if senc not in H2_pre_M:\n",
        "            #print(f'senc[i] in Surrounding_list')\n",
        "                H2_pre_M.append(senc)\n",
        "        i+=1\n",
        "H2_pre_S2 =[' '.join([str(c) for c in lst]) for lst in H2_pre_S]\n",
        "H2_pre_F2 =[' '.join([str(c) for c in lst]) for lst in H2_pre_F]\n",
        "H2_pre_R2 =[' '.join([str(c) for c in lst]) for lst in H2_pre_R]\n",
        "H2_pre_Q2 =[' '.join([str(c) for c in lst]) for lst in H2_pre_Q]\n",
        "H2_pre_Staff2 =[' '.join([str(c) for c in lst]) for lst in H2_pre_Staff]\n",
        "H2_pre_Surr2 =[' '.join([str(c) for c in lst]) for lst in H2_pre_Surr]  \n",
        "H2_pre_M2=[' '.join([str(c) for c in lst]) for lst in H2_pre_M]  \n",
        "H2_pre_S3 = pd.DataFrame(H2_pre_S2, columns = ['new_senc'])\n",
        "H2_pre_F3 = pd.DataFrame(H2_pre_F2, columns = ['new_senc'])\n",
        "H2_pre_R3 = pd.DataFrame(H2_pre_R2, columns = ['new_senc'])\n",
        "H2_pre_Q3 = pd.DataFrame(H2_pre_Q2, columns = ['new_senc'])\n",
        "H2_pre_Staff3 = pd.DataFrame(H2_pre_Staff2, columns = ['new_senc'])\n",
        "H2_pre_Surr3 = pd.DataFrame(H2_pre_Surr2, columns = ['new_senc'])\n",
        "H2_pre_M3= pd.DataFrame(H2_pre_M2, columns = ['new_senc'])\n",
        "\n",
        "H2_pre_S3['Tag'] = 'Service'\n",
        "H2_pre_F3['Tag'] = 'Facility'\n",
        "H2_pre_R3['Tag'] = 'Room'\n",
        "H2_pre_Q3['Tag'] = 'Quality'\n",
        "H2_pre_Staff3['Tag'] = 'Staff'\n",
        "H2_pre_Surr3['Tag'] = 'Surrounding'\n",
        "H2_pre_M3['Tag'] = 'Meal'\n",
        "\n",
        "H2_pre_review = pd.concat([H2_pre_S3,H2_pre_F3,H2_pre_R3,H2_pre_Q3,H2_pre_Staff3,H2_pre_Surr3,H2_pre_M3])\n",
        "\n",
        "#nltk.downoad('vader_lexicon')\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "sentiments = SentimentIntensityAnalyzer()            \n",
        "H2_pre_review[\"Positive\"] = [sentiments.polarity_scores(i)[\"pos\"] for i in H2_pre_review[\"new_senc\"]]\n",
        "H2_pre_review[\"Negative\"] = [sentiments.polarity_scores(i)[\"neg\"] for i in H2_pre_review[\"new_senc\"]]\n",
        "H2_pre_review[\"Neutral\"] = [sentiments.polarity_scores(i)[\"neu\"] for i in H2_pre_review[\"new_senc\"]]\n",
        "H2_pre_review[\"Compound\"] = [sentiments.polarity_scores(i)[\"compound\"] for i in H2_pre_review[\"new_senc\"]]\n",
        "print(H2_pre_review.head())  \n",
        "\n",
        "H2_pre_score = H2_pre_review.groupby('Tag').mean()\n",
        "H2_pre_score.loc[len(H2_pre_score.index)] = [H2_pre_review.mean(axis = 0)[0],\n",
        "                                             H2_pre_review.mean(axis = 0)[1],\n",
        "                                               H2_pre_review.mean(axis = 0)[2],\n",
        "                                             H2_pre_review.mean(axis = 0)[3]]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(H2_pre_score)\n",
        "\n",
        "#------------------------------------------AFTER--------------------------------------------------------------------\n",
        "\n",
        "\n",
        "\n",
        "H2_aft_S =[]\n",
        "H2_aft_F =[]\n",
        "H2_aft_R =[]\n",
        "H2_aft_Q =[]\n",
        "H2_aft_Staff =[]\n",
        "H2_aft_Surr =[]\n",
        "H2_aft_M = []\n",
        "\n",
        "\n",
        "\n",
        "for senc in hotel2_review_aft_pos2:\n",
        "    i = 0\n",
        "    while i < len(senc):\n",
        "        if senc[i] in Service_list:\n",
        "            if senc not in H2_aft_S:\n",
        "                #print(f'senc[i] in Service_list')\n",
        "                H2_aft_S.append(senc)            \n",
        "        elif senc[i] in Facility_list:\n",
        "            if senc not in H2_aft_F:\n",
        "            #print(f'senc[i] in Facility_list')\n",
        "                H2_aft_F.append(senc)\n",
        "        elif senc[i] in Room_list:\n",
        "            if senc not in H2_aft_R:\n",
        "                #print(f'senc[i] in Room_list')\n",
        "                H2_aft_R.append(senc)\n",
        "        elif senc[i] in Quility_list:\n",
        "            if senc not in H2_aft_Q:\n",
        "            #print(f'senc[i] in Quility_list')\n",
        "                H2_aft_Q.append(senc)\n",
        "        elif senc[i] in Staff_list:\n",
        "            if senc not in H2_aft_Staff:\n",
        "            #print(f'senc[i] in Staff_list')\n",
        "                H2_aft_Staff.append(senc)\n",
        "        elif senc[i] in Surrounding_list:\n",
        "            if senc not in H2_aft_Surr:\n",
        "            #print(f'senc[i] in Surrounding_list')\n",
        "                H2_aft_Surr.append(senc)\n",
        "                \n",
        "        elif senc[i] in Meal_list:\n",
        "            if senc not in H2_aft_M:\n",
        "            #print(f'senc[i] in Surrounding_list')\n",
        "                H2_aft_M.append(senc)\n",
        "        i+=1\n",
        "\n",
        "H2_aft_S2 =[' '.join([str(c) for c in lst]) for lst in H2_aft_S]\n",
        "H2_aft_F2 =[' '.join([str(c) for c in lst]) for lst in H2_aft_F]\n",
        "H2_aft_R2 =[' '.join([str(c) for c in lst]) for lst in H2_aft_R]\n",
        "H2_aft_Q2 =[' '.join([str(c) for c in lst]) for lst in H2_aft_Q]\n",
        "H2_aft_Staff2 =[' '.join([str(c) for c in lst]) for lst in H2_aft_Staff]\n",
        "H2_aft_Surr2 =[' '.join([str(c) for c in lst]) for lst in H2_aft_Surr]  \n",
        "H2_aft_M2 =[' '.join([str(c) for c in lst]) for lst in H2_aft_M]  \n",
        "H2_aft_S3 = pd.DataFrame(H2_aft_S2, columns = ['new_senc'])\n",
        "H2_aft_F3 = pd.DataFrame(H2_aft_F2, columns = ['new_senc'])\n",
        "H2_aft_R3 = pd.DataFrame(H2_aft_R2, columns = ['new_senc'])\n",
        "H2_aft_Q3 = pd.DataFrame(H2_aft_Q2, columns = ['new_senc'])\n",
        "H2_aft_Staff3 = pd.DataFrame(H2_aft_Staff2, columns = ['new_senc'])\n",
        "H2_aft_Surr3 = pd.DataFrame(H2_aft_Surr2, columns = ['new_senc'])\n",
        "H2_aft_M3 = pd.DataFrame(H2_aft_M2, columns = ['new_senc'])\n",
        "\n",
        "H2_aft_S3['Tag'] = 'Service'\n",
        "H2_aft_F3['Tag'] = 'Facility'\n",
        "H2_aft_R3['Tag'] = 'Room'\n",
        "H2_aft_Q3['Tag'] = 'Quality'\n",
        "H2_aft_Staff3['Tag'] = 'Staff'\n",
        "H2_aft_Surr3['Tag'] = 'Surrounding'\n",
        "H2_aft_M3['Tag'] = 'Meal'\n",
        "\n",
        "H2_aft_review = pd.concat([H2_aft_S3,H2_aft_F3,H2_aft_R3,H2_aft_Q3,H2_aft_Staff3,H2_aft_Surr3,H2_aft_M3])\n",
        "\n",
        "#nltk.downoad('vader_lexicon')\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "sentiments = SentimentIntensityAnalyzer()            \n",
        "H2_aft_review[\"Positive\"] = [sentiments.polarity_scores(i)[\"pos\"] for i in H2_aft_review[\"new_senc\"]]\n",
        "H2_aft_review[\"Negative\"] = [sentiments.polarity_scores(i)[\"neg\"] for i in H2_aft_review[\"new_senc\"]]\n",
        "H2_aft_review[\"Neutral\"] = [sentiments.polarity_scores(i)[\"neu\"] for i in H2_aft_review[\"new_senc\"]]\n",
        "H2_aft_review[\"Compound\"] = [sentiments.polarity_scores(i)[\"compound\"] for i in H2_aft_review[\"new_senc\"]]\n",
        "print(H2_aft_review.head())  \n",
        "\n",
        "H2_aft_score = H2_aft_review.groupby('Tag').mean()\n",
        "H2_aft_score.loc[len(H2_aft_score.index)] = [H2_aft_review.mean(axis = 0)[0],\n",
        "                                             H2_aft_review.mean(axis = 0)[1],\n",
        "                                               H2_aft_review.mean(axis = 0)[2],\n",
        "                                             H2_aft_review.mean(axis = 0)[3]]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(H2_aft_score)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fd4b3ce",
      "metadata": {
        "id": "3fd4b3ce",
        "outputId": "f14564a5-3369-4b98-db9d-556f36100c12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0    Great location. Nearby food was inexpensive an...\n",
            "1    Thank you to all the staff for making me feel ...\n",
            "2    This is a great hotel and reasonably priced. Y...\n",
            "3    This hotel was in a perfect location with easy...\n",
            "4    This hotel is close to almost everything a tra...\n",
            "Name: reviews_text, dtype: object\n",
            "0    I stayed here for a week while visiting New Yo...\n",
            "1    Had a great stay, staff were polite and the ro...\n",
            "2    Doubletree staff was amazing .Any questions fi...\n",
            "3    We stayed for 5 nights in this hotel. We were ...\n",
            "4    For our 4th visit to NYC we decided to try a D...\n",
            "Name: reviews_text, dtype: object\n"
          ]
        }
      ],
      "source": [
        "####----Hotel 3--------\n",
        "df_H3_pre=pd.read_excel('/Users/siang-linghsu/Downloads/Double_Clean.xlsm',' Hilton_Pre')\n",
        "df_H3_aft=pd.read_excel('/Users/siang-linghsu/Downloads/Double_Clean.xlsm',' Hilton_Post')\n",
        "\n",
        "print(df_H3_pre['reviews_text'].head())\n",
        "\n",
        "df_H3_pre2 = df_H3_pre['reviews_text'].tolist()\n",
        "df_H3_aft2 = df_H3_aft['reviews_text'].tolist()\n",
        "\n",
        "print(df_H3_aft['reviews_text'].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62bbe77a",
      "metadata": {
        "id": "62bbe77a"
      },
      "outputs": [],
      "source": [
        "#nltk.download('punkt')\n",
        "df_H3_pre3 =[]\n",
        "a_list = []\n",
        "# use nltk sentence tokenize\n",
        "for i in range(len(df_H3_pre2)):\n",
        "    try:\n",
        "        a_list = nltk.tokenize.sent_tokenize(df_H3_pre2[i])\n",
        "        df_H3_pre3.extend(a_list)\n",
        "    except:\n",
        "        print(f'pre- Covid : {i}')\n",
        "\n",
        "#for grammerly error : let it go\n",
        "# '!We also spent New Years in the haven rooftop bar which was a lovely finish to our holiday',\n",
        "# ' would highly recommend this hotel.',\n",
        "# I would disappear\n",
        "df_H3_pre4 =[]\n",
        "for j in df_H3_pre3:   \n",
        "    df_H3_pre4.extend( re.split( '[\\.][a-zA-Z]+',j))\n",
        "# turn into nested list\n",
        "\n",
        "df_H3_pre5 = []\n",
        "\n",
        "for k in df_H3_pre4:\n",
        "    temp_list = []\n",
        "    temp_list.append(k)\n",
        "    df_H3_pre5.append(temp_list)\n",
        "    \n",
        "#------------------------------------------AFTER-------------------------------------------------    \n",
        "#nltk.download('punkt')\n",
        "df_H3_aft3 =[]\n",
        "a_list = []\n",
        "# use nltk sentence tokenize\n",
        "for i in range(len(df_H3_aft2)):\n",
        "    try:\n",
        "        a_list = nltk.tokenize.sent_tokenize(df_H3_aft2[i])\n",
        "        df_H3_aft3.extend(a_list)\n",
        "    except:\n",
        "        print(i)\n",
        "\n",
        "#for grammerly error : let it go\n",
        "# '!We also spent New Years in the haven rooftop bar which was a lovely finish to our holiday',\n",
        "# ' would highly recommend this hotel.',\n",
        "# I would disappear\n",
        "df_H3_aft4 =[]\n",
        "for j in df_H3_aft3:   \n",
        "    df_H3_aft4.extend( re.split( '[\\.][a-zA-Z]+',j))\n",
        "# turn into nested list\n",
        "\n",
        "df_H3_aft5 = []\n",
        "\n",
        "for k in df_H3_aft4:\n",
        "    temp_list = []\n",
        "    temp_list.append(k)\n",
        "    df_H3_aft5.append(temp_list)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23cb53b8",
      "metadata": {
        "id": "23cb53b8",
        "outputId": "c5c6a7ca-5feb-48d6-b14e-51d2b94874e9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"The hotel itself was great. The rooms are small but it is in downtown New York. The my did make great use of the space in the rooms. It is in a sketchy area of the street though. I wouldn't walk outside after dark without my husband\""
            ]
          },
          "execution_count": 300,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80ad1a6d",
      "metadata": {
        "id": "80ad1a6d",
        "outputId": "35313182-2ae8-4d0f-f9b3-79fe47e95bbb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[('Great', 'NNP'), ('location', 'NN')], [('Nearby', 'RB'), ('food', 'NN'), ('inexpensive', 'JJ'), ('tasty', 'NN')]]\n",
            "[[('stayed', 'VBN'), ('week', 'NN'), ('visiting', 'VBG'), ('New', 'NNP'), ('York', 'NNP'), ('City', 'NNP'), ('hotel', 'NN'), ('typical', 'JJ'), ('Hilton', 'NNP'), ('Double', 'NNP'), ('Tree', 'NNP'), ('rooftop', 'VB'), ('bar', 'NN'), ('turns', 'NNS'), ('nightclub', 'RB'), ('later', 'RB'), ('night', 'NN')], [('Residents', 'NNS'), ('get', 'VBP'), ('free', 'JJ'), ('entry', 'NN'), ('nightclub', 'NN'), ('night', 'NN')]]\n"
          ]
        }
      ],
      "source": [
        "# hotel3 pre review pre-processing\n",
        "\n",
        "hotel3_pre_review_no_punctuations = []\n",
        "\n",
        "for review in df_H3_pre5:\n",
        "    hotel3_pre_review_no_punctuations.append( re.sub('[^a-zA-Z ]+', '', str(review)))\n",
        "\n",
        "# tokenize\n",
        "#nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "hotel3_review_pre_tokenizing = []\n",
        "for review in hotel3_pre_review_no_punctuations:\n",
        "    hotel3_review_pre_tokenizing.append(word_tokenize(review))\n",
        "\n",
        "# remove stop words\n",
        "\"\"\"\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk_stop_words = stopwords.words('english')\n",
        "\n",
        "hotel3_review_pre_no_stopword = []\n",
        "\n",
        "for review in hotel3_review_pre_tokenizing :\n",
        "    for text in review:\n",
        "        if text.lower() not in nltk_stop_words :\n",
        "            hotel3_review_pre_no_stopword.append(text) \n",
        "\"\"\"\n",
        "\n",
        "\n",
        "hotel3_review_pre_no_stopword = []\n",
        "for review in hotel3_review_pre_tokenizing :\n",
        "    temp_list = []\n",
        "    for text in review:\n",
        "        if text.lower() not in stopword_list :\n",
        "            temp_list.append(text) \n",
        "    hotel3_review_pre_no_stopword.append(temp_list)\n",
        "\n",
        "    \n",
        "# review : \n",
        "#['My', 'boyfriend', 'and', 'I', 'spent', 'the', 'night', 'here', 'awhile', 'ago', \n",
        "#'and', 'we', 'couldnt', 'be', 'happier', 'with', 'our', 'stay']\n",
        "\n",
        "# pos-tagging\n",
        "# ref : https://thinkinfi.com/extract-custom-keywords-using-nltk-pos-tagger-in-python/\n",
        "#from nltk import pos_tag\n",
        "#nltk.download('averaged_perceptron_tagger')\n",
        "hotel3_review_pre_pos= []\n",
        "# sentence :['boyfriend', 'spent', 'night', 'awhile', 'ago', 'couldnt', 'happier', 'stay']\n",
        "for sent_list in hotel3_review_pre_no_stopword:\n",
        "    word_pos=[]\n",
        "    temp_list= [' '.join([str(c) for c in sent_list])]\n",
        "    for sent in temp_list:\n",
        "        try:\n",
        "            word_pos = pos_tag(sent.split(' '))\n",
        "        except:\n",
        "            print('error')\n",
        "    hotel3_review_pre_pos.append(word_pos)\n",
        "\n",
        "print(hotel3_review_pre_pos[0:2])\n",
        "\n",
        "# hotel3 AFT review pre-processing---------------------------------------------------\n",
        "\n",
        "hotel3_aft_review_no_punctuations = []\n",
        "\n",
        "for review in df_H3_aft5:\n",
        "    hotel3_aft_review_no_punctuations.append( re.sub('[^a-zA-Z ]+', '', str(review)))\n",
        "\n",
        "# tokenize\n",
        "\n",
        "hotel3_review_aft_tokenizing = []\n",
        "for review in hotel3_aft_review_no_punctuations:\n",
        "    hotel3_review_aft_tokenizing.append(word_tokenize(review))\n",
        "\n",
        "# remove stop words\n",
        "\n",
        "\n",
        "hotel3_review_aft_no_stopword = []\n",
        "for review in hotel3_review_aft_tokenizing :\n",
        "    temp_list = []\n",
        "    for text in review:\n",
        "        if text.lower() not in stopword_list :\n",
        "            temp_list.append(text) \n",
        "    hotel3_review_aft_no_stopword.append(temp_list)\n",
        "\n",
        "    \n",
        "# review : \n",
        "#['My', 'boyfriend', 'and', 'I', 'spent', 'the', 'night', 'here', 'awhile', 'ago', \n",
        "#'and', 'we', 'couldnt', 'be', 'happier', 'with', 'our', 'stay']\n",
        "\n",
        "# pos-tagging\n",
        "# ref : https://thinkinfi.com/extract-custom-keywords-using-nltk-pos-tagger-in-python/\n",
        "\n",
        "\n",
        "hotel3_review_aft_pos= []\n",
        "# sentence :['boyfriend', 'spent', 'night', 'awhile', 'ago', 'couldnt', 'happier', 'stay']\n",
        "for sent_list in hotel3_review_aft_no_stopword:\n",
        "    word_pos=[]\n",
        "    temp_list= [' '.join([str(c) for c in sent_list])]\n",
        "    for sent in temp_list:\n",
        "        try:\n",
        "            word_pos = pos_tag(sent.split(' '))\n",
        "        except:\n",
        "            print('error')\n",
        "    hotel3_review_aft_pos.append(word_pos)\n",
        "\n",
        "print(hotel3_review_aft_pos[0:2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f018512",
      "metadata": {
        "id": "6f018512"
      },
      "outputs": [],
      "source": [
        "hotel3_review_pre_pos2 = []\n",
        "for sent_tag in hotel3_review_pre_pos:\n",
        "    temp_list = []\n",
        "    temp_list= [word for word,pos in sent_tag \\\n",
        "            if (pos == 'NN' or pos == 'NNP' or pos == 'NNS' or pos == 'NNPS'or \n",
        "                pos == 'JJ' or pos == 'JJR' or pos == 'JJS' or\n",
        "                pos == 'VB' or pos == 'VBD' or pos == 'VBG' or pos == 'VBN'or pos == 'VBP'or pos == 'VBZ'\n",
        "                or pos == 'ADV')]\n",
        "    hotel3_review_pre_pos2.append(temp_list)\n",
        "    \n",
        "#hotel3_review_pre_pos2    \n",
        "\n",
        "\n",
        "hotel3_review_aft_pos2 = []\n",
        "for sent_tag in hotel3_review_aft_pos:\n",
        "    temp_list = []\n",
        "    temp_list= [word for word,pos in sent_tag \\\n",
        "            if (pos == 'NN' or pos == 'NNP' or pos == 'NNS' or pos == 'NNPS'or \n",
        "                pos == 'JJ' or pos == 'JJR' or pos == 'JJS' or\n",
        "                pos == 'VB' or pos == 'VBD' or pos == 'VBG' or pos == 'VBN'or pos == 'VBP'or pos == 'VBZ'\n",
        "                or pos == 'ADV')]\n",
        "    hotel3_review_aft_pos2.append(temp_list)\n",
        "    \n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5d461da",
      "metadata": {
        "id": "a5d461da",
        "outputId": "fafd7997-efc8-4925-d707-f16b68b0c14c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                            new_senc      Tag  Positive  \\\n",
            "0  supposed stay nights service amazing time exte...  Service     0.352   \n",
            "1  stayed nights January th wedding anniversary h...  Service     0.000   \n",
            "2                used concierge service room service  Service     0.000   \n",
            "3  tarnished view hotel good customer service rec...  Service     0.177   \n",
            "4                      Budget time elevators checkin  Service     0.000   \n",
            "\n",
            "   Negative  Neutral  Compound  \n",
            "0     0.000    0.648    0.5859  \n",
            "1     0.000    1.000    0.0000  \n",
            "2     0.000    1.000    0.0000  \n",
            "3     0.213    0.610   -0.1531  \n",
            "4     0.000    1.000    0.0000  \n",
            "             Positive  Negative   Neutral  Compound\n",
            "Tag                                                \n",
            "Facility     0.183754  0.074971  0.741275  0.153846\n",
            "Meal         0.291990  0.041844  0.666170  0.353052\n",
            "Quality      0.255531  0.065533  0.678934  0.238316\n",
            "Room         0.308437  0.048837  0.642731  0.317985\n",
            "Service      0.211788  0.060989  0.727226  0.208205\n",
            "Staff        0.483869  0.026607  0.489524  0.556062\n",
            "Surrounding  0.294650  0.045563  0.659791  0.341604\n",
            "7            0.298430  0.051736  0.649836  0.316648\n",
            "                                            new_senc      Tag  Positive  \\\n",
            "0  shower cubicle door hinge broken arrival first...  Service     0.000   \n",
            "1                          reported front desk check  Service     0.000   \n",
            "2      didnt problem lifts didnt queue checkin lucky  Service     0.235   \n",
            "3             Front desk management control property  Service     0.000   \n",
            "4                      house keeping service perfect  Service     0.552   \n",
            "\n",
            "   Negative  Neutral  Compound  \n",
            "0     0.220    0.780   -0.4767  \n",
            "1     0.000    1.000    0.0000  \n",
            "2     0.243    0.521   -0.0191  \n",
            "3     0.000    1.000    0.0000  \n",
            "4     0.000    0.448    0.5719  \n",
            "             Positive  Negative   Neutral  Compound\n",
            "Tag                                                \n",
            "Facility     0.142751  0.094398  0.762843  0.050441\n",
            "Meal         0.284712  0.092404  0.622885  0.226773\n",
            "Quality      0.192233  0.110944  0.696822  0.103374\n",
            "Room         0.258768  0.094371  0.646861  0.179267\n",
            "Service      0.163163  0.073859  0.762987  0.091107\n",
            "Staff        0.477240  0.039097  0.483679  0.507420\n",
            "Surrounding  0.271307  0.047646  0.681069  0.278157\n",
            "7            0.246457  0.079224  0.674324  0.192116\n"
          ]
        }
      ],
      "source": [
        "H3_pre_S =[]\n",
        "H3_pre_F =[]\n",
        "H3_pre_R =[]\n",
        "H3_pre_Q =[]\n",
        "H3_pre_Staff =[]\n",
        "H3_pre_Surr =[]\n",
        "H3_pre_M = []\n",
        "\n",
        "\n",
        "\n",
        "for senc in hotel3_review_pre_pos2:\n",
        "    i = 0\n",
        "    while i < len(senc):\n",
        "        if senc[i] in Service_list:\n",
        "            if senc not in H3_pre_S:\n",
        "                #print(f'senc[i] in Service_list')\n",
        "                H3_pre_S.append(senc)            \n",
        "        elif senc[i] in Facility_list:\n",
        "            if senc not in H3_pre_F:\n",
        "            #print(f'senc[i] in Facility_list')\n",
        "                H3_pre_F.append(senc)\n",
        "        elif senc[i] in Room_list:\n",
        "            if senc not in H3_pre_R:\n",
        "                #print(f'senc[i] in Room_list')\n",
        "                H3_pre_R.append(senc)\n",
        "        elif senc[i] in Quility_list:\n",
        "            if senc not in H3_pre_Q:\n",
        "            #print(f'senc[i] in Quility_list')\n",
        "                H3_pre_Q.append(senc)\n",
        "        elif senc[i] in Staff_list:\n",
        "            if senc not in H3_pre_Staff:\n",
        "            #print(f'senc[i] in Staff_list')\n",
        "                H3_pre_Staff.append(senc)\n",
        "        elif senc[i] in Surrounding_list:\n",
        "            if senc not in H3_pre_Surr:\n",
        "            #print(f'senc[i] in Surrounding_list')\n",
        "                H3_pre_Surr.append(senc)\n",
        "                \n",
        "        elif senc[i] in Meal_list:\n",
        "            if senc not in H3_pre_M:\n",
        "            #print(f'senc[i] in Surrounding_list')\n",
        "                H3_pre_M.append(senc)\n",
        "        i+=1\n",
        "H3_pre_S2 =[' '.join([str(c) for c in lst]) for lst in H3_pre_S]\n",
        "H3_pre_F2 =[' '.join([str(c) for c in lst]) for lst in H3_pre_F]\n",
        "H3_pre_R2 =[' '.join([str(c) for c in lst]) for lst in H3_pre_R]\n",
        "H3_pre_Q2 =[' '.join([str(c) for c in lst]) for lst in H3_pre_Q]\n",
        "H3_pre_Staff2 =[' '.join([str(c) for c in lst]) for lst in H3_pre_Staff]\n",
        "H3_pre_Surr2 =[' '.join([str(c) for c in lst]) for lst in H3_pre_Surr]  \n",
        "H3_pre_M2  =[' '.join([str(c) for c in lst]) for lst in H3_pre_M]  \n",
        "H3_pre_S3 = pd.DataFrame(H3_pre_S2, columns = ['new_senc'])\n",
        "H3_pre_F3 = pd.DataFrame(H3_pre_F2, columns = ['new_senc'])\n",
        "H3_pre_R3 = pd.DataFrame(H3_pre_R2, columns = ['new_senc'])\n",
        "H3_pre_Q3 = pd.DataFrame(H3_pre_Q2, columns = ['new_senc'])\n",
        "H3_pre_Staff3 = pd.DataFrame(H3_pre_Staff2, columns = ['new_senc'])\n",
        "H3_pre_Surr3 = pd.DataFrame(H3_pre_Surr2, columns = ['new_senc'])\n",
        "H3_pre_M3= pd.DataFrame(H3_pre_M2, columns = ['new_senc'])\n",
        "\n",
        "H3_pre_S3['Tag'] = 'Service'\n",
        "H3_pre_F3['Tag'] = 'Facility'\n",
        "H3_pre_R3['Tag'] = 'Room'\n",
        "H3_pre_Q3['Tag'] = 'Quality'\n",
        "H3_pre_Staff3['Tag'] = 'Staff'\n",
        "H3_pre_Surr3['Tag'] = 'Surrounding'\n",
        "H3_pre_M3['Tag'] = 'Meal'\n",
        "\n",
        "H3_pre_review = pd.concat([H3_pre_S3,H3_pre_F3,H3_pre_R3,H3_pre_Q3,H3_pre_Staff3,H3_pre_Surr3,H3_pre_M3])\n",
        "\n",
        "#nltk.downoad('vader_lexicon')\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "sentiments = SentimentIntensityAnalyzer()            \n",
        "H3_pre_review[\"Positive\"] = [sentiments.polarity_scores(i)[\"pos\"] for i in H3_pre_review[\"new_senc\"]]\n",
        "H3_pre_review[\"Negative\"] = [sentiments.polarity_scores(i)[\"neg\"] for i in H3_pre_review[\"new_senc\"]]\n",
        "H3_pre_review[\"Neutral\"] = [sentiments.polarity_scores(i)[\"neu\"] for i in H3_pre_review[\"new_senc\"]]\n",
        "H3_pre_review[\"Compound\"] = [sentiments.polarity_scores(i)[\"compound\"] for i in H3_pre_review[\"new_senc\"]]\n",
        "print(H3_pre_review.head())  \n",
        "\n",
        "H3_pre_score = H3_pre_review.groupby('Tag').mean()\n",
        "H3_pre_score.loc[len(H3_pre_score.index)] = [H3_pre_review.mean(axis = 0)[0],\n",
        "                                             H3_pre_review.mean(axis = 0)[1],\n",
        "                                               H3_pre_review.mean(axis = 0)[2],\n",
        "                                            H3_pre_review.mean(axis = 0)[3]]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(H3_pre_score)\n",
        "\n",
        "#------------------------------------------AFTER--------------------------------------------------------------------\n",
        "\n",
        "\n",
        "\n",
        "H3_aft_S =[]\n",
        "H3_aft_F =[]\n",
        "H3_aft_R =[]\n",
        "H3_aft_Q =[]\n",
        "H3_aft_Staff =[]\n",
        "H3_aft_Surr =[]\n",
        "H3_aft_M = []\n",
        "\n",
        "\n",
        "\n",
        "for senc in hotel3_review_aft_pos2:\n",
        "    i = 0\n",
        "    while i < len(senc):\n",
        "        if senc[i] in Service_list:\n",
        "            if senc not in H3_aft_S:\n",
        "                #print(f'senc[i] in Service_list')\n",
        "                H3_aft_S.append(senc)            \n",
        "        elif senc[i] in Facility_list:\n",
        "            if senc not in H3_aft_F:\n",
        "            #print(f'senc[i] in Facility_list')\n",
        "                H3_aft_F.append(senc)\n",
        "        elif senc[i] in Room_list:\n",
        "            if senc not in H3_aft_R:\n",
        "                #print(f'senc[i] in Room_list')\n",
        "                H3_aft_R.append(senc)\n",
        "        elif senc[i] in Quility_list:\n",
        "            if senc not in H3_aft_Q:\n",
        "            #print(f'senc[i] in Quility_list')\n",
        "                H3_aft_Q.append(senc)\n",
        "        elif senc[i] in Staff_list:\n",
        "            if senc not in H3_aft_Staff:\n",
        "            #print(f'senc[i] in Staff_list')\n",
        "                H3_aft_Staff.append(senc)\n",
        "        elif senc[i] in Surrounding_list:\n",
        "            if senc not in H3_aft_Surr:\n",
        "            #print(f'senc[i] in Surrounding_list')\n",
        "                H3_aft_Surr.append(senc)\n",
        "                \n",
        "        elif senc[i] in Meal_list:\n",
        "            if senc not in H3_aft_M:\n",
        "            #print(f'senc[i] in Surrounding_list')\n",
        "                H3_aft_M.append(senc)\n",
        "        i+=1\n",
        "\n",
        "H3_aft_S2 =[' '.join([str(c) for c in lst]) for lst in H3_aft_S]\n",
        "H3_aft_F2 =[' '.join([str(c) for c in lst]) for lst in H3_aft_F]\n",
        "H3_aft_R2 =[' '.join([str(c) for c in lst]) for lst in H3_aft_R]\n",
        "H3_aft_Q2 =[' '.join([str(c) for c in lst]) for lst in H3_aft_Q]\n",
        "H3_aft_Staff2 =[' '.join([str(c) for c in lst]) for lst in H3_aft_Staff]\n",
        "H3_aft_Surr2 =[' '.join([str(c) for c in lst]) for lst in H3_aft_Surr]  \n",
        "H3_aft_M2 =[' '.join([str(c) for c in lst]) for lst in H3_aft_M]   \n",
        "H3_aft_S3 = pd.DataFrame(H3_aft_S2, columns = ['new_senc'])\n",
        "H3_aft_F3 = pd.DataFrame(H3_aft_F2, columns = ['new_senc'])\n",
        "H3_aft_R3 = pd.DataFrame(H3_aft_R2, columns = ['new_senc'])\n",
        "H3_aft_Q3 = pd.DataFrame(H3_aft_Q2, columns = ['new_senc'])\n",
        "H3_aft_Staff3 = pd.DataFrame(H3_aft_Staff2, columns = ['new_senc'])\n",
        "H3_aft_Surr3 = pd.DataFrame(H3_aft_Surr2, columns = ['new_senc'])\n",
        "H3_aft_M3 = pd.DataFrame(H3_aft_M2, columns = ['new_senc'])\n",
        "\n",
        "H3_aft_S3['Tag'] = 'Service'\n",
        "H3_aft_F3['Tag'] = 'Facility'\n",
        "H3_aft_R3['Tag'] = 'Room'\n",
        "H3_aft_Q3['Tag'] = 'Quality'\n",
        "H3_aft_Staff3['Tag'] = 'Staff'\n",
        "H3_aft_Surr3['Tag'] = 'Surrounding'\n",
        "H3_aft_M3['Tag'] = 'Meal'\n",
        "\n",
        "H3_aft_review = pd.concat([H3_aft_S3,H3_aft_F3,H3_aft_R3,H3_aft_Q3,H3_aft_Staff3,H3_aft_Surr3,H3_aft_M3])\n",
        "\n",
        "#nltk.downoad('vader_lexicon')\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "sentiments = SentimentIntensityAnalyzer()            \n",
        "H3_aft_review[\"Positive\"] = [sentiments.polarity_scores(i)[\"pos\"] for i in H3_aft_review[\"new_senc\"]]\n",
        "H3_aft_review[\"Negative\"] = [sentiments.polarity_scores(i)[\"neg\"] for i in H3_aft_review[\"new_senc\"]]\n",
        "H3_aft_review[\"Neutral\"] = [sentiments.polarity_scores(i)[\"neu\"] for i in H3_aft_review[\"new_senc\"]]\n",
        "H3_aft_review[\"Compound\"] = [sentiments.polarity_scores(i)[\"compound\"] for i in H3_aft_review[\"new_senc\"]]\n",
        "print(H3_aft_review.head())  \n",
        "\n",
        "H3_aft_score = H3_aft_review.groupby('Tag').mean()\n",
        "H3_aft_score.loc[len(H3_aft_score.index)] = [H3_aft_review.mean(axis = 0)[0],\n",
        "                                             H3_aft_review.mean(axis = 0)[1],\n",
        "                                               H3_aft_review.mean(axis = 0)[2],\n",
        "                                            H3_aft_review.mean(axis = 0)[3]]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(H3_aft_score)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51a02576",
      "metadata": {
        "id": "51a02576",
        "outputId": "0bc1bea0-b0cc-4786-831a-bec033cb2dd1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0    The location of this hotel is the ONLY good th...\n",
            "1    This hotel was very nice and accommodating. Th...\n",
            "2    I wanted my family to fly in for a few days, a...\n",
            "3    Lovely hotel with some of the best service we ...\n",
            "4    My boyfriend and I stayed here at Christmas ti...\n",
            "Name: reviews_text, dtype: object\n",
            "0    i reserved a room with my wife for our honeymo...\n",
            "1    We stayed here from 30th December until 4th Ja...\n",
            "2    Perfect Location- Not sure you can get ANY bet...\n",
            "3    I was worried about the state of the rooms aft...\n",
            "4    Hotel is in a good location if you want Midtow...\n",
            "Name: reviews_text, dtype: object\n"
          ]
        }
      ],
      "source": [
        "####----Hotel 4--------\n",
        "df_H4_pre=pd.read_excel('/Users/siang-linghsu/Downloads/Millennium_Clean.xlsm','Millennium_Pre')\n",
        "df_H4_aft=pd.read_excel('/Users/siang-linghsu/Downloads/Millennium_Clean.xlsm','Millennium_Post')\n",
        "\n",
        "print(df_H4_pre['reviews_text'].head())\n",
        "\n",
        "df_H4_pre2 = df_H4_pre['reviews_text'].tolist()\n",
        "df_H4_aft2 = df_H4_aft['reviews_text'].tolist()\n",
        "\n",
        "print(df_H4_aft['reviews_text'].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "072ba92b",
      "metadata": {
        "id": "072ba92b"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "#nltk.download('punkt')\n",
        "df_H4_pre3 =[]\n",
        "a_list = []\n",
        "# use nltk sentence tokenize\n",
        "for i in range(len(df_H4_pre2)):\n",
        "    try:\n",
        "        a_list = nltk.tokenize.sent_tokenize(df_H4_pre2[i])\n",
        "        df_H4_pre3.extend(a_list)\n",
        "    except:\n",
        "        print(i)\n",
        "\n",
        "#for grammerly error : let it go\n",
        "# '!We also spent New Years in the haven rooftop bar which was a lovely finish to our holiday',\n",
        "# ' would highly recommend this hotel.',\n",
        "# I would disappear\n",
        "df_H4_pre4 =[]\n",
        "for j in df_H4_pre3:   \n",
        "    df_H4_pre4.extend( re.split( '[\\.][a-zA-Z]+',j))\n",
        "# turn into nested list\n",
        "\n",
        "df_H4_pre5 = []\n",
        "\n",
        "for k in df_H4_pre4:\n",
        "    temp_list = []\n",
        "    temp_list.append(k)\n",
        "    df_H4_pre5.append(temp_list)\n",
        "    \n",
        "#------------------------------------------AFTER-------------------------------------------------    \n",
        "#nltk.download('punkt')\n",
        "df_H4_aft3 =[]\n",
        "a_list = []\n",
        "# use nltk sentence tokenize\n",
        "for i in range(len(df_H4_aft2)):\n",
        "    try:\n",
        "        a_list = nltk.tokenize.sent_tokenize(df_H4_aft2[i])\n",
        "        df_H4_aft3.extend(a_list)\n",
        "    except:\n",
        "        print(i)\n",
        "\n",
        "#for grammerly error : let it go\n",
        "# '!We also spent New Years in the haven rooftop bar which was a lovely finish to our holiday',\n",
        "# ' would highly recommend this hotel.',\n",
        "# I would disappear\n",
        "df_H4_aft4 =[]\n",
        "for j in df_H4_aft3:   \n",
        "    df_H4_aft4.extend( re.split( '[\\.][a-zA-Z]+',j))\n",
        "# turn into nested list\n",
        "\n",
        "df_H4_aft5 = []\n",
        "\n",
        "for k in df_H4_aft4:\n",
        "    temp_list = []\n",
        "    temp_list.append(k)\n",
        "    df_H4_aft5.append(temp_list)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "016d58da",
      "metadata": {
        "id": "016d58da",
        "outputId": "9d6c5036-81c5-492c-d684-5618dc7e821d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[('location', 'NN'), ('hotel', 'NN'), ('good', 'JJ'), ('thing', 'NN')], [('would', 'MD'), ('not', 'RB'), ('say', 'VB'), ('star', 'JJ'), ('hotel', 'NN'), ('stayed', 'VBD'), ('many', 'JJ'), ('star', 'NN'), ('motels', 'NNS'), ('throughout', 'IN'), ('trip', 'NN'), ('cleaner', 'NN')]]\n",
            "[[('reserved', 'VBN'), ('room', 'NN'), ('wife', 'NN'), ('honeymoon', 'NN')], [('However', 'RB'), ('arrived', 'VBN'), ('hotel', 'NN'), ('told', 'VBD'), ('us', 'PRP'), ('cant', 'JJ'), ('stay', 'NN'), ('bcs', 'RB'), ('booked', 'VBD'), ('different', 'JJ'), ('date', 'NN'), ('mistake', 'NN')]]\n"
          ]
        }
      ],
      "source": [
        "# hotel4 pre review pre-processing\n",
        "\n",
        "hotel4_pre_review_no_punctuations = []\n",
        "\n",
        "for review in df_H4_pre5:\n",
        "    hotel4_pre_review_no_punctuations.append( re.sub('[^a-zA-Z ]+', '', str(review)))\n",
        "\n",
        "# tokenize\n",
        "#nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "hotel4_review_pre_tokenizing = []\n",
        "for review in hotel4_pre_review_no_punctuations:\n",
        "    hotel4_review_pre_tokenizing.append(word_tokenize(review))\n",
        "\n",
        "# remove stop words\n",
        "\"\"\"\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk_stop_words = stopwords.words('english')\n",
        "\n",
        "hotel4_review_pre_no_stopword = []\n",
        "\n",
        "for review in hotel4_review_pre_tokenizing :\n",
        "    for text in review:\n",
        "        if text.lower() not in nltk_stop_words :\n",
        "            hotel4_review_pre_no_stopword.append(text) \n",
        "\"\"\"\n",
        "\n",
        "\n",
        "hotel4_review_pre_no_stopword = []\n",
        "for review in hotel4_review_pre_tokenizing :\n",
        "    temp_list = []\n",
        "    for text in review:\n",
        "        if text.lower() not in stopword_list :\n",
        "            temp_list.append(text) \n",
        "    hotel4_review_pre_no_stopword.append(temp_list)\n",
        "\n",
        "    \n",
        "# review : \n",
        "#['My', 'boyfriend', 'and', 'I', 'spent', 'the', 'night', 'here', 'awhile', 'ago', \n",
        "#'and', 'we', 'couldnt', 'be', 'happier', 'with', 'our', 'stay']\n",
        "\n",
        "# pos-tagging\n",
        "# ref : https://thinkinfi.com/extract-custom-keywords-using-nltk-pos-tagger-in-python/\n",
        "#from nltk import pos_tag\n",
        "#nltk.download('averaged_perceptron_tagger')\n",
        "hotel4_review_pre_pos= []\n",
        "# sentence :['boyfriend', 'spent', 'night', 'awhile', 'ago', 'couldnt', 'happier', 'stay']\n",
        "for sent_list in hotel4_review_pre_no_stopword:\n",
        "    word_pos=[]\n",
        "    temp_list= [' '.join([str(c) for c in sent_list])]\n",
        "    for sent in temp_list:\n",
        "        try:\n",
        "            word_pos = pos_tag(sent.split(' '))\n",
        "        except:\n",
        "            print('error')\n",
        "    hotel4_review_pre_pos.append(word_pos)\n",
        "\n",
        "print(hotel4_review_pre_pos[0:2])\n",
        "\n",
        "# hotel4 AFT review pre-processing---------------------------------------------------\n",
        "\n",
        "hotel4_aft_review_no_punctuations = []\n",
        "\n",
        "for review in df_H4_aft5:\n",
        "    hotel4_aft_review_no_punctuations.append( re.sub('[^a-zA-Z ]+', '', str(review)))\n",
        "\n",
        "# tokenize\n",
        "\n",
        "hotel4_review_aft_tokenizing = []\n",
        "for review in hotel4_aft_review_no_punctuations:\n",
        "    hotel4_review_aft_tokenizing.append(word_tokenize(review))\n",
        "\n",
        "# remove stop words\n",
        "\n",
        "\n",
        "hotel4_review_aft_no_stopword = []\n",
        "for review in hotel4_review_aft_tokenizing :\n",
        "    temp_list = []\n",
        "    for text in review:\n",
        "        if text.lower() not in stopword_list :\n",
        "            temp_list.append(text) \n",
        "    hotel4_review_aft_no_stopword.append(temp_list)\n",
        "\n",
        "    \n",
        "# review : \n",
        "#['My', 'boyfriend', 'and', 'I', 'spent', 'the', 'night', 'here', 'awhile', 'ago', \n",
        "#'and', 'we', 'couldnt', 'be', 'happier', 'with', 'our', 'stay']\n",
        "\n",
        "# pos-tagging\n",
        "# ref : https://thinkinfi.com/extract-custom-keywords-using-nltk-pos-tagger-in-python/\n",
        "\n",
        "\n",
        "hotel4_review_aft_pos= []\n",
        "# sentence :['boyfriend', 'spent', 'night', 'awhile', 'ago', 'couldnt', 'happier', 'stay']\n",
        "for sent_list in hotel4_review_aft_no_stopword:\n",
        "    word_pos=[]\n",
        "    temp_list= [' '.join([str(c) for c in sent_list])]\n",
        "    for sent in temp_list:\n",
        "        try:\n",
        "            word_pos = pos_tag(sent.split(' '))\n",
        "        except:\n",
        "            print('error')\n",
        "    hotel4_review_aft_pos.append(word_pos)\n",
        "\n",
        "print(hotel4_review_aft_pos[0:2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da819604",
      "metadata": {
        "id": "da819604"
      },
      "outputs": [],
      "source": [
        "hotel4_review_pre_pos2 = []\n",
        "for sent_tag in hotel4_review_pre_pos:\n",
        "    temp_list = []\n",
        "    temp_list= [word for word,pos in sent_tag \\\n",
        "            if (pos == 'NN' or pos == 'NNP' or pos == 'NNS' or pos == 'NNPS'or \n",
        "                pos == 'JJ' or pos == 'JJR' or pos == 'JJS' or\n",
        "                pos == 'VB' or pos == 'VBD' or pos == 'VBG' or pos == 'VBN'or pos == 'VBP'or pos == 'VBZ'\n",
        "                or pos == 'ADV')]\n",
        "    hotel4_review_pre_pos2.append(temp_list)\n",
        "    \n",
        "#hotel4_review_pre_pos2    \n",
        "\n",
        "\n",
        "hotel4_review_aft_pos2 = []\n",
        "for sent_tag in hotel4_review_aft_pos:\n",
        "    temp_list = []\n",
        "    temp_list= [word for word,pos in sent_tag \\\n",
        "            if (pos == 'NN' or pos == 'NNP' or pos == 'NNS' or pos == 'NNPS'or \n",
        "                pos == 'JJ' or pos == 'JJR' or pos == 'JJS' or\n",
        "                pos == 'VB' or pos == 'VBD' or pos == 'VBG' or pos == 'VBN'or pos == 'VBP'or pos == 'VBZ'\n",
        "                or pos == 'ADV')]\n",
        "    hotel4_review_aft_pos2.append(temp_list)\n",
        "    \n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6ea066c",
      "metadata": {
        "id": "c6ea066c",
        "outputId": "9cce2816-d57a-4251-d6ee-5cdcf879d255"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                            new_senc      Tag  Positive  \\\n",
            "0  service staff nice helpful rooms appointed com...  Service     0.690   \n",
            "1                                 hotel best service  Service     0.677   \n",
            "2                  upgrade fee good customer service  Service     0.420   \n",
            "3         Room service great staff welcoming helpful  Service     0.766   \n",
            "4  Good hotel heart Broadway midrange price conve...  Service     0.266   \n",
            "\n",
            "   Negative  Neutral  Compound  \n",
            "0       0.0    0.310    0.8360  \n",
            "1       0.0    0.323    0.6369  \n",
            "2       0.0    0.580    0.4404  \n",
            "3       0.0    0.234    0.8689  \n",
            "4       0.0    0.734    0.4404  \n",
            "             Positive  Negative   Neutral  Compound\n",
            "Tag                                                \n",
            "Facility     0.163047  0.073149  0.763809  0.154876\n",
            "Meal         0.231942  0.054440  0.713638  0.259422\n",
            "Quality      0.255037  0.056119  0.688857  0.252497\n",
            "Room         0.258442  0.084668  0.656886  0.219082\n",
            "Service      0.202689  0.079608  0.717702  0.170320\n",
            "Staff        0.477918  0.031858  0.490236  0.538496\n",
            "Surrounding  0.319114  0.044734  0.636153  0.363757\n",
            "7            0.290256  0.061646  0.648101  0.295199\n",
            "                                            new_senc      Tag  Positive  \\\n",
            "0  room service mini fridge room tea coffee makin...  Service      0.00   \n",
            "1                       Doorman concierge front desk  Service      0.00   \n",
            "2  Starbucks next door use entrance great get mor...  Service      0.24   \n",
            "3                    gentleman desk called confirmed  Service      0.00   \n",
            "4  hotel hold suitcases delay checkout flight nee...  Service      0.00   \n",
            "\n",
            "   Negative  Neutral  Compound  \n",
            "0     0.000    1.000    0.0000  \n",
            "1     0.000    1.000    0.0000  \n",
            "2     0.000    0.760    0.6249  \n",
            "3     0.000    1.000    0.0000  \n",
            "4     0.204    0.796   -0.3182  \n",
            "             Positive  Negative   Neutral  Compound\n",
            "Tag                                                \n",
            "Facility     0.150925  0.116134  0.732925  0.048807\n",
            "Meal         0.164452  0.044677  0.790871  0.188026\n",
            "Quality      0.239526  0.059344  0.701143  0.248425\n",
            "Room         0.213881  0.130325  0.655778  0.115753\n",
            "Service      0.216683  0.078385  0.704923  0.187054\n",
            "Staff        0.497994  0.028052  0.473959  0.560519\n",
            "Surrounding  0.321127  0.032764  0.646109  0.385802\n",
            "7            0.265904  0.079278  0.654813  0.243063\n"
          ]
        }
      ],
      "source": [
        "H4_pre_S =[]\n",
        "H4_pre_F =[]\n",
        "H4_pre_R =[]\n",
        "H4_pre_Q =[]\n",
        "H4_pre_Staff =[]\n",
        "H4_pre_Surr =[]\n",
        "H4_pre_M = []\n",
        "\n",
        "\n",
        "\n",
        "for senc in hotel4_review_pre_pos2:\n",
        "    i = 0\n",
        "    while i < len(senc):\n",
        "        if senc[i] in Service_list:\n",
        "            if senc not in H4_pre_S:\n",
        "                #print(f'senc[i] in Service_list')\n",
        "                H4_pre_S.append(senc)            \n",
        "        elif senc[i] in Facility_list:\n",
        "            if senc not in H4_pre_F:\n",
        "            #print(f'senc[i] in Facility_list')\n",
        "                H4_pre_F.append(senc)\n",
        "        elif senc[i] in Room_list:\n",
        "            if senc not in H4_pre_R:\n",
        "                #print(f'senc[i] in Room_list')\n",
        "                H4_pre_R.append(senc)\n",
        "        elif senc[i] in Quility_list:\n",
        "            if senc not in H4_pre_Q:\n",
        "            #print(f'senc[i] in Quility_list')\n",
        "                H4_pre_Q.append(senc)\n",
        "        elif senc[i] in Staff_list:\n",
        "            if senc not in H4_pre_Staff:\n",
        "            #print(f'senc[i] in Staff_list')\n",
        "                H4_pre_Staff.append(senc)\n",
        "        elif senc[i] in Surrounding_list:\n",
        "            if senc not in H4_pre_Surr:\n",
        "            #print(f'senc[i] in Surrounding_list')\n",
        "                H4_pre_Surr.append(senc)\n",
        "                \n",
        "        elif senc[i] in Meal_list:\n",
        "            if senc not in H4_pre_M:\n",
        "            #print(f'senc[i] in Surrounding_list')\n",
        "                H4_pre_M.append(senc)\n",
        "        i+=1\n",
        "H4_pre_S2 =[' '.join([str(c) for c in lst]) for lst in H4_pre_S]\n",
        "H4_pre_F2 =[' '.join([str(c) for c in lst]) for lst in H4_pre_F]\n",
        "H4_pre_R2 =[' '.join([str(c) for c in lst]) for lst in H4_pre_R]\n",
        "H4_pre_Q2 =[' '.join([str(c) for c in lst]) for lst in H4_pre_Q]\n",
        "H4_pre_Staff2 =[' '.join([str(c) for c in lst]) for lst in H4_pre_Staff]\n",
        "H4_pre_Surr2 =[' '.join([str(c) for c in lst]) for lst in H4_pre_Surr]  \n",
        "H4_pre_M2 = [' '.join([str(c) for c in lst]) for lst in H4_pre_M] \n",
        "H4_pre_S3 = pd.DataFrame(H4_pre_S2, columns = ['new_senc'])\n",
        "H4_pre_F3 = pd.DataFrame(H4_pre_F2, columns = ['new_senc'])\n",
        "H4_pre_R3 = pd.DataFrame(H4_pre_R2, columns = ['new_senc'])\n",
        "H4_pre_Q3 = pd.DataFrame(H4_pre_Q2, columns = ['new_senc'])\n",
        "H4_pre_Staff3 = pd.DataFrame(H4_pre_Staff2, columns = ['new_senc'])\n",
        "H4_pre_Surr3 = pd.DataFrame(H4_pre_Surr2, columns = ['new_senc'])\n",
        "H4_pre_M3 = pd.DataFrame(H4_pre_M2, columns = ['new_senc']) \n",
        "\n",
        "H4_pre_S3['Tag'] = 'Service'\n",
        "H4_pre_F3['Tag'] = 'Facility'\n",
        "H4_pre_R3['Tag'] = 'Room'\n",
        "H4_pre_Q3['Tag'] = 'Quality'\n",
        "H4_pre_Staff3['Tag'] = 'Staff'\n",
        "H4_pre_Surr3['Tag'] = 'Surrounding'\n",
        "H4_pre_M3['Tag'] = 'Meal'\n",
        "\n",
        "H4_pre_review = pd.concat([H4_pre_S3,H4_pre_F3,H4_pre_R3,H4_pre_Q3,H4_pre_Staff3,H4_pre_Surr3,H4_pre_M3])\n",
        "\n",
        "#nltk.downoad('vader_lexicon')\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "sentiments = SentimentIntensityAnalyzer()            \n",
        "H4_pre_review[\"Positive\"] = [sentiments.polarity_scores(i)[\"pos\"] for i in H4_pre_review[\"new_senc\"]]\n",
        "H4_pre_review[\"Negative\"] = [sentiments.polarity_scores(i)[\"neg\"] for i in H4_pre_review[\"new_senc\"]]\n",
        "H4_pre_review[\"Neutral\"] = [sentiments.polarity_scores(i)[\"neu\"] for i in H4_pre_review[\"new_senc\"]]\n",
        "H4_pre_review[\"Compound\"] = [sentiments.polarity_scores(i)[\"compound\"] for i in H4_pre_review[\"new_senc\"]]\n",
        "print(H4_pre_review.head())  \n",
        "\n",
        "H4_pre_score = H4_pre_review.groupby('Tag').mean()\n",
        "H4_pre_score.loc[len(H4_pre_score.index)] = [H4_pre_review.mean(axis = 0)[0],\n",
        "                                             H4_pre_review.mean(axis = 0)[1],\n",
        "                                               H4_pre_review.mean(axis = 0)[2],\n",
        "                                             H4_pre_review.mean(axis = 0)[3]]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(H4_pre_score)\n",
        "\n",
        "#------------------------------------------AFTER--------------------------------------------------------------------\n",
        "\n",
        "\n",
        "\n",
        "H4_aft_S =[]\n",
        "H4_aft_F =[]\n",
        "H4_aft_R =[]\n",
        "H4_aft_Q =[]\n",
        "H4_aft_Staff =[]\n",
        "H4_aft_Surr =[]\n",
        "H4_aft_M = []\n",
        "\n",
        "\n",
        "\n",
        "for senc in hotel4_review_aft_pos2:\n",
        "    i = 0\n",
        "    while i < len(senc):\n",
        "        if senc[i] in Service_list:\n",
        "            if senc not in H4_aft_S:\n",
        "                #print(f'senc[i] in Service_list')\n",
        "                H4_aft_S.append(senc)            \n",
        "        elif senc[i] in Facility_list:\n",
        "            if senc not in H4_aft_F:\n",
        "            #print(f'senc[i] in Facility_list')\n",
        "                H4_aft_F.append(senc)\n",
        "        elif senc[i] in Room_list:\n",
        "            if senc not in H4_aft_R:\n",
        "                #print(f'senc[i] in Room_list')\n",
        "                H4_aft_R.append(senc)\n",
        "        elif senc[i] in Quility_list:\n",
        "            if senc not in H4_aft_Q:\n",
        "            #print(f'senc[i] in Quility_list')\n",
        "                H4_aft_Q.append(senc)\n",
        "        elif senc[i] in Staff_list:\n",
        "            if senc not in H4_aft_Staff:\n",
        "            #print(f'senc[i] in Staff_list')\n",
        "                H4_aft_Staff.append(senc)\n",
        "        elif senc[i] in Surrounding_list:\n",
        "            if senc not in H4_aft_Surr:\n",
        "            #print(f'senc[i] in Surrounding_list')\n",
        "                H4_aft_Surr.append(senc)\n",
        "                \n",
        "        elif senc[i] in Meal_list:\n",
        "            if senc not in H4_aft_M:\n",
        "            #print(f'senc[i] in Surrounding_list')\n",
        "                H4_aft_M.append(senc)\n",
        "        i+=1\n",
        "\n",
        "H4_aft_S2 =[' '.join([str(c) for c in lst]) for lst in H4_aft_S]\n",
        "H4_aft_F2 =[' '.join([str(c) for c in lst]) for lst in H4_aft_F]\n",
        "H4_aft_R2 =[' '.join([str(c) for c in lst]) for lst in H4_aft_R]\n",
        "H4_aft_Q2 =[' '.join([str(c) for c in lst]) for lst in H4_aft_Q]\n",
        "H4_aft_Staff2 =[' '.join([str(c) for c in lst]) for lst in H4_aft_Staff]\n",
        "H4_aft_Surr2 =[' '.join([str(c) for c in lst]) for lst in H4_aft_Surr]  \n",
        "H4_aft_M2  =[' '.join([str(c) for c in lst]) for lst in H4_aft_M] \n",
        "H4_aft_S3 = pd.DataFrame(H4_aft_S2, columns = ['new_senc'])\n",
        "H4_aft_F3 = pd.DataFrame(H4_aft_F2, columns = ['new_senc'])\n",
        "H4_aft_R3 = pd.DataFrame(H4_aft_R2, columns = ['new_senc'])\n",
        "H4_aft_Q3 = pd.DataFrame(H4_aft_Q2, columns = ['new_senc'])\n",
        "H4_aft_Staff3 = pd.DataFrame(H4_aft_Staff2, columns = ['new_senc'])\n",
        "H4_aft_Surr3 = pd.DataFrame(H4_aft_Surr2, columns = ['new_senc'])\n",
        "H4_aft_M3= pd.DataFrame(H4_aft_M2, columns = ['new_senc'])\n",
        "\n",
        "H4_aft_S3['Tag'] = 'Service'\n",
        "H4_aft_F3['Tag'] = 'Facility'\n",
        "H4_aft_R3['Tag'] = 'Room'\n",
        "H4_aft_Q3['Tag'] = 'Quality'\n",
        "H4_aft_Staff3['Tag'] = 'Staff'\n",
        "H4_aft_Surr3['Tag'] = 'Surrounding'\n",
        "H4_aft_M3['Tag'] = 'Meal'\n",
        "\n",
        "H4_aft_review = pd.concat([H4_aft_S3,H4_aft_F3,H4_aft_R3,H4_aft_Q3,H4_aft_Staff3,H4_aft_Surr3,H4_aft_M3])\n",
        "\n",
        "#nltk.downoad('vader_lexicon')\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "sentiments = SentimentIntensityAnalyzer()            \n",
        "H4_aft_review[\"Positive\"] = [sentiments.polarity_scores(i)[\"pos\"] for i in H4_aft_review[\"new_senc\"]]\n",
        "H4_aft_review[\"Negative\"] = [sentiments.polarity_scores(i)[\"neg\"] for i in H4_aft_review[\"new_senc\"]]\n",
        "H4_aft_review[\"Neutral\"] = [sentiments.polarity_scores(i)[\"neu\"] for i in H4_aft_review[\"new_senc\"]]\n",
        "H4_aft_review[\"Compound\"] = [sentiments.polarity_scores(i)[\"compound\"] for i in H4_aft_review[\"new_senc\"]]\n",
        "print(H4_aft_review.head())  \n",
        "\n",
        "H4_aft_score = H4_aft_review.groupby('Tag').mean()\n",
        "H4_aft_score.loc[len(H4_aft_score.index)] = [H4_aft_review.mean(axis = 0)[0],\n",
        "                                             H4_aft_review.mean(axis = 0)[1],\n",
        "                                               H4_aft_review.mean(axis = 0)[2],\n",
        "                                             H4_aft_review.mean(axis = 0)[3]]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(H4_aft_score)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dda34c3f",
      "metadata": {
        "id": "dda34c3f",
        "outputId": "fbcba2c8-e953-4e05-ed0d-9476eb01dbc4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0    We traveled to NYC after NYE for a star-studde...\n",
            "1    My daughter has decided she would like to go t...\n",
            "2    Location is just right not too close but not t...\n",
            "3    While the rooms are smaller than most Hampton'...\n",
            "4    very well positioned, close to Times Square, u...\n",
            "Name: reviews_text, dtype: object\n",
            "0    We stayed at this hotel for a friends birthday...\n",
            "1    I was there two weeks ago with my 4 year old d...\n",
            "2    \"Great Hotel, Great staff, Great location. The...\n",
            "3    This hotel had everything we could possibly as...\n",
            "4    Looking back on this four day experience what ...\n",
            "Name: reviews_text, dtype: object\n"
          ]
        }
      ],
      "source": [
        "####----Hotel 5--------\n",
        "df_H5_pre=pd.read_excel('/Users/siang-linghsu/Downloads/5.Hampton_Clean.xlsx','Hampton_Pre')\n",
        "df_H5_aft=pd.read_excel('/Users/siang-linghsu/Downloads/5.Hampton_Clean.xlsx','Hampton_Post')\n",
        "\n",
        "print(df_H5_pre['reviews_text'].head())\n",
        "\n",
        "df_H5_pre2 = df_H5_pre['reviews_text'].tolist()\n",
        "df_H5_aft2 = df_H5_aft['reviews_text'].tolist()\n",
        "\n",
        "print(df_H5_aft['reviews_text'].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8b99acb",
      "metadata": {
        "id": "f8b99acb"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "#nltk.download('punkt')\n",
        "df_H5_pre3 =[]\n",
        "a_list = []\n",
        "# use nltk sentence tokenize\n",
        "for i in range(len(df_H5_pre2)):\n",
        "    try:\n",
        "        a_list = nltk.tokenize.sent_tokenize(df_H5_pre2[i])\n",
        "        df_H5_pre3.extend(a_list)\n",
        "    except:\n",
        "        print(i)\n",
        "\n",
        "#for grammerly error : let it go\n",
        "# '!We also spent New Years in the haven rooftop bar which was a lovely finish to our holiday',\n",
        "# ' would highly recommend this hotel.',\n",
        "# I would disappear\n",
        "df_H5_pre4 =[]\n",
        "for j in df_H5_pre3:   \n",
        "    df_H5_pre4.extend( re.split( '[\\.][a-zA-Z]+',j))\n",
        "# turn into nested list\n",
        "\n",
        "df_H5_pre5 = []\n",
        "\n",
        "for k in df_H5_pre4:\n",
        "    temp_list = []\n",
        "    temp_list.append(k)\n",
        "    df_H5_pre5.append(temp_list)\n",
        "    \n",
        "#------------------------------------------AFTER-------------------------------------------------    \n",
        "#nltk.download('punkt')\n",
        "df_H5_aft3 =[]\n",
        "a_list = []\n",
        "# use nltk sentence tokenize\n",
        "for i in range(len(df_H5_aft2)):\n",
        "    try:\n",
        "        a_list = nltk.tokenize.sent_tokenize(df_H5_aft2[i])\n",
        "        df_H5_aft3.extend(a_list)\n",
        "    except:\n",
        "        print(i)\n",
        "\n",
        "#for grammerly error : let it go\n",
        "# '!We also spent New Years in the haven rooftop bar which was a lovely finish to our holiday',\n",
        "# ' would highly recommend this hotel.',\n",
        "# I would disappear\n",
        "df_H5_aft4 =[]\n",
        "for j in df_H5_aft3:   \n",
        "    df_H5_aft4.extend( re.split( '[\\.][a-zA-Z]+',j))\n",
        "# turn into nested list\n",
        "\n",
        "df_H5_aft5 = []\n",
        "\n",
        "for k in df_H5_aft4:\n",
        "    temp_list = []\n",
        "    temp_list.append(k)\n",
        "    df_H5_aft5.append(temp_list)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e44086d6",
      "metadata": {
        "id": "e44086d6",
        "outputId": "c41a2385-caf4-4dd2-cf26-b19cee730001"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[('traveled', 'VBN'), ('NYC', 'NNP'), ('NYE', 'NNP'), ('starstudded', 'VBD'), ('Broadway', 'NNP'), ('extravaganza', 'NN')], [('Naturally', 'RB'), ('wanted', 'VBN'), ('stay', 'NN'), ('close', 'RB'), ('Broadways', 'NNP'), ('theatre', 'NN'), ('district', 'NN'), ('figured', 'VBD'), ('long', 'RB'), ('shot', 'JJ'), ('wanted', 'VBN'), ('save', 'VBP'), ('bit', 'NN'), ('money', 'NN')]]\n",
            "[[('stayed', 'JJ'), ('hotel', 'NN'), ('friends', 'NNS'), ('birthday', 'JJ'), ('celebration', 'NN'), ('great', 'JJ')], [('Steps', 'NNS'), ('away', 'RB'), ('Times', 'NNP'), ('Square', 'NNP'), ('fun', 'NN')]]\n"
          ]
        }
      ],
      "source": [
        "# hotel5 pre review pre-processing\n",
        "\n",
        "hotel5_pre_review_no_punctuations = []\n",
        "\n",
        "for review in df_H5_pre5:\n",
        "    hotel5_pre_review_no_punctuations.append( re.sub('[^a-zA-Z ]+', '', str(review)))\n",
        "\n",
        "# tokenize\n",
        "#nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "hotel5_review_pre_tokenizing = []\n",
        "for review in hotel5_pre_review_no_punctuations:\n",
        "    hotel5_review_pre_tokenizing.append(word_tokenize(review))\n",
        "\n",
        "# remove stop words\n",
        "\"\"\"\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk_stop_words = stopwords.words('english')\n",
        "\n",
        "hotel5_review_pre_no_stopword = []\n",
        "\n",
        "for review in hotel5_review_pre_tokenizing :\n",
        "    for text in review:\n",
        "        if text.lower() not in nltk_stop_words :\n",
        "            hotel5_review_pre_no_stopword.append(text) \n",
        "\"\"\"\n",
        "\n",
        "\n",
        "hotel5_review_pre_no_stopword = []\n",
        "for review in hotel5_review_pre_tokenizing :\n",
        "    temp_list = []\n",
        "    for text in review:\n",
        "        if text.lower() not in stopword_list :\n",
        "            temp_list.append(text) \n",
        "    hotel5_review_pre_no_stopword.append(temp_list)\n",
        "\n",
        "    \n",
        "# review : \n",
        "#['My', 'boyfriend', 'and', 'I', 'spent', 'the', 'night', 'here', 'awhile', 'ago', \n",
        "#'and', 'we', 'couldnt', 'be', 'happier', 'with', 'our', 'stay']\n",
        "\n",
        "# pos-tagging\n",
        "# ref : https://thinkinfi.com/extract-custom-keywords-using-nltk-pos-tagger-in-python/\n",
        "#from nltk import pos_tag\n",
        "#nltk.download('averaged_perceptron_tagger')\n",
        "hotel5_review_pre_pos= []\n",
        "# sentence :['boyfriend', 'spent', 'night', 'awhile', 'ago', 'couldnt', 'happier', 'stay']\n",
        "for sent_list in hotel5_review_pre_no_stopword:\n",
        "    word_pos=[]\n",
        "    temp_list= [' '.join([str(c) for c in sent_list])]\n",
        "    for sent in temp_list:\n",
        "        try:\n",
        "            word_pos = pos_tag(sent.split(' '))\n",
        "        except:\n",
        "            print('error')\n",
        "    hotel5_review_pre_pos.append(word_pos)\n",
        "\n",
        "print(hotel5_review_pre_pos[0:2])\n",
        "\n",
        "# hotel5 AFT review pre-processing---------------------------------------------------\n",
        "\n",
        "hotel5_aft_review_no_punctuations = []\n",
        "\n",
        "for review in df_H5_aft5:\n",
        "    hotel5_aft_review_no_punctuations.append( re.sub('[^a-zA-Z ]+', '', str(review)))\n",
        "\n",
        "# tokenize\n",
        "\n",
        "hotel5_review_aft_tokenizing = []\n",
        "for review in hotel5_aft_review_no_punctuations:\n",
        "    hotel5_review_aft_tokenizing.append(word_tokenize(review))\n",
        "\n",
        "# remove stop words\n",
        "\n",
        "\n",
        "hotel5_review_aft_no_stopword = []\n",
        "for review in hotel5_review_aft_tokenizing :\n",
        "    temp_list = []\n",
        "    for text in review:\n",
        "        if text.lower() not in stopword_list :\n",
        "            temp_list.append(text) \n",
        "    hotel5_review_aft_no_stopword.append(temp_list)\n",
        "\n",
        "    \n",
        "# review : \n",
        "#['My', 'boyfriend', 'and', 'I', 'spent', 'the', 'night', 'here', 'awhile', 'ago', \n",
        "#'and', 'we', 'couldnt', 'be', 'happier', 'with', 'our', 'stay']\n",
        "\n",
        "# pos-tagging\n",
        "# ref : https://thinkinfi.com/extract-custom-keywords-using-nltk-pos-tagger-in-python/\n",
        "\n",
        "\n",
        "hotel5_review_aft_pos= []\n",
        "# sentence :['boyfriend', 'spent', 'night', 'awhile', 'ago', 'couldnt', 'happier', 'stay']\n",
        "for sent_list in hotel5_review_aft_no_stopword:\n",
        "    word_pos=[]\n",
        "    temp_list= [' '.join([str(c) for c in sent_list])]\n",
        "    for sent in temp_list:\n",
        "        try:\n",
        "            word_pos = pos_tag(sent.split(' '))\n",
        "        except:\n",
        "            print('error')\n",
        "    hotel5_review_aft_pos.append(word_pos)\n",
        "\n",
        "print(hotel5_review_aft_pos[0:2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "098ac7ce",
      "metadata": {
        "id": "098ac7ce"
      },
      "outputs": [],
      "source": [
        "hotel5_review_pre_pos2 = []\n",
        "for sent_tag in hotel5_review_pre_pos:\n",
        "    temp_list = []\n",
        "    temp_list= [word for word,pos in sent_tag \\\n",
        "            if (pos == 'NN' or pos == 'NNP' or pos == 'NNS' or pos == 'NNPS'or \n",
        "                pos == 'JJ' or pos == 'JJR' or pos == 'JJS' or\n",
        "                pos == 'VB' or pos == 'VBD' or pos == 'VBG' or pos == 'VBN'or pos == 'VBP'or pos == 'VBZ'\n",
        "                or pos == 'ADV')]\n",
        "    hotel5_review_pre_pos2.append(temp_list)\n",
        "    \n",
        "#hotel5_review_pre_pos2    \n",
        "\n",
        "\n",
        "hotel5_review_aft_pos2 = []\n",
        "for sent_tag in hotel5_review_aft_pos:\n",
        "    temp_list = []\n",
        "    temp_list= [word for word,pos in sent_tag \\\n",
        "            if (pos == 'NN' or pos == 'NNP' or pos == 'NNS' or pos == 'NNPS'or \n",
        "                pos == 'JJ' or pos == 'JJR' or pos == 'JJS' or\n",
        "                pos == 'VB' or pos == 'VBD' or pos == 'VBG' or pos == 'VBN'or pos == 'VBP'or pos == 'VBZ'\n",
        "                or pos == 'ADV')]\n",
        "    hotel5_review_aft_pos2.append(temp_list)\n",
        "    \n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3b3002c",
      "metadata": {
        "id": "b3b3002c",
        "outputId": "27878521-ed1c-43dc-9b62-e94eb88edc98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                            new_senc      Tag  Positive  \\\n",
            "0    service great location perfect room spectacular  Service     0.661   \n",
            "1    Great helpful staff remarkable customer service  Service     0.778   \n",
            "2  th floor front hotel lot early hours couple da...  Service     0.123   \n",
            "3                      wasnt convenient problem stay  Service     0.429   \n",
            "4              Times Square minute walk service city  Service     0.000   \n",
            "\n",
            "   Negative  Neutral  Compound  \n",
            "0      0.00    0.339    0.8316  \n",
            "1      0.00    0.222    0.8885  \n",
            "2      0.09    0.787    0.2617  \n",
            "3      0.00    0.571    0.3089  \n",
            "4      0.00    1.000    0.0000  \n",
            "             Positive  Negative   Neutral  Compound\n",
            "Tag                                                \n",
            "Facility     0.198164  0.062487  0.739363  0.196720\n",
            "Meal         0.347248  0.030229  0.622535  0.433495\n",
            "Quality      0.322424  0.026310  0.651261  0.354389\n",
            "Room         0.435370  0.022846  0.541781  0.490449\n",
            "Service      0.297788  0.028247  0.673966  0.360867\n",
            "Staff        0.522719  0.021307  0.455977  0.587176\n",
            "Surrounding  0.363755  0.026381  0.609875  0.448807\n",
            "7            0.381334  0.028555  0.590116  0.442130\n",
            "                                            new_senc      Tag  Positive  \\\n",
            "0  contacted Hilton manager NO FOUND DEAL SITUATI...  Service     0.211   \n",
            "1      front desk patience breakfast time plenty gor  Service     0.000   \n",
            "2  useful information checkin purchasing drinks l...  Service     0.535   \n",
            "3  Concierge service downstairs help subway links...  Service     0.213   \n",
            "4    Room size plenty big king bed desk chair closet  Service     0.000   \n",
            "\n",
            "   Negative  Neutral  Compound  \n",
            "0     0.155    0.634    0.2656  \n",
            "1     0.000    1.000    0.0000  \n",
            "2     0.000    0.465    0.7096  \n",
            "3     0.000    0.787    0.4019  \n",
            "4     0.000    1.000    0.0000  \n",
            "             Positive  Negative   Neutral  Compound\n",
            "Tag                                                \n",
            "Facility     0.219750  0.081500  0.698783  0.190875\n",
            "Meal         0.336643  0.030500  0.632864  0.395600\n",
            "Quality      0.322081  0.032207  0.645712  0.349385\n",
            "Room         0.411216  0.045643  0.543119  0.416696\n",
            "Service      0.236602  0.044301  0.719117  0.293822\n",
            "Staff        0.524032  0.014150  0.461818  0.589897\n",
            "Surrounding  0.361825  0.036891  0.601307  0.427793\n",
            "7            0.372779  0.036232  0.590993  0.413748\n"
          ]
        }
      ],
      "source": [
        "H5_pre_S =[]\n",
        "H5_pre_F =[]\n",
        "H5_pre_R =[]\n",
        "H5_pre_Q =[]\n",
        "H5_pre_Staff =[]\n",
        "H5_pre_Surr =[]\n",
        "H5_pre_M = []\n",
        "\n",
        "\n",
        "\n",
        "for senc in hotel5_review_pre_pos2:\n",
        "    i = 0\n",
        "    while i < len(senc):\n",
        "        if senc[i] in Service_list:\n",
        "            if senc not in H5_pre_S:\n",
        "                #print(f'senc[i] in Service_list')\n",
        "                H5_pre_S.append(senc)            \n",
        "        elif senc[i] in Facility_list:\n",
        "            if senc not in H5_pre_F:\n",
        "            #print(f'senc[i] in Facility_list')\n",
        "                H5_pre_F.append(senc)\n",
        "        elif senc[i] in Room_list:\n",
        "            if senc not in H5_pre_R:\n",
        "                #print(f'senc[i] in Room_list')\n",
        "                H5_pre_R.append(senc)\n",
        "        elif senc[i] in Quility_list:\n",
        "            if senc not in H5_pre_Q:\n",
        "            #print(f'senc[i] in Quility_list')\n",
        "                H5_pre_Q.append(senc)\n",
        "        elif senc[i] in Staff_list:\n",
        "            if senc not in H5_pre_Staff:\n",
        "            #print(f'senc[i] in Staff_list')\n",
        "                H5_pre_Staff.append(senc)\n",
        "        elif senc[i] in Surrounding_list:\n",
        "            if senc not in H5_pre_Surr:\n",
        "            #print(f'senc[i] in Surrounding_list')\n",
        "                H5_pre_Surr.append(senc)\n",
        "        elif senc[i] in Meal_list:\n",
        "            if senc not in H5_pre_M:\n",
        "            #print(f'senc[i] in Surrounding_list')\n",
        "                H5_pre_M.append(senc)\n",
        "        i+=1\n",
        "H5_pre_S2 =[' '.join([str(c) for c in lst]) for lst in H5_pre_S]\n",
        "H5_pre_F2 =[' '.join([str(c) for c in lst]) for lst in H5_pre_F]\n",
        "H5_pre_R2 =[' '.join([str(c) for c in lst]) for lst in H5_pre_R]\n",
        "H5_pre_Q2 =[' '.join([str(c) for c in lst]) for lst in H5_pre_Q]\n",
        "H5_pre_Staff2 =[' '.join([str(c) for c in lst]) for lst in H5_pre_Staff]\n",
        "H5_pre_Surr2 =[' '.join([str(c) for c in lst]) for lst in H5_pre_Surr]  \n",
        "H5_pre_M2 =[' '.join([str(c) for c in lst]) for lst in H5_pre_M]  \n",
        "H5_pre_S3 = pd.DataFrame(H5_pre_S2, columns = ['new_senc'])\n",
        "H5_pre_F3 = pd.DataFrame(H5_pre_F2, columns = ['new_senc'])\n",
        "H5_pre_R3 = pd.DataFrame(H5_pre_R2, columns = ['new_senc'])\n",
        "H5_pre_Q3 = pd.DataFrame(H5_pre_Q2, columns = ['new_senc'])\n",
        "H5_pre_Staff3 = pd.DataFrame(H5_pre_Staff2, columns = ['new_senc'])\n",
        "H5_pre_Surr3 = pd.DataFrame(H5_pre_Surr2, columns = ['new_senc'])\n",
        "H5_pre_M3= pd.DataFrame(H5_pre_M2, columns = ['new_senc'])\n",
        "\n",
        "H5_pre_S3['Tag'] = 'Service'\n",
        "H5_pre_F3['Tag'] = 'Facility'\n",
        "H5_pre_R3['Tag'] = 'Room'\n",
        "H5_pre_Q3['Tag'] = 'Quality'\n",
        "H5_pre_Staff3['Tag'] = 'Staff'\n",
        "H5_pre_Surr3['Tag'] = 'Surrounding'\n",
        "H5_pre_M3['Tag'] = 'Meal'\n",
        "\n",
        "H5_pre_review = pd.concat([H5_pre_S3,H5_pre_F3,H5_pre_R3,H5_pre_Q3,H5_pre_Staff3,H5_pre_Surr3,H5_pre_M3])\n",
        "\n",
        "#nltk.downoad('vader_lexicon')\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "sentiments = SentimentIntensityAnalyzer()            \n",
        "H5_pre_review[\"Positive\"] = [sentiments.polarity_scores(i)[\"pos\"] for i in H5_pre_review[\"new_senc\"]]\n",
        "H5_pre_review[\"Negative\"] = [sentiments.polarity_scores(i)[\"neg\"] for i in H5_pre_review[\"new_senc\"]]\n",
        "H5_pre_review[\"Neutral\"] = [sentiments.polarity_scores(i)[\"neu\"] for i in H5_pre_review[\"new_senc\"]]\n",
        "H5_pre_review[\"Compound\"] = [sentiments.polarity_scores(i)[\"compound\"] for i in H5_pre_review[\"new_senc\"]]\n",
        "print(H5_pre_review.head())  \n",
        "\n",
        "H5_pre_score = H5_pre_review.groupby('Tag').mean()\n",
        "H5_pre_score.loc[len(H5_pre_score.index)] = [H5_pre_review.mean(axis = 0)[0],\n",
        "                                             H5_pre_review.mean(axis = 0)[1],\n",
        "                                               H5_pre_review.mean(axis = 0)[2],\n",
        "                                            H5_pre_review.mean(axis = 0)[3]]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(H5_pre_score)\n",
        "\n",
        "#------------------------------------------AFTER--------------------------------------------------------------------\n",
        "\n",
        "\n",
        "\n",
        "H5_aft_S =[]\n",
        "H5_aft_F =[]\n",
        "H5_aft_R =[]\n",
        "H5_aft_Q =[]\n",
        "H5_aft_Staff =[]\n",
        "H5_aft_Surr =[]\n",
        "\n",
        "H5_aft_M = []\n",
        "\n",
        "\n",
        "for senc in hotel5_review_aft_pos2:\n",
        "    i = 0\n",
        "    while i < len(senc):\n",
        "        if senc[i] in Service_list:\n",
        "            if senc not in H5_aft_S:\n",
        "                #print(f'senc[i] in Service_list')\n",
        "                H5_aft_S.append(senc)            \n",
        "        elif senc[i] in Facility_list:\n",
        "            if senc not in H5_aft_F:\n",
        "            #print(f'senc[i] in Facility_list')\n",
        "                H5_aft_F.append(senc)\n",
        "        elif senc[i] in Room_list:\n",
        "            if senc not in H5_aft_R:\n",
        "                #print(f'senc[i] in Room_list')\n",
        "                H5_aft_R.append(senc)\n",
        "        elif senc[i] in Quility_list:\n",
        "            if senc not in H5_aft_Q:\n",
        "            #print(f'senc[i] in Quility_list')\n",
        "                H5_aft_Q.append(senc)\n",
        "        elif senc[i] in Staff_list:\n",
        "            if senc not in H5_aft_Staff:\n",
        "            #print(f'senc[i] in Staff_list')\n",
        "                H5_aft_Staff.append(senc)\n",
        "        elif senc[i] in Surrounding_list:\n",
        "            if senc not in H5_aft_Surr:\n",
        "            #print(f'senc[i] in Surrounding_list')\n",
        "                H5_aft_Surr.append(senc)\n",
        "                \n",
        "        elif senc[i] in Meal_list:\n",
        "            if senc not in H5_aft_M:\n",
        "            #print(f'senc[i] in Surrounding_list')\n",
        "                H5_aft_M.append(senc)\n",
        "        i+=1\n",
        "\n",
        "H5_aft_S2 =[' '.join([str(c) for c in lst]) for lst in H5_aft_S]\n",
        "H5_aft_F2 =[' '.join([str(c) for c in lst]) for lst in H5_aft_F]\n",
        "H5_aft_R2 =[' '.join([str(c) for c in lst]) for lst in H5_aft_R]\n",
        "H5_aft_Q2 =[' '.join([str(c) for c in lst]) for lst in H5_aft_Q]\n",
        "H5_aft_Staff2 =[' '.join([str(c) for c in lst]) for lst in H5_aft_Staff]\n",
        "H5_aft_M2=[' '.join([str(c) for c in lst]) for lst in H5_aft_M]  \n",
        "H5_aft_S3 = pd.DataFrame(H5_aft_S2, columns = ['new_senc'])\n",
        "H5_aft_F3 = pd.DataFrame(H5_aft_F2, columns = ['new_senc'])\n",
        "H5_aft_R3 = pd.DataFrame(H5_aft_R2, columns = ['new_senc'])\n",
        "H5_aft_Q3 = pd.DataFrame(H5_aft_Q2, columns = ['new_senc'])\n",
        "H5_aft_Staff3 = pd.DataFrame(H5_aft_Staff2, columns = ['new_senc'])\n",
        "H5_aft_Surr3 = pd.DataFrame(H5_aft_Surr2, columns = ['new_senc'])\n",
        "H5_aft_M3 = pd.DataFrame(H5_aft_M2, columns = ['new_senc'])\n",
        "\n",
        "H5_aft_S3['Tag'] = 'Service'\n",
        "H5_aft_F3['Tag'] = 'Facility'\n",
        "H5_aft_R3['Tag'] = 'Room'\n",
        "H5_aft_Q3['Tag'] = 'Quality'\n",
        "H5_aft_Staff3['Tag'] = 'Staff'\n",
        "H5_aft_Surr3['Tag'] = 'Surrounding'\n",
        "H5_aft_M3['Tag'] = 'Meal'\n",
        "\n",
        "H5_aft_review = pd.concat([H5_aft_S3,H5_aft_F3,H5_aft_R3,H5_aft_Q3,H5_aft_Staff3,H5_aft_Surr3,H5_aft_M3])\n",
        "\n",
        "#nltk.downoad('vader_lexicon')\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "sentiments = SentimentIntensityAnalyzer()            \n",
        "H5_aft_review[\"Positive\"] = [sentiments.polarity_scores(i)[\"pos\"] for i in H5_aft_review[\"new_senc\"]]\n",
        "H5_aft_review[\"Negative\"] = [sentiments.polarity_scores(i)[\"neg\"] for i in H5_aft_review[\"new_senc\"]]\n",
        "H5_aft_review[\"Neutral\"] = [sentiments.polarity_scores(i)[\"neu\"] for i in H5_aft_review[\"new_senc\"]]\n",
        "H5_aft_review[\"Compound\"] = [sentiments.polarity_scores(i)[\"compound\"] for i in H5_aft_review[\"new_senc\"]]\n",
        "print(H5_aft_review.head())  \n",
        "\n",
        "H5_aft_score = H5_aft_review.groupby('Tag').mean()\n",
        "H5_aft_score.loc[len(H5_aft_score.index)] = [H5_aft_review.mean(axis = 0)[0],\n",
        "                                             H5_aft_review.mean(axis = 0)[1],\n",
        "                                               H5_aft_review.mean(axis = 0)[2],\n",
        "                                            H5_aft_review.mean(axis = 0)[3]]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(H5_aft_score)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96413fb8",
      "metadata": {
        "id": "96413fb8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12271c60",
      "metadata": {
        "id": "12271c60"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17043a73",
      "metadata": {
        "id": "17043a73",
        "outputId": "ec64c3b1-55d6-43ca-f51b-ccc801593904"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0    Loved staying here.Great location right next t...\n",
            "1    Fantastic location - walk to great restaurants...\n",
            "2    Whilst the Warwick may not have some of the fa...\n",
            "3    We are a family of 4 and we booked 2 premier p...\n",
            "4    Hotel is in the middle of the buzz of midtown ...\n",
            "Name: reviews_text, dtype: object\n",
            "0    We stayed here for 3 nights with our one year ...\n",
            "1    We have stayed at the Warwick once before.  It...\n",
            "2    I had a 2 night reservation at the Warwick tha...\n",
            "3    Great experience was a little pricey but overa...\n",
            "4    If you are looking for a hotel in the middle o...\n",
            "Name: reviews_text, dtype: object\n"
          ]
        }
      ],
      "source": [
        "####----Hotel 6--------\n",
        "df_H6_pre=pd.read_excel('/Users/siang-linghsu/Downloads/Warwick_Clean.xls','Warwick_Pre')\n",
        "df_H6_aft=pd.read_excel('/Users/siang-linghsu/Downloads/Warwick_Clean.xls','Warwick_Post')\n",
        "\n",
        "print(df_H6_pre['reviews_text'].head())\n",
        "\n",
        "df_H6_pre2 = df_H6_pre['reviews_text'].tolist()\n",
        "df_H6_aft2 = df_H6_aft['reviews_text'].tolist()\n",
        "\n",
        "print(df_H6_aft['reviews_text'].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67d29d9a",
      "metadata": {
        "id": "67d29d9a"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "#nltk.download('punkt')\n",
        "df_H6_pre3 =[]\n",
        "a_list = []\n",
        "# use nltk sentence tokenize\n",
        "for i in range(len(df_H6_pre2)):\n",
        "    try:\n",
        "        a_list = nltk.tokenize.sent_tokenize(df_H6_pre2[i])\n",
        "        df_H6_pre3.extend(a_list)\n",
        "    except:\n",
        "        print(i)\n",
        "\n",
        "#for grammerly error : let it go\n",
        "# '!We also spent New Years in the haven rooftop bar which was a lovely finish to our holiday',\n",
        "# ' would highly recommend this hotel.',\n",
        "# I would disappear\n",
        "df_H6_pre4 =[]\n",
        "for j in df_H6_pre3:   \n",
        "    df_H6_pre4.extend( re.split( '[\\.][a-zA-Z]+',j))\n",
        "# turn into nested list\n",
        "\n",
        "df_H6_pre5 = []\n",
        "\n",
        "for k in df_H6_pre4:\n",
        "    temp_list = []\n",
        "    temp_list.append(k)\n",
        "    df_H6_pre5.append(temp_list)\n",
        "    \n",
        "#------------------------------------------AFTER-------------------------------------------------    \n",
        "#nltk.download('punkt')\n",
        "df_H6_aft3 =[]\n",
        "a_list = []\n",
        "# use nltk sentence tokenize\n",
        "for i in range(len(df_H6_aft2)):\n",
        "    try:\n",
        "        a_list = nltk.tokenize.sent_tokenize(df_H6_aft2[i])\n",
        "        df_H6_aft3.extend(a_list)\n",
        "    except:\n",
        "        print(i)\n",
        "\n",
        "#for grammerly error : let it go\n",
        "# '!We also spent New Years in the haven rooftop bar which was a lovely finish to our holiday',\n",
        "# ' would highly recommend this hotel.',\n",
        "# I would disappear\n",
        "df_H6_aft4 =[]\n",
        "for j in df_H6_aft3:   \n",
        "    df_H6_aft4.extend( re.split( '[\\.][a-zA-Z]+',j))\n",
        "# turn into nested list\n",
        "\n",
        "df_H6_aft5 = []\n",
        "\n",
        "for k in df_H6_aft4:\n",
        "    temp_list = []\n",
        "    temp_list.append(k)\n",
        "    df_H6_aft5.append(temp_list)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "231c2880",
      "metadata": {
        "id": "231c2880",
        "outputId": "6642f5e8-a3d4-4d89-df4d-58d9053a8c64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[('Loved', 'VBN'), ('staying', 'VBG')], [('location', 'NN'), ('right', 'RB'), ('next', 'JJ'), ('subway', 'RB'), ('wonderful', 'JJ'), ('breakfast', 'NN'), ('ground', 'NN'), ('floor', 'NN')]]\n",
            "[[('stayed', 'VBN'), ('nights', 'NNS'), ('one', 'CD'), ('year', 'NN'), ('old', 'JJ'), ('last', 'JJ'), ('month', 'NN')], [('perfect', 'NN')]]\n"
          ]
        }
      ],
      "source": [
        "# hotel6 pre review pre-processing\n",
        "\n",
        "hotel6_pre_review_no_punctuations = []\n",
        "\n",
        "for review in df_H6_pre5:\n",
        "    hotel6_pre_review_no_punctuations.append( re.sub('[^a-zA-Z ]+', '', str(review)))\n",
        "\n",
        "# tokenize\n",
        "#nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "hotel6_review_pre_tokenizing = []\n",
        "for review in hotel6_pre_review_no_punctuations:\n",
        "    hotel6_review_pre_tokenizing.append(word_tokenize(review))\n",
        "\n",
        "# remove stop words\n",
        "\"\"\"\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk_stop_words = stopwords.words('english')\n",
        "\n",
        "hotel6_review_pre_no_stopword = []\n",
        "\n",
        "for review in hotel6_review_pre_tokenizing :\n",
        "    for text in review:\n",
        "        if text.lower() not in nltk_stop_words :\n",
        "            hotel6_review_pre_no_stopword.append(text) \n",
        "\"\"\"\n",
        "\n",
        "\n",
        "hotel6_review_pre_no_stopword = []\n",
        "for review in hotel6_review_pre_tokenizing :\n",
        "    temp_list = []\n",
        "    for text in review:\n",
        "        if text.lower() not in stopword_list :\n",
        "            temp_list.append(text) \n",
        "    hotel6_review_pre_no_stopword.append(temp_list)\n",
        "\n",
        "    \n",
        "# review : \n",
        "#['My', 'boyfriend', 'and', 'I', 'spent', 'the', 'night', 'here', 'awhile', 'ago', \n",
        "#'and', 'we', 'couldnt', 'be', 'happier', 'with', 'our', 'stay']\n",
        "\n",
        "# pos-tagging\n",
        "# ref : https://thinkinfi.com/extract-custom-keywords-using-nltk-pos-tagger-in-python/\n",
        "#from nltk import pos_tag\n",
        "#nltk.download('averaged_perceptron_tagger')\n",
        "hotel6_review_pre_pos= []\n",
        "# sentence :['boyfriend', 'spent', 'night', 'awhile', 'ago', 'couldnt', 'happier', 'stay']\n",
        "for sent_list in hotel6_review_pre_no_stopword:\n",
        "    word_pos=[]\n",
        "    temp_list= [' '.join([str(c) for c in sent_list])]\n",
        "    for sent in temp_list:\n",
        "        try:\n",
        "            word_pos = pos_tag(sent.split(' '))\n",
        "        except:\n",
        "            print('error')\n",
        "    hotel6_review_pre_pos.append(word_pos)\n",
        "\n",
        "print(hotel6_review_pre_pos[0:2])\n",
        "\n",
        "# hotel6 AFT review pre-processing---------------------------------------------------\n",
        "\n",
        "hotel6_aft_review_no_punctuations = []\n",
        "\n",
        "for review in df_H6_aft5:\n",
        "    hotel6_aft_review_no_punctuations.append( re.sub('[^a-zA-Z ]+', '', str(review)))\n",
        "\n",
        "# tokenize\n",
        "\n",
        "hotel6_review_aft_tokenizing = []\n",
        "for review in hotel6_aft_review_no_punctuations:\n",
        "    hotel6_review_aft_tokenizing.append(word_tokenize(review))\n",
        "\n",
        "# remove stop words\n",
        "\n",
        "\n",
        "hotel6_review_aft_no_stopword = []\n",
        "for review in hotel6_review_aft_tokenizing :\n",
        "    temp_list = []\n",
        "    for text in review:\n",
        "        if text.lower() not in stopword_list :\n",
        "            temp_list.append(text) \n",
        "    hotel6_review_aft_no_stopword.append(temp_list)\n",
        "\n",
        "    \n",
        "# review : \n",
        "#['My', 'boyfriend', 'and', 'I', 'spent', 'the', 'night', 'here', 'awhile', 'ago', \n",
        "#'and', 'we', 'couldnt', 'be', 'happier', 'with', 'our', 'stay']\n",
        "\n",
        "# pos-tagging\n",
        "# ref : https://thinkinfi.com/extract-custom-keywords-using-nltk-pos-tagger-in-python/\n",
        "\n",
        "\n",
        "hotel6_review_aft_pos= []\n",
        "# sentence :['boyfriend', 'spent', 'night', 'awhile', 'ago', 'couldnt', 'happier', 'stay']\n",
        "for sent_list in hotel6_review_aft_no_stopword:\n",
        "    word_pos=[]\n",
        "    temp_list= [' '.join([str(c) for c in sent_list])]\n",
        "    for sent in temp_list:\n",
        "        try:\n",
        "            word_pos = pos_tag(sent.split(' '))\n",
        "        except:\n",
        "            print('error')\n",
        "    hotel6_review_aft_pos.append(word_pos)\n",
        "\n",
        "print(hotel6_review_aft_pos[0:2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee078ab4",
      "metadata": {
        "id": "ee078ab4"
      },
      "outputs": [],
      "source": [
        "hotel6_review_pre_pos2 = []\n",
        "for sent_tag in hotel6_review_pre_pos:\n",
        "    temp_list = []\n",
        "    temp_list= [word for word,pos in sent_tag \\\n",
        "            if (pos == 'NN' or pos == 'NNP' or pos == 'NNS' or pos == 'NNPS'or \n",
        "                pos == 'JJ' or pos == 'JJR' or pos == 'JJS' or\n",
        "                pos == 'VB' or pos == 'VBD' or pos == 'VBG' or pos == 'VBN'or pos == 'VBP'or pos == 'VBZ'\n",
        "                or pos == 'ADV')]\n",
        "    hotel6_review_pre_pos2.append(temp_list)\n",
        "    \n",
        "#hotel6_review_pre_pos2    \n",
        "\n",
        "\n",
        "hotel6_review_aft_pos2 = []\n",
        "for sent_tag in hotel6_review_aft_pos:\n",
        "    temp_list = []\n",
        "    temp_list= [word for word,pos in sent_tag \\\n",
        "            if (pos == 'NN' or pos == 'NNP' or pos == 'NNS' or pos == 'NNPS'or \n",
        "                pos == 'JJ' or pos == 'JJR' or pos == 'JJS' or\n",
        "                pos == 'VB' or pos == 'VBD' or pos == 'VBG' or pos == 'VBN'or pos == 'VBP'or pos == 'VBZ'\n",
        "                or pos == 'ADV')]\n",
        "    hotel6_review_aft_pos2.append(temp_list)\n",
        "    \n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cde088a1",
      "metadata": {
        "id": "cde088a1",
        "outputId": "e3dc2e25-e857-4f25-f8b5-914c82c10ed0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                            new_senc      Tag  Positive  \\\n",
            "0                             rooms fast lifts bonus  Service     0.538   \n",
            "1       Nicest people front desk doormen divine beds  Service     0.576   \n",
            "2  breakfasts sublime expensive bar busy expensiv...  Service     0.000   \n",
            "3          location convenient everything wanted see  Service     0.000   \n",
            "4           encountered great service friendly staff  Service     0.709   \n",
            "\n",
            "   Negative  Neutral  Compound  \n",
            "0     0.000    0.462    0.5423  \n",
            "1     0.000    0.424    0.7783  \n",
            "2     0.242    0.758   -0.4939  \n",
            "3     0.000    1.000    0.0000  \n",
            "4     0.000    0.291    0.8074  \n",
            "             Positive  Negative   Neutral  Compound\n",
            "Tag                                                \n",
            "Facility     0.226426  0.058228  0.715345  0.255115\n",
            "Meal         0.289969  0.039327  0.670699  0.348991\n",
            "Quality      0.278842  0.037729  0.683432  0.299951\n",
            "Room         0.320543  0.047275  0.632184  0.336891\n",
            "Service      0.285758  0.037596  0.676645  0.348685\n",
            "Staff        0.499742  0.019356  0.480912  0.584572\n",
            "Surrounding  0.336620  0.030269  0.633115  0.438100\n",
            "7            0.336826  0.036732  0.626444  0.394012\n",
            "                                            new_senc      Tag  Positive  \\\n",
            "0        Premiere room appointed small service great  Service     0.451   \n",
            "1  amazed friendly understanding desk staff took ...  Service     0.561   \n",
            "2  spent time Randolphs bar varying service excel...  Service     0.596   \n",
            "3                     front desk staff accommodating  Service     0.000   \n",
            "4  House keeping fantastic job overall experience...  Service     0.313   \n",
            "\n",
            "   Negative  Neutral  Compound  \n",
            "0     0.000    0.549    0.6249  \n",
            "1     0.000    0.439    0.7506  \n",
            "2     0.000    0.404    0.8957  \n",
            "3     0.000    1.000    0.0000  \n",
            "4     0.117    0.570    0.7351  \n",
            "             Positive  Negative   Neutral  Compound\n",
            "Tag                                                \n",
            "Facility     0.122942  0.072538  0.804442  0.069060\n",
            "Meal         0.168462  0.033808  0.797692  0.175112\n",
            "Quality      0.252943  0.066286  0.680757  0.254454\n",
            "Room         0.226730  0.070452  0.702810  0.165421\n",
            "Service      0.194032  0.074768  0.731211  0.146644\n",
            "Staff        0.483718  0.031224  0.485071  0.552520\n",
            "Surrounding  0.319500  0.039244  0.641267  0.412980\n",
            "7            0.267189  0.057825  0.674978  0.674978\n"
          ]
        }
      ],
      "source": [
        "H6_pre_S =[]\n",
        "H6_pre_F =[]\n",
        "H6_pre_R =[]\n",
        "H6_pre_Q =[]\n",
        "H6_pre_Staff =[]\n",
        "H6_pre_Surr =[]\n",
        "H6_pre_M = []\n",
        "\n",
        "\n",
        "\n",
        "for senc in hotel6_review_pre_pos2:\n",
        "    i = 0\n",
        "    while i < len(senc):\n",
        "        if senc[i] in Service_list:\n",
        "            if senc not in H6_pre_S:\n",
        "                #print(f'senc[i] in Service_list')\n",
        "                H6_pre_S.append(senc)            \n",
        "        elif senc[i] in Facility_list:\n",
        "            if senc not in H6_pre_F:\n",
        "            #print(f'senc[i] in Facility_list')\n",
        "                H6_pre_F.append(senc)\n",
        "        elif senc[i] in Room_list:\n",
        "            if senc not in H6_pre_R:\n",
        "                #print(f'senc[i] in Room_list')\n",
        "                H6_pre_R.append(senc)\n",
        "        elif senc[i] in Quility_list:\n",
        "            if senc not in H6_pre_Q:\n",
        "            #print(f'senc[i] in Quility_list')\n",
        "                H6_pre_Q.append(senc)\n",
        "        elif senc[i] in Staff_list:\n",
        "            if senc not in H6_pre_Staff:\n",
        "            #print(f'senc[i] in Staff_list')\n",
        "                H6_pre_Staff.append(senc)\n",
        "        elif senc[i] in Surrounding_list:\n",
        "            if senc not in H6_pre_Surr:\n",
        "            #print(f'senc[i] in Surrounding_list')\n",
        "                H6_pre_Surr.append(senc)\n",
        "        elif senc[i] in Meal_list:\n",
        "            if senc not in H6_pre_M:\n",
        "            #print(f'senc[i] in Surrounding_list')\n",
        "                H6_pre_M.append(senc)\n",
        "        i+=1\n",
        "H6_pre_S2 =[' '.join([str(c) for c in lst]) for lst in H6_pre_S]\n",
        "H6_pre_F2 =[' '.join([str(c) for c in lst]) for lst in H6_pre_F]\n",
        "H6_pre_R2 =[' '.join([str(c) for c in lst]) for lst in H6_pre_R]\n",
        "H6_pre_Q2 =[' '.join([str(c) for c in lst]) for lst in H6_pre_Q]\n",
        "H6_pre_Staff2 =[' '.join([str(c) for c in lst]) for lst in H6_pre_Staff]\n",
        "H6_pre_Surr2 =[' '.join([str(c) for c in lst]) for lst in H6_pre_Surr]  \n",
        "H6_pre_M2 = [' '.join([str(c) for c in lst]) for lst in H6_pre_M]  \n",
        "H6_pre_S3 = pd.DataFrame(H6_pre_S2, columns = ['new_senc'])\n",
        "H6_pre_F3 = pd.DataFrame(H6_pre_F2, columns = ['new_senc'])\n",
        "H6_pre_R3 = pd.DataFrame(H6_pre_R2, columns = ['new_senc'])\n",
        "H6_pre_Q3 = pd.DataFrame(H6_pre_Q2, columns = ['new_senc'])\n",
        "H6_pre_Staff3 = pd.DataFrame(H6_pre_Staff2, columns = ['new_senc'])\n",
        "H6_pre_Surr3 = pd.DataFrame(H6_pre_Surr2, columns = ['new_senc'])\n",
        "H6_pre_M3= pd.DataFrame(H6_pre_M2, columns = ['new_senc'])\n",
        "\n",
        "H6_pre_S3['Tag'] = 'Service'\n",
        "H6_pre_F3['Tag'] = 'Facility'\n",
        "H6_pre_R3['Tag'] = 'Room'\n",
        "H6_pre_Q3['Tag'] = 'Quality'\n",
        "H6_pre_Staff3['Tag'] = 'Staff'\n",
        "H6_pre_Surr3['Tag'] = 'Surrounding'\n",
        "H6_pre_M3['Tag'] = 'Meal'\n",
        "\n",
        "H6_pre_review = pd.concat([H6_pre_S3,H6_pre_F3,H6_pre_R3,H6_pre_Q3,H6_pre_Staff3,H6_pre_Surr3,H6_pre_M3])\n",
        "\n",
        "#nltk.downoad('vader_lexicon')\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "sentiments = SentimentIntensityAnalyzer()            \n",
        "H6_pre_review[\"Positive\"] = [sentiments.polarity_scores(i)[\"pos\"] for i in H6_pre_review[\"new_senc\"]]\n",
        "H6_pre_review[\"Negative\"] = [sentiments.polarity_scores(i)[\"neg\"] for i in H6_pre_review[\"new_senc\"]]\n",
        "H6_pre_review[\"Neutral\"] = [sentiments.polarity_scores(i)[\"neu\"] for i in H6_pre_review[\"new_senc\"]]\n",
        "H6_pre_review[\"Compound\"] = [sentiments.polarity_scores(i)[\"compound\"] for i in H6_pre_review[\"new_senc\"]]\n",
        "print(H6_pre_review.head())  \n",
        "\n",
        "H6_pre_score = H6_pre_review.groupby('Tag').mean()\n",
        "H6_pre_score.loc[len(H6_pre_score.index)] = [H6_pre_review.mean(axis = 0)[0],\n",
        "                                             H6_pre_review.mean(axis = 0)[1],\n",
        "                                               H6_pre_review.mean(axis = 0)[2],\n",
        "                                            H6_pre_review.mean(axis = 0)[3]]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(H6_pre_score)\n",
        "\n",
        "#------------------------------------------AFTER--------------------------------------------------------------------\n",
        "\n",
        "\n",
        "\n",
        "H6_aft_S =[]\n",
        "H6_aft_F =[]\n",
        "H6_aft_R =[]\n",
        "H6_aft_Q =[]\n",
        "H6_aft_Staff =[]\n",
        "H6_aft_Surr =[]\n",
        "H6_aft_M = []\n",
        "\n",
        "\n",
        "\n",
        "for senc in hotel6_review_aft_pos2:\n",
        "    i = 0\n",
        "    while i < len(senc):\n",
        "        if senc[i] in Service_list:\n",
        "            if senc not in H6_aft_S:\n",
        "                #print(f'senc[i] in Service_list')\n",
        "                H6_aft_S.append(senc)            \n",
        "        elif senc[i] in Facility_list:\n",
        "            if senc not in H6_aft_F:\n",
        "            #print(f'senc[i] in Facility_list')\n",
        "                H6_aft_F.append(senc)\n",
        "        elif senc[i] in Room_list:\n",
        "            if senc not in H6_aft_R:\n",
        "                #print(f'senc[i] in Room_list')\n",
        "                H6_aft_R.append(senc)\n",
        "        elif senc[i] in Quility_list:\n",
        "            if senc not in H6_aft_Q:\n",
        "            #print(f'senc[i] in Quility_list')\n",
        "                H6_aft_Q.append(senc)\n",
        "        elif senc[i] in Staff_list:\n",
        "            if senc not in H6_aft_Staff:\n",
        "            #print(f'senc[i] in Staff_list')\n",
        "                H6_aft_Staff.append(senc)\n",
        "        elif senc[i] in Surrounding_list:\n",
        "            if senc not in H6_aft_Surr:\n",
        "            #print(f'senc[i] in Surrounding_list')\n",
        "                H6_aft_Surr.append(senc)\n",
        "        elif senc[i] in Meal_list:\n",
        "            if senc not in H6_aft_M:\n",
        "            #print(f'senc[i] in Surrounding_list')\n",
        "                H6_aft_M.append(senc)\n",
        "        i+=1\n",
        "\n",
        "H6_aft_S2 =[' '.join([str(c) for c in lst]) for lst in H6_aft_S]\n",
        "H6_aft_F2 =[' '.join([str(c) for c in lst]) for lst in H6_aft_F]\n",
        "H6_aft_R2 =[' '.join([str(c) for c in lst]) for lst in H6_aft_R]\n",
        "H6_aft_Q2 =[' '.join([str(c) for c in lst]) for lst in H6_aft_Q]\n",
        "H6_aft_Staff2 =[' '.join([str(c) for c in lst]) for lst in H6_aft_Staff]\n",
        "H6_aft_Surr2 =[' '.join([str(c) for c in lst]) for lst in H6_aft_Surr]  \n",
        "H6_aft_M2=[' '.join([str(c) for c in lst]) for lst in H6_aft_M]  \n",
        "H6_aft_S3 = pd.DataFrame(H6_aft_S2, columns = ['new_senc'])\n",
        "H6_aft_F3 = pd.DataFrame(H6_aft_F2, columns = ['new_senc'])\n",
        "H6_aft_R3 = pd.DataFrame(H6_aft_R2, columns = ['new_senc'])\n",
        "H6_aft_Q3 = pd.DataFrame(H6_aft_Q2, columns = ['new_senc'])\n",
        "H6_aft_Staff3 = pd.DataFrame(H6_aft_Staff2, columns = ['new_senc'])\n",
        "H6_aft_Surr3 = pd.DataFrame(H6_aft_Surr2, columns = ['new_senc'])\n",
        "H6_aft_M3= pd.DataFrame(H6_aft_M2, columns = ['new_senc'])\n",
        "\n",
        "H6_aft_S3['Tag'] = 'Service'\n",
        "H6_aft_F3['Tag'] = 'Facility'\n",
        "H6_aft_R3['Tag'] = 'Room'\n",
        "H6_aft_Q3['Tag'] = 'Quality'\n",
        "H6_aft_Staff3['Tag'] = 'Staff'\n",
        "H6_aft_Surr3['Tag'] = 'Surrounding'\n",
        "H6_aft_M3['Tag'] = 'Meal'\n",
        "\n",
        "H6_aft_review = pd.concat([H6_aft_S3,H6_aft_F3,H6_aft_R3,H6_aft_Q3,H6_aft_Staff3,H6_aft_Surr3,H6_aft_M3])\n",
        "\n",
        "#nltk.downoad('vader_lexicon')\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "sentiments = SentimentIntensityAnalyzer()            \n",
        "H6_aft_review[\"Positive\"] = [sentiments.polarity_scores(i)[\"pos\"] for i in H6_aft_review[\"new_senc\"]]\n",
        "H6_aft_review[\"Negative\"] = [sentiments.polarity_scores(i)[\"neg\"] for i in H6_aft_review[\"new_senc\"]]\n",
        "H6_aft_review[\"Neutral\"] = [sentiments.polarity_scores(i)[\"neu\"] for i in H6_aft_review[\"new_senc\"]]\n",
        "H6_aft_review[\"Compound\"] = [sentiments.polarity_scores(i)[\"compound\"] for i in H6_aft_review[\"new_senc\"]]\n",
        "print(H6_aft_review.head())  \n",
        "\n",
        "H6_aft_score = H6_aft_review.groupby('Tag').mean()\n",
        "H6_aft_score.loc[len(H6_aft_score.index)] = [H6_aft_review.mean(axis = 0)[0],\n",
        "                                             H6_aft_review.mean(axis = 0)[1],\n",
        "                                               H6_aft_review.mean(axis = 0)[2],\n",
        "                                            H6_aft_review.mean(axis = 0)[2]]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(H6_aft_score)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56e0adbd",
      "metadata": {
        "id": "56e0adbd"
      },
      "outputs": [],
      "source": [
        "H1_aft_review.to_excel('H1_aft_review.xlsx')\n",
        "H1_pre_review.to_excel('H1_pre_review.xlsx')\n",
        "H2_aft_review.to_excel('H2_aft_review.xlsx')\n",
        "H2_pre_review.to_excel('H2_pre_review.xlsx')\n",
        "H3_aft_review.to_excel('H3_aft_review.xlsx')\n",
        "H3_pre_review.to_excel('H3_pre_review.xlsx')\n",
        "H4_aft_review.to_excel('H4_aft_review.xlsx')\n",
        "H4_pre_review.to_excel('H4_pre_review.xlsx')\n",
        "H5_aft_review.to_excel('H5_aft_review.xlsx')\n",
        "H5_pre_review.to_excel('H5_pre_review.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d830ce5d",
      "metadata": {
        "id": "d830ce5d"
      },
      "outputs": [],
      "source": [
        "H6_aft_review.to_excel('H6_aft_review.xlsx')\n",
        "H6_pre_review.to_excel('H6_pre_review.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8297bbea",
      "metadata": {
        "id": "8297bbea"
      },
      "outputs": [],
      "source": [
        "H1_aft_review2 = pd.read_excel('/Users/siang-linghsu/Downloads/H1_aft_review.xlsx')\n",
        "H1_pre_review2 = pd.read_excel('/Users/siang-linghsu/Downloads/H1_pre_review.xlsx')\n",
        "H2_aft_review2 = pd.read_excel('/Users/siang-linghsu/Downloads/H2_aft_review.xlsx')\n",
        "H2_pre_review2 = pd.read_excel('/Users/siang-linghsu/Downloads/H2_pre_review.xlsx')\n",
        "H3_aft_review2 = pd.read_excel('/Users/siang-linghsu/Downloads/H3_aft_review.xlsx')\n",
        "H3_pre_review2 = pd.read_excel('/Users/siang-linghsu/Downloads/H3_pre_review.xlsx')\n",
        "H4_aft_review2 = pd.read_excel('/Users/siang-linghsu/Downloads/H4_aft_review.xlsx')\n",
        "H4_pre_review2 = pd.read_excel('/Users/siang-linghsu/Downloads/H4_pre_review.xlsx')\n",
        "H5_aft_review2 = pd.read_excel('/Users/siang-linghsu/Downloads/H5_aft_review.xlsx')\n",
        "H5_pre_review2 = pd.read_excel('/Users/siang-linghsu/Downloads/H5_pre_review.xlsx')\n",
        "H6_aft_review2 = pd.read_excel('/Users/siang-linghsu/Downloads/H6_aft_review.xlsx')\n",
        "H6_pre_review2 = pd.read_excel('/Users/siang-linghsu/Downloads/H6_pre_review.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca164036",
      "metadata": {
        "id": "ca164036",
        "outputId": "b3ce1bad-e490-458c-97cb-99f2c5643c1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "          Unnamed: 0  new_senc  Tag  Positive  Negative  Neutral  Compound  \\\n",
            "Result                                                                       \n",
            "Negative          27        27   27        27        27       27        27   \n",
            "Neutral           69        69   69        69        69       69        69   \n",
            "Positive         183       183  183       183       183      183       183   \n",
            "\n",
            "          Hotel  \n",
            "Result           \n",
            "Negative     27  \n",
            "Neutral      69  \n",
            "Positive    183  \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\"\\nH6_aft_score = H6_aft_review.groupby('Tag').mean()\\nH6_aft_score.loc[len(H6_aft_score.index)] = [H6_aft_review.mean(axis = 0)[0],\\n                                             H6_aft_review.mean(axis = 0)[1],\\n                                               H6_aft_review.mean(axis = 0)[2],\\n                                            H6_aft_review.mean(axis = 0)[2]]\\n                                            \\n                                            \""
            ]
          },
          "execution_count": 421,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(H1_aft_review2.groupby('Result').count())\n",
        "\"\"\"\n",
        "H6_aft_score = H6_aft_review.groupby('Tag').mean()\n",
        "H6_aft_score.loc[len(H6_aft_score.index)] = [H6_aft_review.mean(axis = 0)[0],\n",
        "                                             H6_aft_review.mean(axis = 0)[1],\n",
        "                                               H6_aft_review.mean(axis = 0)[2],\n",
        "                                            H6_aft_review.mean(axis = 0)[2]]\n",
        "                                            \n",
        "                                            \"\"\"\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a589873b",
      "metadata": {
        "id": "a589873b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6048791",
      "metadata": {
        "id": "a6048791"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3819791b",
      "metadata": {
        "id": "3819791b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ac39cf4",
      "metadata": {
        "id": "4ac39cf4"
      },
      "outputs": [],
      "source": [
        "H1_pre_score2 = H1_pre_score.transpose().rename(columns={6: \"Sum_of_Ave\"})\n",
        "H1_pre_score2.index = ['H1_Pos','H1_Neg','H1_Neu','H1_Comp']\n",
        "H2_pre_score2 = H2_pre_score.transpose().rename(columns={6: \"Sum_of_Ave\"})\n",
        "H2_pre_score2.index = ['H2_Pos','H2_Neg','H2_Neu','H2_Comp']\n",
        "H3_pre_score2 = H3_pre_score.transpose().rename(columns={6: \"Sum_of_Ave\"})\n",
        "H3_pre_score2.index = ['H3_Pos','H3_Neg','H3_Neu','H3_Comp']\n",
        "H4_pre_score2 = H4_pre_score.transpose().rename(columns={6: \"Sum_of_Ave\"})\n",
        "H4_pre_score2.index = ['H4_Pos','H4_Neg','H4_Neu','H4_Comp']\n",
        "H5_pre_score2 = H5_pre_score.transpose().rename(columns={6: \"Sum_of_Ave\"})\n",
        "H5_pre_score2.index = ['H5_Pos','H5_Neg','H5_Neu','H5_Comp']\n",
        "H6_pre_score2 = H6_pre_score.transpose().rename(columns={6: \"Sum_of_Ave\"})\n",
        "H6_pre_score2.index = ['H6_Pos','H6_Neg','H6_Neu','H6_Comp']\n",
        "\n",
        "H1_aft_score2 = H1_aft_score.transpose().rename(columns={6: \"Sum_of_Ave\"})\n",
        "H1_aft_score2.index = ['H1_Pos_post','H1_Neg_post','H1_Neu_post','H1_Comp_post']\n",
        "H2_aft_score2 = H2_aft_score.transpose().rename(columns={6: \"Sum_of_Ave\"})\n",
        "H2_aft_score2.index = ['H2_Pos_post','H2_Neg_post','H2_Neu_post','H2_Comp_post]']\n",
        "H3_aft_score2 = H3_aft_score.transpose().rename(columns={6: \"Sum_of_Ave\"})\n",
        "H3_aft_score2.index = ['H3_Pos_post','H3_Neg_post','H3_Neu_post','H3_Comp_post]']\n",
        "H4_aft_score2 = H4_aft_score.transpose().rename(columns={6: \"Sum_of_Ave\"})\n",
        "H4_aft_score2.index = ['H4_Pos_post','H4_Neg_post','H4_Neu_post','H4_Comp_post]']\n",
        "H5_aft_score2 = H5_aft_score.transpose().rename(columns={6: \"Sum_of_Ave\"})\n",
        "H5_aft_score2.index = ['H5_Pos_post','H5_Neg_post','H5_Neu_post','H5_Comp_post]']\n",
        "H6_aft_score2 = H6_aft_score.transpose().rename(columns={6: \"Sum_of_Ave\"})\n",
        "H6_aft_score2.index = ['H6_Pos_post','H6_Neg_post','H6_Neu_post','H6_Comp_post]']\n",
        "\n",
        "Hotel_Score = pd.concat([H6_aft_score2,H5_aft_score2,H4_aft_score2,H3_aft_score2,\n",
        "                         H2_aft_score2,H1_aft_score2,H6_pre_score2,H5_pre_score2,\n",
        "                         H4_pre_score2,H3_pre_score2,H2_pre_score2,H1_pre_score2])\n",
        "\n",
        "\n",
        "Hotel_Score2  = Hotel_Score*100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce3488a2",
      "metadata": {
        "id": "ce3488a2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11462af6",
      "metadata": {
        "id": "11462af6"
      },
      "outputs": [],
      "source": [
        "Hotel_Score.to_excel('Hotel_Score5.xlsx')\n",
        "Hotel_Score2.to_excel('Hotel_Score6.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ec1e71c",
      "metadata": {
        "id": "1ec1e71c"
      },
      "outputs": [],
      "source": [
        "#H6_aft_score.to_excel('H6_aft_score')\n",
        "# Create a Pandas Excel writer using XlsxWriter as the engine.\n",
        "writer = pd.ExcelWriter('Score.xlsx', engine='xlsxwriter')\n",
        "\n",
        "# Write each dataframe to a different worksheet.\n",
        "H1_aft_score.to_excel(writer, sheet_name='H1_aft')\n",
        "H1_pre_score.to_excel(writer, sheet_name='H1_pre')\n",
        "H2_aft_score.to_excel(writer, sheet_name='H2_aft')\n",
        "H2_pre_score.to_excel(writer, sheet_name='H2_pre')\n",
        "H3_aft_score.to_excel(writer, sheet_name='H3_aft')\n",
        "H3_pre_score.to_excel(writer, sheet_name='H3_pre')\n",
        "H4_aft_score.to_excel(writer, sheet_name='H4_aft')\n",
        "H4_pre_score.to_excel(writer, sheet_name='H4_pre')\n",
        "H5_aft_score.to_excel(writer, sheet_name='H5_aft')\n",
        "H5_pre_score.to_excel(writer, sheet_name='H5_pre')\n",
        "H6_aft_score.to_excel(writer, sheet_name='H6_aft')\n",
        "H6_pre_score.to_excel(writer, sheet_name='H6_pre')\n",
        "\n",
        "\n",
        "# Close the Pandas Excel writer and output the Excel file.\n",
        "writer.save()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68d0bbfd",
      "metadata": {
        "id": "68d0bbfd",
        "outputId": "6bab1330-ffff-4875-d745-0a8b560d2fba"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Tag</th>\n",
              "      <th>Room</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>H1_Pos</th>\n",
              "      <td>0.334066</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>H1_Neg</th>\n",
              "      <td>0.040522</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>H1_Neu</th>\n",
              "      <td>0.625410</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Tag         Room\n",
              "H1_Pos  0.334066\n",
              "H1_Neg  0.040522\n",
              "H1_Neu  0.625410"
            ]
          },
          "execution_count": 355,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "H1_pre_score2[['Room']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7d5c2bc",
      "metadata": {
        "id": "f7d5c2bc",
        "outputId": "18b3aa9c-76cd-48c4-af6d-eab862307905"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"isn't\", 'ma', 'herself', 'before', 'have', 'about', 'll', 'shouldn', 'from', 'does', 'd', \"should've\", 'should', 'weren', \"shouldn't\", 'such', 'i', 'below', 'wouldn', 'ours', 'being', 'nor', 'with', 't', 'has', 'ain', 'these', 'it', 'doesn', 'aren', \"wasn't\", 'a', 'yourselves', 'now', 'not', 'too', 'through', 'up', 'against', \"you're\", 'can', 'just', 'the', \"that'll\", 'so', 'during', \"didn't\", \"haven't\", 'only', \"needn't\", 'under', 'had', 'of', 'your', 'yourself', 'myself', 'their', 'was', 'y', 'why', 'no', 'any', \"shan't\", \"doesn't\", 'while', \"couldn't\", 'himself', 'once', 'until', 'she', 'off', 'all', 'o', 'wasn', 'this', 'mightn', 'when', 'been', 'won', 'are', 'then', \"hasn't\", 'as', \"mustn't\", 'or', 'itself', 'if', 'than', 'above', 'theirs', 'whom', 'that', 'mustn', 'for', \"she's\", 'couldn', 'an', 'few', 'her', 'needn', 'those', 'because', 'further', 'having', 'ourselves', 'over', 'most', 's', 'between', \"hadn't\", \"weren't\", 'each', 'didn', 'yours', 'be', 'but', 'to', 'do', \"won't\", 'on', 'his', 'shan', 'own', \"you'd\", 'were', 'them', 'm', 've', 'by', 'where', 'some', 'hasn', \"wouldn't\", 'same', 're', 'am', 'hers', 'him', 'there', 'me', 'and', 'who', \"don't\", 'its', 'down', 'in', 'isn', 'haven', 'other', 'did', 'he', 'after', 'what', 'themselves', 'hadn', 'both', 'at', \"you've\", 'into', \"you'll\", 'will', 'our', 'they', 'doing', \"mightn't\", \"it's\", 'my', 'which', 'how', 'is', 'here', 'don', 'we', 'more', 'very', 'out', 'again', 'you', \"aren't\"}\n"
          ]
        }
      ],
      "source": [
        "# the stop word list \n",
        "stops = set(stopwords.words('english'))\n",
        "print(stops)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}