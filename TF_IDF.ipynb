{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yunhui666/NLP_TripAdvisor_Review_Scrap/blob/main/TF_IDF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ffb26b20",
      "metadata": {
        "id": "ffb26b20"
      },
      "outputs": [],
      "source": [
        "#pip install nltk\n",
        "import nltk\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1bced7be",
      "metadata": {
        "id": "1bced7be"
      },
      "outputs": [],
      "source": [
        "df_H1_pre=pd.read_excel('/Users/siang-linghsu/Downloads/Sanctuary Hotel-.xlsx','Sanctuary_Pre')\n",
        "df_H1_aft=pd.read_excel('/Users/siang-linghsu/Downloads/Sanctuary Hotel-.xlsx','Sanctuary_Post')\n",
        "df_H2_pre=pd.read_excel('/Users/siang-linghsu/Downloads/Edison_Clean.xls','Edison_Pre')\n",
        "df_H2_aft=pd.read_excel('/Users/siang-linghsu/Downloads/Edison_Clean.xls','Edison_Post')\n",
        "df_H3_pre=pd.read_excel('/Users/siang-linghsu/Downloads/Double_Clean.xlsm',' Hilton_Pre')\n",
        "df_H3_aft=pd.read_excel('/Users/siang-linghsu/Downloads/Double_Clean.xlsm',' Hilton_Post')\n",
        "df_H4_pre=pd.read_excel('/Users/siang-linghsu/Downloads/Millennium_Clean.xlsm','Millennium_Pre')\n",
        "df_H4_aft=pd.read_excel('/Users/siang-linghsu/Downloads/Millennium_Clean.xlsm','Millennium_Post')\n",
        "df_H5_pre=pd.read_excel('/Users/siang-linghsu/Downloads/5.Hampton_Clean.xlsx','Hampton_Pre')\n",
        "df_H5_aft=pd.read_excel('/Users/siang-linghsu/Downloads/5.Hampton_Clean.xlsx','Hampton_Post')\n",
        "df_H6_pre=pd.read_excel('/Users/siang-linghsu/Downloads/Warwick_Clean.xls','Warwick_Pre')\n",
        "df_H6_aft=pd.read_excel('/Users/siang-linghsu/Downloads/Warwick_Clean.xls','Warwick_Post')\n",
        "\n",
        "\n",
        "# turn dataframe column into a list\n",
        "H1_pre_review=df_H1_pre[\"reviews_text\"].tolist()\n",
        "H1_aft_review=df_H1_aft[\"reviews_text\"].tolist()\n",
        "H2_pre_review=df_H2_pre[\"reviews_text\"].tolist()\n",
        "H2_aft_review=df_H2_aft[\"reviews_text\"].tolist()\n",
        "H3_pre_review=df_H3_pre[\"reviews_text\"].tolist()\n",
        "H3_aft_review=df_H3_aft[\"reviews_text\"].tolist()\n",
        "H4_pre_review=df_H4_pre[\"reviews_text\"].tolist()\n",
        "H4_aft_review=df_H4_aft[\"reviews_text\"].tolist()\n",
        "H5_pre_review=df_H5_pre[\"reviews_text\"].tolist()\n",
        "H5_aft_review=df_H5_aft[\"reviews_text\"].tolist()\n",
        "H6_pre_review=df_H6_pre[\"reviews_text\"].tolist()\n",
        "H6_aft_review=df_H6_aft[\"reviews_text\"].tolist()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46cf0589",
      "metadata": {
        "id": "46cf0589",
        "outputId": "f0bc526b-1371-4d4e-9461-7b93a755cc63"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /Users/siang-\n",
            "[nltk_data]     linghsu/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /Users/siang-\n",
            "[nltk_data]     linghsu/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /Users/siang-\n",
            "[nltk_data]     linghsu/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /Users/siang-linghsu/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ],
      "source": [
        "# hotel1 pre review pre-processing\n",
        "# These block treat a hotel brand as one document\n",
        "# remove number and punctuation\n",
        "# ref : https://www.geeksforgeeks.org/python-compute-the-frequency-of-words-after-removing-stop-words-and-stemming/?ref=rp\n",
        "\n",
        "hotel1_pre_review_no_punctuations = []\n",
        "\n",
        "\n",
        "for review in H1_pre_review:\n",
        "    hotel1_pre_review_no_punctuations.append( re.sub('[^a-zA-Z ]+', '', str(review)))\n",
        "    \n",
        "    \n",
        "# tokenize\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "hotel1_review_tokenizing = []\n",
        "for review in hotel1_pre_review_no_punctuations:\n",
        "    hotel1_review_tokenizing.append(word_tokenize(review))\n",
        "\n",
        "# remove stop words\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk_stop_words = stopwords.words('english')\n",
        "\n",
        "hotel1_review_without_stopword = []\n",
        "\n",
        "for review in hotel1_review_tokenizing :\n",
        "    for text in review:\n",
        "        if text.lower() not in nltk_stop_words :\n",
        "            hotel1_review_without_stopword.append(text)\n",
        "        \n",
        "# stemming \n",
        "#from nltk.stem.porter import PorterStemmer\n",
        "#stemmer = PorterStemmer()\n",
        "hotel1_review_after_stemming = []\n",
        "\n",
        "#for review in hotel1_review_without_stopword:\n",
        "#    hotel1_review_after_stemming.append(stemmer.stem(review))\n",
        "\n",
        "# ref:https://www.analyticsvidhya.com/blog/2020/11/text-cleaning-nltk-library/\n",
        "nltk.download('wordnet')\n",
        "wn = nltk.WordNetLemmatizer()\n",
        "for review in hotel1_review_without_stopword:\n",
        "    hotel1_review_after_stemming.append(wn.lemmatize(review))\n",
        "\n",
        "\n",
        "    \n",
        "# pos-tagging\n",
        "# ref : https://thinkinfi.com/extract-custom-keywords-using-nltk-pos-tagger-in-python/\n",
        "from nltk import pos_tag\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "hotel1_review_pos_tagging = pos_tag(hotel1_review_after_stemming)\n",
        "hotel1_N = [word for word,pos in hotel1_review_pos_tagging \\\n",
        "            if (pos == 'NN' or pos == 'NNP' or pos == 'NNS' or pos == 'NNPS')]\n",
        "hotel1_adj = [word for word,pos in hotel1_review_pos_tagging \\\n",
        "            if (pos == 'JJ' or pos == 'JJR' or pos == 'JJS' )]\n",
        "hotel1_verb = [word for word,pos in hotel1_review_pos_tagging \\\n",
        "            if (pos == 'VB' or pos == 'VBD' or pos == 'VBG' or pos == 'VBN'or pos == 'VBP'or pos == 'VBZ')]\n",
        "h1_pre_NADJ = [word for word,pos in hotel1_review_pos_tagging \\\n",
        "            if (pos == 'NN' or pos == 'NNP' or pos == 'NNS' or pos == 'NNPS'or pos == 'JJ' or pos == 'JJR' or pos == 'JJS' )]\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "with open('hotel1_pre_all_word2.txt', 'w') as file:\n",
        "    file.writelines(\"%s\\n\" % line for line in hotel1_review_after_stemming)\n",
        "with open('H1_pre_noun2.txt', 'w') as file:\n",
        "    file.writelines(\"%s\\n\" % line for line in hotel1_N )\n",
        "with open('H1_pre_adj2.txt', 'w') as file:\n",
        "    file.writelines(\"%s\\n\" % line for line in hotel1_adj )\n",
        "with open('H1_pre_ver2.txt', 'w') as file:\n",
        "    file.writelines(\"%s\\n\" % line for line in hotel1_verb)\n",
        "with open('H1_pre_NADJ2.txt', 'w') as file:\n",
        "    file.writelines(\"%s\\n\" % line for line in h1_pre_NADJ)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ef5cb3f",
      "metadata": {
        "id": "1ef5cb3f",
        "outputId": "216b0cea-d21e-473f-8f6a-447ebcb116f4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['boyfriend',\n",
              " 'spent',\n",
              " 'night',\n",
              " 'awhile',\n",
              " 'ago',\n",
              " 'couldnt',\n",
              " 'happier',\n",
              " 'stay',\n",
              " 'hotel',\n",
              " 'feel',\n",
              " 'sexy',\n",
              " 'perfect',\n",
              " 'little',\n",
              " 'staycation',\n",
              " 'right',\n",
              " 'next',\n",
              " 'Times',\n",
              " 'Square',\n",
              " 'got',\n",
              " 'tourist',\n",
              " 'city',\n",
              " 'rooftop',\n",
              " 'gorgeous',\n",
              " 'king',\n",
              " 'suite',\n",
              " 'overlooking',\n",
              " 'street',\n",
              " 'wall',\n",
              " 'wall',\n",
              " 'window',\n",
              " 'great',\n",
              " 'change',\n",
              " 'escape',\n",
              " 'tiny',\n",
              " 'Brooklyn',\n",
              " 'apartment',\n",
              " 'Would',\n",
              " 'highly',\n",
              " 'recommend',\n",
              " 'sexy',\n",
              " 'night',\n",
              " 'NY',\n",
              " 'Also',\n",
              " 'shout',\n",
              " 'GM',\n",
              " 'Jeremy',\n",
              " 'Poon',\n",
              " 'he',\n",
              " 'still',\n",
              " 'Amazing',\n",
              " 'hospitality',\n",
              " 'bellman',\n",
              " 'front',\n",
              " 'desk',\n",
              " 'housekeeping',\n",
              " 'team',\n",
              " 'fiance',\n",
              " 'stayed',\n",
              " 'hotel',\n",
              " 'Christmas',\n",
              " 'year',\n",
              " 'anniversaryBeing',\n",
              " 'New',\n",
              " 'York',\n",
              " 'Christmas',\n",
              " 'always',\n",
              " 'bucket',\n",
              " 'list',\n",
              " 'got',\n",
              " 'tick',\n",
              " 'yearThe',\n",
              " 'sanctuary',\n",
              " 'hotel',\n",
              " 'beautiful',\n",
              " 'best',\n",
              " 'location',\n",
              " 'want',\n",
              " 'stay',\n",
              " 'hustle',\n",
              " 'bustle',\n",
              " 'city',\n",
              " 'Loved',\n",
              " 'fact',\n",
              " 'close',\n",
              " 'Central',\n",
              " 'made',\n",
              " 'even',\n",
              " 'better',\n",
              " 'cold',\n",
              " 'morning',\n",
              " 'winter',\n",
              " 'walksThe',\n",
              " 'staff',\n",
              " 'friendly',\n",
              " 'food',\n",
              " 'restaurant',\n",
              " 'amazingI',\n",
              " 'would',\n",
              " 'highly',\n",
              " 'recommend',\n",
              " 'sushiWe',\n",
              " 'also',\n",
              " 'spent',\n",
              " 'New',\n",
              " 'Years',\n",
              " 'rooftop',\n",
              " 'bar',\n",
              " 'lovely',\n",
              " 'finish',\n",
              " 'holidayI',\n",
              " 'would',\n",
              " 'highly',\n",
              " 'recommend',\n",
              " 'hotel',\n",
              " 'staycation',\n",
              " 'relax',\n",
              " 'couple',\n",
              " 'day',\n",
              " 'glad',\n",
              " 'chose',\n",
              " 'hotel',\n",
              " 'real',\n",
              " 'hidden',\n",
              " 'gem',\n",
              " 'Times',\n",
              " 'Square',\n",
              " 'real',\n",
              " 'New',\n",
              " 'Yorker',\n",
              " 'always',\n",
              " 'avoid',\n",
              " 'area',\n",
              " 'Room',\n",
              " 'small',\n",
              " 'pretty',\n",
              " 'standard',\n",
              " 'NY',\n",
              " 'hotel',\n",
              " 'make',\n",
              " 'great',\n",
              " 'use',\n",
              " 'space',\n",
              " 'Buffet',\n",
              " 'breakfast',\n",
              " 'also',\n",
              " 'pretty',\n",
              " 'good',\n",
              " 'skip',\n",
              " 'rooftopopen',\n",
              " 'winter',\n",
              " 'covered',\n",
              " 'good',\n",
              " 'music',\n",
              " 'eats',\n",
              " 'gym',\n",
              " 'pass',\n",
              " 'gym',\n",
              " 'within',\n",
              " 'walking',\n",
              " 'distance',\n",
              " 'visit',\n",
              " 'since',\n",
              " 'close',\n",
              " 'enough',\n",
              " 'cold',\n",
              " 'winter',\n",
              " 'morning',\n",
              " 'Would',\n",
              " 'recommend',\n",
              " 'staying',\n",
              " 'rd',\n",
              " 'visit',\n",
              " 'back',\n",
              " 'New',\n",
              " 'York',\n",
              " 'time',\n",
              " 'Christmas',\n",
              " 'stayed',\n",
              " 'Sanctuary',\n",
              " 'rd',\n",
              " 'time',\n",
              " 'everything',\n",
              " 'superb',\n",
              " 'Nothing',\n",
              " 'much',\n",
              " 'trouble',\n",
              " 'room',\n",
              " 'lovely',\n",
              " 'location',\n",
              " 'perfect',\n",
              " 'staff',\n",
              " 'amazingJimmy',\n",
              " 'STAR',\n",
              " 'team',\n",
              " 'absolutely',\n",
              " 'brilliant',\n",
              " 'booked',\n",
              " 'restaurant',\n",
              " 'recommended',\n",
              " 'prior',\n",
              " 'u',\n",
              " 'arriving',\n",
              " 'helped',\n",
              " 'u',\n",
              " 'anyway',\n",
              " 'couldIf',\n",
              " 'visiting',\n",
              " 'New',\n",
              " 'York',\n",
              " 'stay',\n",
              " 'hotel',\n",
              " 'everything',\n",
              " 'need',\n",
              " 'perfect',\n",
              " 'location',\n",
              " 'right',\n",
              " 'around',\n",
              " 'corner',\n",
              " 'Times',\n",
              " 'Square',\n",
              " 'husband',\n",
              " 'along',\n",
              " 'two',\n",
              " 'child',\n",
              " 'wonderful',\n",
              " 'stay',\n",
              " 'Sanctuary',\n",
              " 'hotel',\n",
              " 'NYC',\n",
              " 'front',\n",
              " 'desk',\n",
              " 'staff',\n",
              " 'friendly',\n",
              " 'helpful',\n",
              " 'time',\n",
              " 'room',\n",
              " 'clean',\n",
              " 'small',\n",
              " 'room',\n",
              " 'quite',\n",
              " 'throughout',\n",
              " 'day',\n",
              " 'overnight',\n",
              " 'would',\n",
              " 'definitely',\n",
              " 'stay',\n",
              " 'booked',\n",
              " 'cozy',\n",
              " 'queen',\n",
              " 'room',\n",
              " 'little',\n",
              " 'small',\n",
              " 'couple',\n",
              " 'worked',\n",
              " 'fine',\n",
              " 'u',\n",
              " 'hotel',\n",
              " 'cozy',\n",
              " 'clean',\n",
              " 'rooftop',\n",
              " 'bar',\n",
              " 'nice',\n",
              " 'location',\n",
              " 'perfect',\n",
              " 'staff',\n",
              " 'accommodating',\n",
              " 'friendly',\n",
              " 'highly',\n",
              " 'recommend',\n",
              " 'stay',\n",
              " 'hotel',\n",
              " 'low',\n",
              " 'lighting',\n",
              " 'keep',\n",
              " 'mind',\n",
              " 'stay',\n",
              " 'interior',\n",
              " 'room',\n",
              " 'noise',\n",
              " 'issue',\n",
              " 'wife',\n",
              " 'spent',\n",
              " 'night',\n",
              " 'Sanctuary',\n",
              " 'Hotel',\n",
              " 'Christmas',\n",
              " 'location',\n",
              " 'excellent',\n",
              " 'block',\n",
              " 'away',\n",
              " 'MoMa',\n",
              " 'Rockefeller',\n",
              " 'center',\n",
              " 'Timesquare',\n",
              " 'service',\n",
              " 'nice',\n",
              " 'helpfulThe',\n",
              " 'room',\n",
              " 'small',\n",
              " 'cozy',\n",
              " 'pretty',\n",
              " 'quiet',\n",
              " 'directly',\n",
              " 'street',\n",
              " 'service',\n",
              " 'location',\n",
              " 'excellent',\n",
              " 'enjoyed',\n",
              " 'Hotel',\n",
              " 'peaceful',\n",
              " 'environment',\n",
              " 'Rooftop',\n",
              " 'restaurant',\n",
              " 'enjoyable',\n",
              " 'place',\n",
              " 'eat',\n",
              " 'talk',\n",
              " 'Close',\n",
              " 'Timesquare',\n",
              " 'Rockefeller',\n",
              " 'center',\n",
              " 'definitely',\n",
              " 'book',\n",
              " 'Hotel',\n",
              " 'fifth',\n",
              " 'time',\n",
              " 'visiting',\n",
              " 'Sanctuary',\n",
              " 'Hotel',\n",
              " 'New',\n",
              " 'York',\n",
              " 'City',\n",
              " 'wife',\n",
              " 'truly',\n",
              " 'love',\n",
              " 'fantastic',\n",
              " 'hotel',\n",
              " 'perfect',\n",
              " 'location',\n",
              " 'activity',\n",
              " 'planned',\n",
              " 'room',\n",
              " 'gorgeous',\n",
              " 'staff',\n",
              " 'truly',\n",
              " 'outstanding',\n",
              " 'go',\n",
              " 'way',\n",
              " 'ensure',\n",
              " 'hotel',\n",
              " 'stay',\n",
              " 'amazing',\n",
              " 'enjoyed',\n",
              " 'excellent',\n",
              " 'breakfast',\n",
              " 'staff',\n",
              " 'hosting',\n",
              " 'fantastic',\n",
              " 'definitely',\n",
              " 'stay',\n",
              " 'Thanks',\n",
              " 'pleasantly',\n",
              " 'surprised',\n",
              " 'hotel',\n",
              " 'close',\n",
              " 'noise',\n",
              " 'bustle',\n",
              " 'Times',\n",
              " 'Square',\n",
              " 'truly',\n",
              " 'sanctuary',\n",
              " 'experience',\n",
              " 'friendliness',\n",
              " 'helpfulness',\n",
              " 'front',\n",
              " 'desk',\n",
              " 'bell',\n",
              " 'service',\n",
              " 'peaceful',\n",
              " 'beautiful',\n",
              " 'surroundings',\n",
              " 'amazing',\n",
              " 'hotel',\n",
              " 'restaurant',\n",
              " 'first',\n",
              " 'class',\n",
              " 'dinner',\n",
              " 'breakfast',\n",
              " 'great',\n",
              " 'room',\n",
              " 'although',\n",
              " 'small',\n",
              " 'comfortable',\n",
              " 'efficient',\n",
              " 'pack',\n",
              " 'great',\n",
              " 'deal',\n",
              " 'small',\n",
              " 'property',\n",
              " 'never',\n",
              " 'make',\n",
              " 'feel',\n",
              " 'crowded',\n",
              " 'Definitely',\n",
              " 'one',\n",
              " 'best',\n",
              " 'hotel',\n",
              " 'experience',\n",
              " 'great',\n",
              " 'experience',\n",
              " 'hotel',\n",
              " 'close',\n",
              " 'Times',\n",
              " 'Square',\n",
              " 'NBC',\n",
              " 'Studios',\n",
              " 'Rockefeller',\n",
              " 'Center',\n",
              " 'Empire',\n",
              " 'State',\n",
              " 'Building',\n",
              " 'hotel',\n",
              " 'clean',\n",
              " 'substantial',\n",
              " 'breakfast',\n",
              " 'provided',\n",
              " 'room',\n",
              " 'clean',\n",
              " 'cozy',\n",
              " 'staff',\n",
              " 'knowledgeable',\n",
              " 'friendly',\n",
              " 'satisfied',\n",
              " 'definitely',\n",
              " 'go',\n",
              " 'back',\n",
              " 'stay',\n",
              " 'Sanctuary',\n",
              " 'Christmas',\n",
              " 'weekend',\n",
              " 'wonderfulThe',\n",
              " 'room',\n",
              " 'bit',\n",
              " 'smaller',\n",
              " 'expected',\n",
              " 'however',\n",
              " 'staff',\n",
              " 'cordial',\n",
              " 'polite',\n",
              " 'helpful',\n",
              " 'encountered',\n",
              " 'anywhere',\n",
              " 'doorman',\n",
              " 'reception',\n",
              " 'restaurant',\n",
              " 'staffWould',\n",
              " 'hesitate',\n",
              " 'recommend',\n",
              " 'arrived',\n",
              " 'hotel',\n",
              " 'around',\n",
              " 'checked',\n",
              " 'twice',\n",
              " 'front',\n",
              " 'desk',\n",
              " 'status',\n",
              " 'pm',\n",
              " 'young',\n",
              " 'guy',\n",
              " 'said',\n",
              " 'would',\n",
              " 'come',\n",
              " 'let',\n",
              " 'know',\n",
              " 'status',\n",
              " 'room',\n",
              " 'never',\n",
              " 'came',\n",
              " 'back',\n",
              " 'typically',\n",
              " 'patient',\n",
              " 'person',\n",
              " 'swear',\n",
              " 'God',\n",
              " 'never',\n",
              " 'write',\n",
              " 'review',\n",
              " 'worst',\n",
              " 'experience',\n",
              " 'life',\n",
              " 'wait',\n",
              " 'time',\n",
              " 'customer',\n",
              " 'service',\n",
              " 'must',\n",
              " 'say',\n",
              " 'generally',\n",
              " 'like',\n",
              " 'patronize',\n",
              " 'boutique',\n",
              " 'hotel',\n",
              " 'However',\n",
              " 'one',\n",
              " 'worst',\n",
              " 'hotel',\n",
              " 'ever',\n",
              " 'stayed',\n",
              " 'Admittedly',\n",
              " 'time',\n",
              " 'chose',\n",
              " 'visit',\n",
              " 'considered',\n",
              " 'high',\n",
              " 'season',\n",
              " 'second',\n",
              " 'week',\n",
              " 'December',\n",
              " 'however',\n",
              " 'rate',\n",
              " 'charge',\n",
              " 'hotel',\n",
              " 'get',\n",
              " 'simply',\n",
              " 'outrageousTo',\n",
              " 'say',\n",
              " 'room',\n",
              " 'small',\n",
              " 'understatement',\n",
              " 'barely',\n",
              " 'room',\n",
              " 'suitcase',\n",
              " 'seasoned',\n",
              " 'traveler',\n",
              " 'dont',\n",
              " 'needuse',\n",
              " 'large',\n",
              " 'suitcase',\n",
              " 'night',\n",
              " 'stay',\n",
              " 'queen',\n",
              " 'bed',\n",
              " 'platform',\n",
              " 'style',\n",
              " 'small',\n",
              " 'desk',\n",
              " 'mini',\n",
              " 'bar',\n",
              " 'outdated',\n",
              " 'television',\n",
              " 'wall',\n",
              " 'modern',\n",
              " 'day',\n",
              " 'flat',\n",
              " 'screen',\n",
              " 'item',\n",
              " 'roomvery',\n",
              " 'small',\n",
              " 'space',\n",
              " 'walk',\n",
              " 'closet',\n",
              " 'width',\n",
              " 'suitcase',\n",
              " 'standing',\n",
              " 'upThe',\n",
              " 'room',\n",
              " 'decor',\n",
              " 'darkbrown',\n",
              " 'carpet',\n",
              " 'concern',\n",
              " 'since',\n",
              " 'cant',\n",
              " 'see',\n",
              " 'dirt',\n",
              " 'clearlyand',\n",
              " 'know',\n",
              " 'dirt',\n",
              " 'apparent',\n",
              " 'stain',\n",
              " 'roman',\n",
              " 'shade',\n",
              " 'room',\n",
              " 'furnishing',\n",
              " 'definitely',\n",
              " 'seen',\n",
              " 'better',\n",
              " 'daysold',\n",
              " 'show',\n",
              " 'significant',\n",
              " 'sign',\n",
              " 'wear',\n",
              " 'hype',\n",
              " 'website',\n",
              " 'leaf',\n",
              " 'believe',\n",
              " 'amazing',\n",
              " 'experience',\n",
              " 'room',\n",
              " 'roof',\n",
              " 'top',\n",
              " 'bar',\n",
              " 'live',\n",
              " 'expectation',\n",
              " 'even',\n",
              " 'advertisement',\n",
              " 'positive',\n",
              " 'thing',\n",
              " 'property',\n",
              " 'going',\n",
              " 'employee',\n",
              " 'Really',\n",
              " 'helpful',\n",
              " 'friendly',\n",
              " 'groupfrom',\n",
              " 'level',\n",
              " 'engagementHOWEVER',\n",
              " 'would',\n",
              " 'never',\n",
              " 'stay',\n",
              " 'property',\n",
              " 'know',\n",
              " 'get',\n",
              " 'much',\n",
              " 'larger',\n",
              " 'cleaner',\n",
              " 'room',\n",
              " 'elsewhere',\n",
              " 'especially',\n",
              " 'rate',\n",
              " 'place',\n",
              " 'charging',\n",
              " 'travel',\n",
              " 'ny',\n",
              " 'lot',\n",
              " 'hotel',\n",
              " 'normally',\n",
              " 'stay',\n",
              " 'unusual',\n",
              " 'try',\n",
              " 'something',\n",
              " 'new',\n",
              " 'tend',\n",
              " 'like',\n",
              " 'boutique',\n",
              " 'hotel',\n",
              " 'case',\n",
              " 'room',\n",
              " 'expensive',\n",
              " 'even',\n",
              " 'NY',\n",
              " 'standard',\n",
              " 'smallest',\n",
              " 'room',\n",
              " 'outside',\n",
              " 'Asia',\n",
              " 'room',\n",
              " 'desk',\n",
              " 'chair',\n",
              " 'bathroom',\n",
              " 'directly',\n",
              " 'adjacent',\n",
              " 'bed',\n",
              " 'looking',\n",
              " 'brick',\n",
              " 'wall',\n",
              " 'light',\n",
              " 'well',\n",
              " 'could',\n",
              " 'almost',\n",
              " 'touch',\n",
              " 'shower',\n",
              " 'bed',\n",
              " 'decor',\n",
              " 'unusual',\n",
              " 'noir',\n",
              " 'sure',\n",
              " 'trendy',\n",
              " 'really',\n",
              " 'like',\n",
              " 'Great',\n",
              " 'location',\n",
              " 'people',\n",
              " 'super',\n",
              " 'helpful',\n",
              " 'see',\n",
              " 'review',\n",
              " 'differ',\n",
              " 'others',\n",
              " 'probably',\n",
              " 'back',\n",
              " 'regular',\n",
              " 'spot',\n",
              " 'next',\n",
              " 'time',\n",
              " 'Ie',\n",
              " 'coming',\n",
              " 'year',\n",
              " 'bc',\n",
              " 'fam',\n",
              " 'parade',\n",
              " 'Wonderful',\n",
              " 'place',\n",
              " 'skip',\n",
              " 'Thanksgiving',\n",
              " 'Covid',\n",
              " 'parade',\n",
              " 'restriction',\n",
              " 'back',\n",
              " 'Japanese',\n",
              " 'restaurant',\n",
              " 'daily',\n",
              " 'breakfast',\n",
              " 'wonderful',\n",
              " 'convenient',\n",
              " 'fabulous',\n",
              " 'stay',\n",
              " 'Sanctuary',\n",
              " 'Staff',\n",
              " 'friendly',\n",
              " 'helpful',\n",
              " 'really',\n",
              " 'go',\n",
              " 'way',\n",
              " 'Rooms',\n",
              " 'nice',\n",
              " 'clean',\n",
              " 'great',\n",
              " 'shower',\n",
              " 'Breakfast',\n",
              " 'great',\n",
              " 'selection',\n",
              " 'ok',\n",
              " 'nice',\n",
              " 'enough',\n",
              " 'would',\n",
              " 'say',\n",
              " 'good',\n",
              " 'would',\n",
              " 'get',\n",
              " 'Hotel',\n",
              " 'NewYork',\n",
              " 'included',\n",
              " 'price',\n",
              " 'Restaurant',\n",
              " 'food',\n",
              " 'good',\n",
              " 'bit',\n",
              " 'priceyLocation',\n",
              " 'absolutely',\n",
              " 'Fantastic',\n",
              " 'really',\n",
              " 'recommend',\n",
              " 'Sanctuary',\n",
              " 'alone',\n",
              " 'rest',\n",
              " 'bonus',\n",
              " 'hotel',\n",
              " 'superb',\n",
              " 'every',\n",
              " 'wayThe',\n",
              " 'location',\n",
              " 'Times',\n",
              " 'Square',\n",
              " 'perfect',\n",
              " 'whole',\n",
              " 'team',\n",
              " 'fantastic',\n",
              " 'room',\n",
              " 'cleaned',\n",
              " 'daily',\n",
              " 'breakfast',\n",
              " 'superb',\n",
              " 'bar',\n",
              " 'great',\n",
              " 'cant',\n",
              " 'praise',\n",
              " 'enough',\n",
              " 'disappointed',\n",
              " 'stay',\n",
              " 'Monday',\n",
              " 'Nov',\n",
              " 'Friday',\n",
              " 'Nov',\n",
              " 'Sanctuary',\n",
              " 'Kingsize',\n",
              " 'deluxe',\n",
              " 'room',\n",
              " 'thanksgiving',\n",
              " 'Fantastic',\n",
              " 'amazing',\n",
              " 'luved',\n",
              " 'every',\n",
              " 'minute',\n",
              " 'stay',\n",
              " 'bed',\n",
              " 'enormous',\n",
              " 'staff',\n",
              " 'wonderful',\n",
              " 'location',\n",
              " 'perfect',\n",
              " 'base',\n",
              " 'explore',\n",
              " 'NYC',\n",
              " 'Highly',\n",
              " 'recommend',\n",
              " 'hotel',\n",
              " 'nd',\n",
              " 'visit',\n",
              " 'first',\n",
              " 'standard',\n",
              " 'slipped',\n",
              " 'love',\n",
              " 'hotel',\n",
              " 'dont',\n",
              " 'typically',\n",
              " 'leave',\n",
              " 'comment',\n",
              " 'say',\n",
              " 'coziest',\n",
              " 'place',\n",
              " 'far',\n",
              " 'Times',\n",
              " 'Square',\n",
              " 'area',\n",
              " 'Great',\n",
              " 'place',\n",
              " 'seek',\n",
              " 'quiet',\n",
              " 'comfortable',\n",
              " 'relax',\n",
              " 'center',\n",
              " 'BTW',\n",
              " 'Douglas',\n",
              " 'Danny',\n",
              " 'helpful',\n",
              " 'thanks',\n",
              " 'guy',\n",
              " 'returned',\n",
              " 'birthday',\n",
              " 'visiting',\n",
              " 'last',\n",
              " 'summer',\n",
              " 'love',\n",
              " 'sanctuary',\n",
              " 'great',\n",
              " 'setting',\n",
              " 'short',\n",
              " 'walk',\n",
              " 'bustle',\n",
              " 'Times',\n",
              " 'Square',\n",
              " 'greatest',\n",
              " 'staff',\n",
              " 'nothing',\n",
              " 'much',\n",
              " 'trouble',\n",
              " 'stayed',\n",
              " 'BB',\n",
              " 'booking',\n",
              " 'breakfast',\n",
              " 'continental',\n",
              " 'hot',\n",
              " 'food',\n",
              " 'door',\n",
              " 'staff',\n",
              " 'amazing',\n",
              " 'helpful',\n",
              " 'luggage',\n",
              " 'friendly',\n",
              " 'shall',\n",
              " 'back',\n",
              " 'next',\n",
              " 'year',\n",
              " 'promise',\n",
              " 'Cool',\n",
              " 'entrance',\n",
              " 'bar',\n",
              " 'dont',\n",
              " 'overcome',\n",
              " 'street',\n",
              " 'noise',\n",
              " 'small',\n",
              " 'room',\n",
              " 'Even',\n",
              " 'NYC',\n",
              " 'standard',\n",
              " 'room',\n",
              " 'exceptionally',\n",
              " 'small',\n",
              " 'room',\n",
              " 'th',\n",
              " 'floor',\n",
              " 'street',\n",
              " 'side',\n",
              " 'loud',\n",
              " 'Homeless',\n",
              " 'outside',\n",
              " 'nearby',\n",
              " 'th',\n",
              " 'street',\n",
              " 'Church',\n",
              " 'construction',\n",
              " 'half',\n",
              " 'building',\n",
              " 'also',\n",
              " 'disruptive',\n",
              " 'Lastly',\n",
              " 'towel',\n",
              " 'old',\n",
              " 'thread',\n",
              " 'bare',\n",
              " 'spot',\n",
              " 'staff',\n",
              " 'friendly',\n",
              " 'serviceoriented',\n",
              " 'dealing',\n",
              " 'impossible',\n",
              " 'condition',\n",
              " 'room',\n",
              " 'small',\n",
              " 'well',\n",
              " 'put',\n",
              " 'together',\n",
              " 'staff',\n",
              " 'super',\n",
              " 'friendly',\n",
              " 'restaurant',\n",
              " 'location',\n",
              " 'also',\n",
              " 'great',\n",
              " 'Really',\n",
              " 'positive',\n",
              " 'surprised',\n",
              " 'breakfast',\n",
              " 'pretty',\n",
              " 'good',\n",
              " 'sushi',\n",
              " 'place',\n",
              " 'awesome',\n",
              " 'stayed',\n",
              " 'recent',\n",
              " 'trip',\n",
              " 'NYC',\n",
              " 'enjoyed',\n",
              " 'staying',\n",
              " 'hotel',\n",
              " 'reminded',\n",
              " 'cozy',\n",
              " 'boutique',\n",
              " 'type',\n",
              " 'hotel',\n",
              " 'stayed',\n",
              " 'Europe',\n",
              " 'indeed',\n",
              " 'many',\n",
              " 'fellow',\n",
              " 'guest',\n",
              " 'European',\n",
              " 'Talking',\n",
              " 'point',\n",
              " 'Staff',\n",
              " 'friendly',\n",
              " 'helpful',\n",
              " 'moment',\n",
              " 'taxi',\n",
              " 'dropped',\n",
              " 'left',\n",
              " 'airport',\n",
              " 'Hotel',\n",
              " 'appears',\n",
              " 'recently',\n",
              " 'updated',\n",
              " 'modern',\n",
              " 'shower',\n",
              " 'decor',\n",
              " 'furnishing',\n",
              " 'throughout',\n",
              " 'entire',\n",
              " 'hotel',\n",
              " 'nice',\n",
              " 'fresh',\n",
              " 'overpowering',\n",
              " 'smell',\n",
              " 'Convenient',\n",
              " 'location',\n",
              " 'theatre',\n",
              " 'district',\n",
              " 'time',\n",
              " 'square',\n",
              " 'shopping',\n",
              " 'continental',\n",
              " 'breakfast',\n",
              " 'nice',\n",
              " 'includes',\n",
              " 'hot',\n",
              " 'item',\n",
              " 'egg',\n",
              " 'bacon',\n",
              " 'andor',\n",
              " 'sausage',\n",
              " 'coffee',\n",
              " ...]"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hotel1_review_after_stemming"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3640f275",
      "metadata": {
        "id": "3640f275",
        "outputId": "f6fe385c-659a-4004-f9a6-a5772b07c5ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1 1 1 ... 1 1 1]]\n"
          ]
        }
      ],
      "source": [
        "# Hotel 1 pre : TFIDF\n",
        "# turn after prepocessing word into a sentence again\n",
        "H1_pre_NADJ = [' '.join([str(c) for c in h1_pre_NADJ])]\n",
        "\n",
        "\n",
        "# Hotel 2 pre covid -tfidf\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "cv= CountVectorizer(analyzer = \"word\",stop_words = ['time','hotel','square','squar','york'],lowercase=True)\n",
        "# convert the documents into a document-term matrix\n",
        "TermFreq_Matrix = cv.fit_transform(H1_pre_NADJ)\n",
        "print(TermFreq_Matrix.todense())\n",
        "\n",
        "#shape of count vector: 2 docs and 11 unique words (columns)!\n",
        "#print(TermFreq_Matrix.shape)\n",
        "# (2, 11)\n",
        "\n",
        "tokens = cv.get_feature_names()\n",
        "# print(tokens)\n",
        "\n",
        "# ['also', 'football', 'game', 'john', 'likes', 'mary', 'match', 'movies', 'to', 'too', 'watch']\n",
        "\n",
        "# create an index for each row\n",
        "doc_names = ['Doc{:d}'.format(idx) for idx, _ in enumerate(TermFreq_Matrix)]\n",
        "df_frequency = pd.DataFrame(data=TermFreq_Matrix.toarray(), index=doc_names,\n",
        "                  columns=tokens)\n",
        "#print(df)\n",
        "\n",
        "\n",
        "# TF-IDF\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True)\n",
        "tfidf_transformer.fit(TermFreq_Matrix)\n",
        "\n",
        "#TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)\n",
        "\n",
        "# print idf values\n",
        "df_idf_pre = pd.DataFrame(tfidf_transformer.idf_, index=tokens,columns=[\"idf_weights\"])\n",
        "\n",
        "#df_idf\n",
        " \n",
        "# tf-idf scores\n",
        "tf_idf_vector=tfidf_transformer.transform(TermFreq_Matrix)\n",
        " \n",
        "#get tfidf vector for first document\n",
        "first_document_vector=tf_idf_vector[0]\n",
        " \n",
        "#print the scores\n",
        "df_tfidf_h1_NADJ = pd.DataFrame(first_document_vector.T.todense(), index=tokens, columns=[\"tf-idf\"])\n",
        "df_tfidf_h1_NADJ = df_tfidf_h1_NADJ.sort_values(by=[\"tf-idf\"],ascending=False)\n",
        "\n",
        "# dataframe clean\n",
        "df_frequency2 = df_frequency.transpose()\n",
        "df_frequency2['term'] = df_frequency2.index\n",
        "df_frequency2.reset_index(drop=True, inplace=True)\n",
        "df_idf2 = df_idf_pre.copy()\n",
        "df_idf2['term'] = df_idf_pre.index\n",
        "df_idf2.reset_index(drop=True, inplace=True)\n",
        "df_tfidf_h1_NADJ2=df_tfidf_h1_NADJ.sort_index()\n",
        "#df_tfidf_h1_NADJ2 = df_tfidf_h1_NADJ2.sort_index()\n",
        "df_tfidf_h1_NADJ2['term']  = df_tfidf_h1_NADJ2.index\n",
        "df_tfidf_h1_NADJ2.reset_index(drop=True, inplace=True)\n",
        "\n",
        "H1_pre_result = pd.concat([df_frequency2,df_idf2,df_tfidf_h1_NADJ2],axis = 1,ignore_index = True)\n",
        "H1_pre_result2 = H1_pre_result.copy()\n",
        "\n",
        "\n",
        "H1_pre_result2  = H1_pre_result2.rename(columns={0: \"Frequency\",\n",
        "                                 1:\"term\",2:\"IDF\",3:\"term2\",4:\"TF-IDF(Normalized)\",5:\"term3\"})\n",
        "H1_pre_result3 = H1_pre_result2.drop(columns = ['term2','term3'])\n",
        "# relocate columns\n",
        "H1_pre_result4 = H1_pre_result3 [['term', 'Frequency', 'IDF', 'TF-IDF(Normalized)']]\n",
        "#H1_result4 \n",
        "H1_pre_result5 = H1_pre_result4.sort_values('TF-IDF(Normalized)',ascending = False)\n",
        "H1_pre_result5['Rank_TFIDF'] = H1_pre_result5['TF-IDF(Normalized)'].rank(ascending=False,method='max')\n",
        "\n",
        "H1_pre_result5.to_csv('Hotel1_pre_Terms.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8452ba69",
      "metadata": {
        "id": "8452ba69"
      },
      "outputs": [],
      "source": [
        "# hotel1 aft review pre-processing\n",
        "# These block treat a hotel brand as one document\n",
        "# remove number and punctuation\n",
        "# ref : https://www.geeksforgeeks.org/python-compute-the-frequency-of-words-after-removing-stop-words-and-stemming/?ref=rp\n",
        "\n",
        "hotel1_aft_review_no_punctuations = []\n",
        "\n",
        "\n",
        "for review in H1_aft_review:\n",
        "    hotel1_aft_review_no_punctuations.append( re.sub('[^a-zA-Z ]+', '', str(review)))\n",
        "    \n",
        "    \n",
        "# tokenize\n",
        "#nltk.download('punkt')\n",
        "#from nltk.tokenize import word_tokenize\n",
        "hotel1_review_aft_tokenizing = []\n",
        "for review in hotel1_aft_review_no_punctuations:\n",
        "    hotel1_review_aft_tokenizing.append(word_tokenize(review))\n",
        "\n",
        "# remove stop words\n",
        "#from nltk.corpus import stopwords\n",
        "#nltk.download('stopwords')\n",
        "#nltk_stop_words = stopwords.words('english')\n",
        "\n",
        "hotel1_review_aft_without_stopword = []\n",
        "\n",
        "for review in hotel1_review_aft_tokenizing :\n",
        "    for text in review:\n",
        "        if text.lower() not in nltk_stop_words :\n",
        "            hotel1_review_aft_without_stopword.append(text)\n",
        "        \n",
        "# stemming \n",
        "#from nltk.stem.porter import PorterStemmer\n",
        "#stemmer = PorterStemmer()\n",
        "hotel1_review_aft_after_stemming = []\n",
        "\n",
        "#for review in hotel1_review_without_stopword:\n",
        "#    hotel1_review_after_stemming.append(stemmer.stem(review))\n",
        "\n",
        "# ref:https://www.analyticsvidhya.com/blog/2020/11/text-cleaning-nltk-library/\n",
        "#nltk.download('wordnet')\n",
        "#wn = nltk.WordNetLemmatizer()\n",
        "for review in hotel1_review_aft_without_stopword:\n",
        "    hotel1_review_aft_after_stemming.append(wn.lemmatize(review))\n",
        "\n",
        "\n",
        "    \n",
        "# pos-tagging\n",
        "# ref : https://thinkinfi.com/extract-custom-keywords-using-nltk-pos-tagger-in-python/\n",
        "#from nltk import pos_tag\n",
        "#nltk.download('averaged_perceptron_tagger')\n",
        "hotel1_review_aft_pos_tagging = pos_tag(hotel1_review_aft_after_stemming)\n",
        "hotel1_N_aft = [word for word,pos in hotel1_review_aft_pos_tagging \\\n",
        "            if (pos == 'NN' or pos == 'NNP' or pos == 'NNS' or pos == 'NNPS')]\n",
        "hotel1_adj_aft = [word for word,pos in hotel1_review_aft_pos_tagging \\\n",
        "            if (pos == 'JJ' or pos == 'JJR' or pos == 'JJS' )]\n",
        "hotel1_verb_aft = [word for word,pos in hotel1_review_aft_pos_tagging \\\n",
        "            if (pos == 'VB' or pos == 'VBD' or pos == 'VBG' or pos == 'VBN'or pos == 'VBP'or pos == 'VBZ')]\n",
        "h1_aft_NADJ = [word for word,pos in hotel1_review_aft_pos_tagging \\\n",
        "            if (pos == 'NN' or pos == 'NNP' or pos == 'NNS' or pos == 'NNPS'or pos == 'JJ' or pos == 'JJR' or pos == 'JJS' )]\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "with open('hotel1_aft_all_word2.txt', 'w') as file:\n",
        "    file.writelines(\"%s\\n\" % line for line in hotel1_review_aft_after_stemming)\n",
        "with open('H1_aft_noun2.txt', 'w') as file:\n",
        "    file.writelines(\"%s\\n\" % line for line in hotel1_N_aft )\n",
        "with open('H1_aft_adj2.txt', 'w') as file:\n",
        "    file.writelines(\"%s\\n\" % line for line in hotel1_adj_aft )\n",
        "with open('H1_aft_ver2.txt', 'w') as file:\n",
        "    file.writelines(\"%s\\n\" % line for line in hotel1_verb_aft)\n",
        "with open('H1_aft_NADJ2.txt', 'w') as file:\n",
        "    file.writelines(\"%s\\n\" % line for line in h1_aft_NADJ)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c65a0b0e",
      "metadata": {
        "id": "c65a0b0e"
      },
      "outputs": [],
      "source": [
        "# Hotel 1 aft : TFIDF\n",
        "# turn after prepocessing word into a sentence again\n",
        "H1_aft_NADJ = [' '.join([str(c) for c in h1_aft_NADJ])]\n",
        "\n",
        "#from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "cv= CountVectorizer(analyzer = \"word\",stop_words = ['time','hotel','square','squar','york'],lowercase=True)\n",
        "# convert the documents into a document-term matrix\n",
        "TermFreq_Matrix = cv.fit_transform(H1_aft_NADJ)\n",
        "#print(TermFreq_Matrix.todense())\n",
        "\n",
        "tokens = cv.get_feature_names()\n",
        "# print(tokens)\n",
        "\n",
        "# ['also', 'football', 'game', 'john', 'likes', 'mary', 'match', 'movies', 'to', 'too', 'watch']\n",
        "\n",
        "# create an index for each row\n",
        "doc_names = ['Doc{:d}'.format(idx) for idx, _ in enumerate(TermFreq_Matrix)]\n",
        "df_frequency = pd.DataFrame(data=TermFreq_Matrix.toarray(), index=doc_names,\n",
        "                  columns=tokens)\n",
        "#print(df)\n",
        "\n",
        "\n",
        "# TF-IDF\n",
        "#from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True)\n",
        "tfidf_transformer.fit(TermFreq_Matrix)\n",
        "\n",
        "#TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)\n",
        "\n",
        "# print idf values\n",
        "df_idf_aft= pd.DataFrame(tfidf_transformer.idf_, index=tokens,columns=[\"idf_weights\"])\n",
        "\n",
        "#df_idf\n",
        " \n",
        "# tf-idf scores\n",
        "tf_idf_vector=tfidf_transformer.transform(TermFreq_Matrix)\n",
        " \n",
        "#get tfidf vector for first document\n",
        "first_document_vector=tf_idf_vector[0]\n",
        " \n",
        "#print the scores\n",
        "df_tfidf_h1_NADJ = pd.DataFrame(first_document_vector.T.todense(), index=tokens, columns=[\"tf-idf\"])\n",
        "df_tfidf_h1_NADJ = df_tfidf_h1_NADJ.sort_values(by=[\"tf-idf\"],ascending=False)\n",
        "\n",
        "# dataframe clean\n",
        "df_frequency2 = df_frequency.transpose()\n",
        "df_frequency2['term'] = df_frequency2.index\n",
        "df_frequency2.reset_index(drop=True, inplace=True)\n",
        "df_idf2 = df_idf_aft.copy()\n",
        "df_idf2['term'] = df_idf_aft.index\n",
        "df_idf2.reset_index(drop=True, inplace=True)\n",
        "df_tfidf_h1_NADJ2=df_tfidf_h1_NADJ.sort_index()\n",
        "\n",
        "df_tfidf_h1_NADJ2['term']  = df_tfidf_h1_NADJ2.index\n",
        "df_tfidf_h1_NADJ2.reset_index(drop=True, inplace=True)\n",
        "\n",
        "H1_aft_result = pd.concat([df_frequency2,df_idf2,df_tfidf_h1_NADJ2],axis = 1,ignore_index = True)\n",
        "H1_aft_result2 = H1_aft_result.copy()\n",
        "\n",
        "\n",
        "H1_aft_result2  = H1_aft_result2.rename(columns={0: \"Frequency\",\n",
        "                                 1:\"term\",2:\"IDF\",3:\"term2\",4:\"TF-IDF(Normalized)\",5:\"term3\"})\n",
        "H1_aft_result3 = H1_aft_result2.drop(columns = ['term2','term3'])\n",
        "# relocate columns\n",
        "H1_aft_result4 = H1_aft_result3 [['term', 'Frequency', 'IDF', 'TF-IDF(Normalized)']]\n",
        "#H1_result4 \n",
        "H1_aft_result5 = H1_aft_result4.sort_values('TF-IDF(Normalized)',ascending = False)\n",
        "H1_aft_result5['Rank_TFIDF'] = H1_aft_result5['TF-IDF(Normalized)'].rank(ascending=False,method='max')\n",
        "\n",
        "H1_aft_result5.to_csv('Hotel1_aft_Terms.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae3dca40",
      "metadata": {
        "id": "ae3dca40"
      },
      "outputs": [],
      "source": [
        "# hotel2 pre review pre-processing\n",
        "# These block treat a hotel brand as one document\n",
        "# remove number and punctuation\n",
        "# ref : https://www.geeksforgeeks.org/python-compute-the-frequency-of-words-after-removing-stop-words-and-stemming/?ref=rp\n",
        "\n",
        "hotel2_pre_review_no_punctuations = []\n",
        "\n",
        "\n",
        "for review in H2_pre_review:\n",
        "    hotel2_pre_review_no_punctuations.append( re.sub('[^a-zA-Z ]+', '', str(review)))\n",
        "    \n",
        "    \n",
        "# tokenize\n",
        "#nltk.download('punkt')\n",
        "#from nltk.tokenize import word_tokenize\n",
        "hotel2_review_tokenizing = []\n",
        "for review in hotel2_pre_review_no_punctuations:\n",
        "    hotel2_review_tokenizing.append(word_tokenize(review))\n",
        "\n",
        "# remove stop words\n",
        "#from nltk.corpus import stopwords\n",
        "#nltk.download('stopwords')\n",
        "#nltk_stop_words = stopwords.words('english')\n",
        "\n",
        "hotel2_review_without_stopword = []\n",
        "\n",
        "for review in hotel2_review_tokenizing :\n",
        "    for text in review:\n",
        "        if text.lower() not in nltk_stop_words :\n",
        "            hotel2_review_without_stopword.append(text)\n",
        "        \n",
        "# stemming \n",
        "#from nltk.stem.porter import PorterStemmer\n",
        "#stemmer = PorterStemmer()\n",
        "hotel2_review_after_stemming = []\n",
        "\n",
        "#for review in hotel1_review_without_stopword:\n",
        "#    hotel1_review_after_stemming.append(stemmer.stem(review))\n",
        "\n",
        "# ref:https://www.analyticsvidhya.com/blog/2020/11/text-cleaning-nltk-library/\n",
        "#nltk.download('wordnet')\n",
        "#wn = nltk.WordNetLemmatizer()\n",
        "for review in hotel2_review_without_stopword:\n",
        "    hotel2_review_after_stemming.append(wn.lemmatize(review))\n",
        "\n",
        "\n",
        "    \n",
        "# pos-tagging\n",
        "# ref : https://thinkinfi.com/extract-custom-keywords-using-nltk-pos-tagger-in-python/\n",
        "#from nltk import pos_tag\n",
        "#nltk.download('averaged_perceptron_tagger')\n",
        "hotel2_review_pos_tagging = pos_tag(hotel2_review_after_stemming)\n",
        "hotel2_N = [word for word,pos in hotel2_review_pos_tagging \\\n",
        "            if (pos == 'NN' or pos == 'NNP' or pos == 'NNS' or pos == 'NNPS')]\n",
        "hotel2_adj = [word for word,pos in hotel2_review_pos_tagging \\\n",
        "            if (pos == 'JJ' or pos == 'JJR' or pos == 'JJS' )]\n",
        "hotel2_verb = [word for word,pos in hotel2_review_pos_tagging \\\n",
        "            if (pos == 'VB' or pos == 'VBD' or pos == 'VBG' or pos == 'VBN'or pos == 'VBP'or pos == 'VBZ')]\n",
        "h2_pre_NADJ = [word for word,pos in hotel2_review_pos_tagging \\\n",
        "            if (pos == 'NN' or pos == 'NNP' or pos == 'NNS' or pos == 'NNPS'or pos == 'JJ' or pos == 'JJR' or pos == 'JJS' )]\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "with open('hotel2_pre_all_word2.txt', 'w') as file:\n",
        "    file.writelines(\"%s\\n\" % line for line in hotel2_review_after_stemming)\n",
        "with open('H2_pre_noun2.txt', 'w') as file:\n",
        "    file.writelines(\"%s\\n\" % line for line in hotel2_N )\n",
        "with open('H2_pre_adj2.txt', 'w') as file:\n",
        "    file.writelines(\"%s\\n\" % line for line in hotel2_adj )\n",
        "with open('H2_pre_ver2.txt', 'w') as file:\n",
        "    file.writelines(\"%s\\n\" % line for line in hotel2_verb)\n",
        "with open('H2_pre_NADJ2.txt', 'w') as file:\n",
        "    file.writelines(\"%s\\n\" % line for line in h2_pre_NADJ)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59d5f014",
      "metadata": {
        "id": "59d5f014",
        "outputId": "0afc702e-9b5e-470a-f006-182f41f51aa2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 3  2 51 ...  3  1  4]]\n"
          ]
        }
      ],
      "source": [
        "# Hotel 2 pre : TFIDF\n",
        "# turn after prepocessing word into a sentence again\n",
        "H2_pre_NADJ = [' '.join([str(c) for c in h2_pre_NADJ])]\n",
        "\n",
        "#from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "cv= CountVectorizer(analyzer = \"word\",stop_words = ['time','hotel','square','squar','york'],lowercase=True)\n",
        "# convert the documents into a document-term matrix\n",
        "TermFreq_Matrix = cv.fit_transform(H2_pre_NADJ)\n",
        "print(TermFreq_Matrix.todense())\n",
        "\n",
        "#shape of count vector: 2 docs and 11 unique words (columns)!\n",
        "#print(TermFreq_Matrix.shape)\n",
        "# (2, 11)\n",
        "\n",
        "tokens = cv.get_feature_names()\n",
        "# print(tokens)\n",
        "\n",
        "# ['also', 'football', 'game', 'john', 'likes', 'mary', 'match', 'movies', 'to', 'too', 'watch']\n",
        "\n",
        "# create an index for each row\n",
        "doc_names = ['Doc{:d}'.format(idx) for idx, _ in enumerate(TermFreq_Matrix)]\n",
        "df_frequency = pd.DataFrame(data=TermFreq_Matrix.toarray(), index=doc_names,\n",
        "                  columns=tokens)\n",
        "#print(df)\n",
        "\n",
        "\n",
        "# TF-IDF\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True)\n",
        "tfidf_transformer.fit(TermFreq_Matrix)\n",
        "\n",
        "#TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)\n",
        "\n",
        "# print idf values\n",
        "df_idf_pre  = pd.DataFrame(tfidf_transformer.idf_, index=tokens,columns=[\"idf_weights\"])\n",
        "\n",
        "#df_idf\n",
        " \n",
        "# tf-idf scores\n",
        "tf_idf_vector=tfidf_transformer.transform(TermFreq_Matrix)\n",
        " \n",
        "#get tfidf vector for first document\n",
        "first_document_vector=tf_idf_vector[0]\n",
        " \n",
        "#print the scores\n",
        "df_tfidf_h2_NADJ = pd.DataFrame(first_document_vector.T.todense(), index=tokens, columns=[\"tf-idf\"])\n",
        "df_tfidf_h2_NADJ = df_tfidf_h2_NADJ.sort_values(by=[\"tf-idf\"],ascending=False)\n",
        "\n",
        "# dataframe clean\n",
        "df_frequency2 = df_frequency.transpose()\n",
        "df_frequency2['term'] = df_frequency2.index\n",
        "df_frequency2.reset_index(drop=True, inplace=True)\n",
        "df_idf2 = df_idf_pre.copy()\n",
        "df_idf2['term'] = df_idf_pre.index\n",
        "df_idf2.reset_index(drop=True, inplace=True)\n",
        "df_tfidf_h2_NADJ2=df_tfidf_h2_NADJ.sort_index()\n",
        "#df_tfidf_h1_NADJ2 = df_tfidf_h1_NADJ2.sort_index()\n",
        "df_tfidf_h2_NADJ2['term']  = df_tfidf_h2_NADJ2.index\n",
        "df_tfidf_h2_NADJ2.reset_index(drop=True, inplace=True)\n",
        "\n",
        "H2_pre_result = pd.concat([df_frequency2,df_idf2,df_tfidf_h2_NADJ2],axis = 1,ignore_index = True)\n",
        "H2_pre_result2 = H2_pre_result.copy()\n",
        "\n",
        "\n",
        "H2_pre_result2  = H2_pre_result2.rename(columns={0: \"Frequency\",\n",
        "                                 1:\"term\",2:\"IDF\",3:\"term2\",4:\"TF-IDF(Normalized)\",5:\"term3\"})\n",
        "H2_pre_result3 = H2_pre_result2.drop(columns = ['term2','term3'])\n",
        "# relocate columns\n",
        "H2_pre_result4 = H2_pre_result3 [['term', 'Frequency', 'IDF', 'TF-IDF(Normalized)']]\n",
        "#H1_result4 \n",
        "H2_pre_result5 = H2_pre_result4.sort_values('TF-IDF(Normalized)',ascending = False)\n",
        "H2_pre_result5['Rank_TFIDF'] = H2_pre_result5['TF-IDF(Normalized)'].rank(ascending=False,method='max')\n",
        "\n",
        "H2_pre_result5.to_csv('Hotel2_pre_Terms.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac58f143",
      "metadata": {
        "id": "ac58f143"
      },
      "outputs": [],
      "source": [
        "# hotel2 aft review pre-processing\n",
        "# These block treat a hotel brand as one document\n",
        "# remove number and punctuation\n",
        "# ref : https://www.geeksforgeeks.org/python-compute-the-frequency-of-words-after-removing-stop-words-and-stemming/?ref=rp\n",
        "\n",
        "hotel2_aft_review_no_punctuations = []\n",
        "\n",
        "\n",
        "for review in H2_aft_review:\n",
        "    hotel2_aft_review_no_punctuations.append( re.sub('[^a-zA-Z ]+', '', str(review)))\n",
        "    \n",
        "    \n",
        "# tokenize\n",
        "#nltk.download('punkt')\n",
        "#from nltk.tokenize import word_tokenize\n",
        "hotel2_review_aft_tokenizing = []\n",
        "for review in hotel2_aft_review_no_punctuations:\n",
        "    hotel2_review_aft_tokenizing.append(word_tokenize(review))\n",
        "\n",
        "# remove stop words\n",
        "#from nltk.corpus import stopwords\n",
        "#nltk.download('stopwords')\n",
        "#nltk_stop_words = stopwords.words('english')\n",
        "\n",
        "hotel2_review_aft_without_stopword = []\n",
        "\n",
        "for review in hotel2_review_aft_tokenizing :\n",
        "    for text in review:\n",
        "        if text.lower() not in nltk_stop_words :\n",
        "            hotel2_review_aft_without_stopword.append(text)\n",
        "        \n",
        "# stemming \n",
        "#from nltk.stem.porter import PorterStemmer\n",
        "#stemmer = PorterStemmer()\n",
        "hotel2_review_aft_after_stemming = []\n",
        "\n",
        "#for review in hotel1_review_without_stopword:\n",
        "#    hotel1_review_after_stemming.append(stemmer.stem(review))\n",
        "\n",
        "# ref:https://www.analyticsvidhya.com/blog/2020/11/text-cleaning-nltk-library/\n",
        "#nltk.download('wordnet')\n",
        "#wn = nltk.WordNetLemmatizer()\n",
        "for review in hotel2_review_aft_without_stopword:\n",
        "    hotel2_review_aft_after_stemming.append(wn.lemmatize(review))\n",
        "\n",
        "\n",
        "    \n",
        "# pos-tagging\n",
        "# ref : https://thinkinfi.com/extract-custom-keywords-using-nltk-pos-tagger-in-python/\n",
        "#from nltk import pos_tag\n",
        "#nltk.download('averaged_perceptron_tagger')\n",
        "hotel2_review_aft_pos_tagging = pos_tag(hotel2_review_aft_after_stemming)\n",
        "hotel2_N_aft = [word for word,pos in hotel2_review_aft_pos_tagging \\\n",
        "            if (pos == 'NN' or pos == 'NNP' or pos == 'NNS' or pos == 'NNPS')]\n",
        "hotel2_adj_aft = [word for word,pos in hotel2_review_aft_pos_tagging \\\n",
        "            if (pos == 'JJ' or pos == 'JJR' or pos == 'JJS' )]\n",
        "hotel2_verb_aft = [word for word,pos in hotel2_review_aft_pos_tagging \\\n",
        "            if (pos == 'VB' or pos == 'VBD' or pos == 'VBG' or pos == 'VBN'or pos == 'VBP'or pos == 'VBZ')]\n",
        "h2_aft_NADJ = [word for word,pos in hotel2_review_aft_pos_tagging \\\n",
        "            if (pos == 'NN' or pos == 'NNP' or pos == 'NNS' or pos == 'NNPS'or pos == 'JJ' or pos == 'JJR' or pos == 'JJS' )]\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "with open('hotel2_aft_all_word2.txt', 'w') as file:\n",
        "    file.writelines(\"%s\\n\" % line for line in hotel2_review_aft_after_stemming)\n",
        "with open('H2_aft_noun2.txt', 'w') as file:\n",
        "    file.writelines(\"%s\\n\" % line for line in hotel2_N_aft )\n",
        "with open('H2_aft_adj2.txt', 'w') as file:\n",
        "    file.writelines(\"%s\\n\" % line for line in hotel2_adj_aft )\n",
        "with open('H2_aft_ver2.txt', 'w') as file:\n",
        "    file.writelines(\"%s\\n\" % line for line in hotel2_verb_aft)\n",
        "with open('H2_aft_NADJ2.txt', 'w') as file:\n",
        "    file.writelines(\"%s\\n\" % line for line in h2_aft_NADJ)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6328f8b",
      "metadata": {
        "id": "c6328f8b",
        "outputId": "c39cf344-658e-4040-a18c-4fa4139eaad9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 2 44  2 ...  6  2  5]]\n"
          ]
        }
      ],
      "source": [
        "# Hotel 2 aft : TFIDF\n",
        "# turn after prepocessing word into a sentence again\n",
        "H2_aft_NADJ = [' '.join([str(c) for c in h2_aft_NADJ])]\n",
        "\n",
        "#from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "cv= CountVectorizer(analyzer = \"word\",stop_words =['time','hotel','square','squar','york'],lowercase=True)\n",
        "# convert the documents into a document-term matrix\n",
        "TermFreq_Matrix = cv.fit_transform(H2_aft_NADJ)\n",
        "print(TermFreq_Matrix.todense())\n",
        "\n",
        "#shape of count vector: 2 docs and 11 unique words (columns)!\n",
        "#print(TermFreq_Matrix.shape)\n",
        "# (2, 11)\n",
        "\n",
        "tokens = cv.get_feature_names()\n",
        "# print(tokens)\n",
        "\n",
        "# ['also', 'football', 'game', 'john', 'likes', 'mary', 'match', 'movies', 'to', 'too', 'watch']\n",
        "\n",
        "# create an index for each row\n",
        "doc_names = ['Doc{:d}'.format(idx) for idx, _ in enumerate(TermFreq_Matrix)]\n",
        "df_frequency = pd.DataFrame(data=TermFreq_Matrix.toarray(), index=doc_names,\n",
        "                  columns=tokens)\n",
        "#print(df)\n",
        "\n",
        "\n",
        "# TF-IDF\n",
        "#from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True)\n",
        "tfidf_transformer.fit(TermFreq_Matrix)\n",
        "\n",
        "#TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)\n",
        "\n",
        "# print idf values\n",
        "df_idf_aft= pd.DataFrame(tfidf_transformer.idf_, index=tokens,columns=[\"idf_weights\"])\n",
        "\n",
        "#df_idf\n",
        " \n",
        "# tf-idf scores\n",
        "tf_idf_vector=tfidf_transformer.transform(TermFreq_Matrix)\n",
        " \n",
        "#get tfidf vector for first document\n",
        "first_document_vector=tf_idf_vector[0]\n",
        " \n",
        "#print the scores\n",
        "df_tfidf_h2_NADJ = pd.DataFrame(first_document_vector.T.todense(), index=tokens, columns=[\"tf-idf\"])\n",
        "df_tfidf_h2_NADJ = df_tfidf_h2_NADJ.sort_values(by=[\"tf-idf\"],ascending=False)\n",
        "\n",
        "# dataframe clean\n",
        "df_frequency2 = df_frequency.transpose()\n",
        "df_frequency2['term'] = df_frequency2.index\n",
        "df_frequency2.reset_index(drop=True, inplace=True)\n",
        "df_idf2 = df_idf_aft.copy()\n",
        "df_idf2['term'] = df_idf_aft.index\n",
        "df_idf2.reset_index(drop=True, inplace=True)\n",
        "df_tfidf_h2_NADJ2=df_tfidf_h2_NADJ.sort_index()\n",
        "\n",
        "df_tfidf_h2_NADJ2['term']  = df_tfidf_h2_NADJ2.index\n",
        "df_tfidf_h2_NADJ2.reset_index(drop=True, inplace=True)\n",
        "\n",
        "H2_aft_result = pd.concat([df_frequency2,df_idf2,df_tfidf_h2_NADJ2],axis = 1,ignore_index = True)\n",
        "H2_aft_result2 = H2_aft_result.copy()\n",
        "\n",
        "\n",
        "H2_aft_result2  = H2_aft_result2.rename(columns={0: \"Frequency\",\n",
        "                                 1:\"term\",2:\"IDF\",3:\"term2\",4:\"TF-IDF(Normalized)\",5:\"term3\"})\n",
        "H2_aft_result3 = H2_aft_result2.drop(columns = ['term2','term3'])\n",
        "# relocate columns\n",
        "H2_aft_result4 = H2_aft_result3 [['term', 'Frequency', 'IDF', 'TF-IDF(Normalized)']]\n",
        "#H1_result4 \n",
        "H2_aft_result5 = H2_aft_result4.sort_values('TF-IDF(Normalized)',ascending = False)\n",
        "H2_aft_result5['Rank_TFIDF'] = H2_aft_result5['TF-IDF(Normalized)'].rank(ascending=False,method='max')\n",
        "\n",
        "H2_aft_result5.to_csv('Hotel2_aft_Terms.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4645dc7",
      "metadata": {
        "id": "d4645dc7"
      },
      "outputs": [],
      "source": [
        "# hotel3 pre review pre-processing\n",
        "# These block treat a hotel brand as one document\n",
        "# remove number and punctuation\n",
        "# ref : https://www.geeksforgeeks.org/python-compute-the-frequency-of-words-after-removing-stop-words-and-stemming/?ref=rp\n",
        "\n",
        "hotel3_pre_review_no_punctuations = []\n",
        "\n",
        "\n",
        "for review in H3_pre_review:\n",
        "    hotel3_pre_review_no_punctuations.append( re.sub('[^a-zA-Z ]+', '', str(review)))\n",
        "    \n",
        "    \n",
        "# tokenize\n",
        "#nltk.download('punkt')\n",
        "#from nltk.tokenize import word_tokenize\n",
        "hotel3_review_tokenizing = []\n",
        "for review in hotel3_pre_review_no_punctuations:\n",
        "    hotel3_review_tokenizing.append(word_tokenize(review))\n",
        "\n",
        "# remove stop words\n",
        "#from nltk.corpus import stopwords\n",
        "#nltk.download('stopwords')\n",
        "#nltk_stop_words = stopwords.words('english')\n",
        "\n",
        "hotel3_review_without_stopword = []\n",
        "\n",
        "for review in hotel3_review_tokenizing :\n",
        "    for text in review:\n",
        "        if text.lower() not in nltk_stop_words :\n",
        "            hotel3_review_without_stopword.append(text)\n",
        "        \n",
        "# stemming \n",
        "#from nltk.stem.porter import PorterStemmer\n",
        "#stemmer = PorterStemmer()\n",
        "hotel3_review_after_stemming = []\n",
        "\n",
        "#for review in hotel1_review_without_stopword:\n",
        "#    hotel1_review_after_stemming.append(stemmer.stem(review))\n",
        "\n",
        "# ref:https://www.analyticsvidhya.com/blog/2020/11/text-cleaning-nltk-library/\n",
        "#nltk.download('wordnet')\n",
        "#wn = nltk.WordNetLemmatizer()\n",
        "for review in hotel3_review_without_stopword:\n",
        "    hotel3_review_after_stemming.append(wn.lemmatize(review))\n",
        "\n",
        "\n",
        "    \n",
        "# pos-tagging\n",
        "# ref : https://thinkinfi.com/extract-custom-keywords-using-nltk-pos-tagger-in-python/\n",
        "#from nltk import pos_tag\n",
        "#nltk.download('averaged_perceptron_tagger')\n",
        "hotel3_review_pos_tagging = pos_tag(hotel3_review_after_stemming)\n",
        "hotel3_N = [word for word,pos in hotel3_review_pos_tagging \\\n",
        "            if (pos == 'NN' or pos == 'NNP' or pos == 'NNS' or pos == 'NNPS')]\n",
        "hotel3_adj = [word for word,pos in hotel3_review_pos_tagging \\\n",
        "            if (pos == 'JJ' or pos == 'JJR' or pos == 'JJS' )]\n",
        "hotel3_verb = [word for word,pos in hotel3_review_pos_tagging \\\n",
        "            if (pos == 'VB' or pos == 'VBD' or pos == 'VBG' or pos == 'VBN'or pos == 'VBP'or pos == 'VBZ')]\n",
        "h3_pre_NADJ = [word for word,pos in hotel3_review_pos_tagging \\\n",
        "            if (pos == 'NN' or pos == 'NNP' or pos == 'NNS' or pos == 'NNPS'or pos == 'JJ' or pos == 'JJR' or pos == 'JJS' )]\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "with open('hotel3_pre_all_word2.txt', 'w') as file:\n",
        "    file.writelines(\"%s\\n\" % line for line in hotel3_review_after_stemming)\n",
        "with open('H3_pre_noun2.txt', 'w') as file:\n",
        "    file.writelines(\"%s\\n\" % line for line in hotel3_N )\n",
        "with open('H3_pre_adj2.txt', 'w') as file:\n",
        "    file.writelines(\"%s\\n\" % line for line in hotel3_adj )\n",
        "with open('H3_pre_ver2.txt', 'w') as file:\n",
        "    file.writelines(\"%s\\n\" % line for line in hotel3_verb)\n",
        "with open('H3_pre_NADJ2.txt', 'w') as file:\n",
        "    file.writelines(\"%s\\n\" % line for line in h3_pre_NADJ)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1b0f938",
      "metadata": {
        "id": "e1b0f938",
        "outputId": "ed8e040f-7976-477a-cbea-5b41a20db557"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 3  1  1 ...  1 13  1]]\n"
          ]
        }
      ],
      "source": [
        "# Hotel 3 pre : TFIDF\n",
        "# turn after prepocessing word into a sentence again\n",
        "H3_pre_NADJ = [' '.join([str(c) for c in h3_pre_NADJ])]\n",
        "\n",
        "#from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "cv= CountVectorizer(analyzer = \"word\",stop_words = ['time','hotel','square','squar','york'],lowercase=True)\n",
        "# convert the documents into a document-term matrix\n",
        "TermFreq_Matrix = cv.fit_transform(H3_pre_NADJ)\n",
        "print(TermFreq_Matrix.todense())\n",
        "\n",
        "#shape of count vector: 2 docs and 11 unique words (columns)!\n",
        "#print(TermFreq_Matrix.shape)\n",
        "# (2, 11)\n",
        "\n",
        "tokens = cv.get_feature_names()\n",
        "# print(tokens)\n",
        "\n",
        "# ['also', 'football', 'game', 'john', 'likes', 'mary', 'match', 'movies', 'to', 'too', 'watch']\n",
        "\n",
        "# create an index for each row\n",
        "doc_names = ['Doc{:d}'.format(idx) for idx, _ in enumerate(TermFreq_Matrix)]\n",
        "df_frequency = pd.DataFrame(data=TermFreq_Matrix.toarray(), index=doc_names,\n",
        "                  columns=tokens)\n",
        "#print(df)\n",
        "\n",
        "\n",
        "# TF-IDF\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True)\n",
        "tfidf_transformer.fit(TermFreq_Matrix)\n",
        "\n",
        "#TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)\n",
        "\n",
        "# print idf values\n",
        "df_idf_pre = pd.DataFrame(tfidf_transformer.idf_, index=tokens,columns=[\"idf_weights\"])\n",
        "\n",
        "#df_idf\n",
        " \n",
        "# tf-idf scores\n",
        "tf_idf_vector=tfidf_transformer.transform(TermFreq_Matrix)\n",
        " \n",
        "#get tfidf vector for first document\n",
        "first_document_vector=tf_idf_vector[0]\n",
        " \n",
        "#print the scores\n",
        "df_tfidf_h3_NADJ = pd.DataFrame(first_document_vector.T.todense(), index=tokens, columns=[\"tf-idf\"])\n",
        "df_tfidf_h3_NADJ = df_tfidf_h3_NADJ.sort_values(by=[\"tf-idf\"],ascending=False)\n",
        "\n",
        "# dataframe clean\n",
        "df_frequency2 = df_frequency.transpose()\n",
        "df_frequency2['term'] = df_frequency2.index\n",
        "df_frequency2.reset_index(drop=True, inplace=True)\n",
        "df_idf2 = df_idf_pre.copy()\n",
        "df_idf2['term'] = df_idf_pre.index\n",
        "df_idf2.reset_index(drop=True, inplace=True)\n",
        "df_tfidf_h3_NADJ2=df_tfidf_h3_NADJ.sort_index()\n",
        "#df_tfidf_h1_NADJ2 = df_tfidf_h1_NADJ2.sort_index()\n",
        "df_tfidf_h3_NADJ2['term']  = df_tfidf_h3_NADJ2.index\n",
        "df_tfidf_h3_NADJ2.reset_index(drop=True, inplace=True)\n",
        "\n",
        "H3_pre_result = pd.concat([df_frequency2,df_idf2,df_tfidf_h3_NADJ2],axis = 1,ignore_index = True)\n",
        "H3_pre_result2 = H3_pre_result.copy()\n",
        "\n",
        "\n",
        "H3_pre_result2  = H3_pre_result2.rename(columns={0: \"Frequency\",\n",
        "                                 1:\"term\",2:\"IDF\",3:\"term2\",4:\"TF-IDF(Normalized)\",5:\"term3\"})\n",
        "H3_pre_result3 = H3_pre_result2.drop(columns = ['term2','term3'])\n",
        "# relocate columns\n",
        "H3_pre_result4 = H3_pre_result3 [['term', 'Frequency', 'IDF', 'TF-IDF(Normalized)']]\n",
        "#H1_result4 \n",
        "H3_pre_result5 = H3_pre_result4.sort_values('TF-IDF(Normalized)',ascending = False)\n",
        "H3_pre_result5['Rank_TFIDF'] = H3_pre_result5['TF-IDF(Normalized)'].rank(ascending=False,method='max')\n",
        "\n",
        "H3_pre_result5.to_csv('Hotel3_pre_Terms.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a3c2e15",
      "metadata": {
        "id": "9a3c2e15"
      },
      "outputs": [],
      "source": [
        "# hotel3 aft review pre-processing\n",
        "# These block treat a hotel brand as one document\n",
        "# remove number and punctuation\n",
        "# ref : https://www.geeksforgeeks.org/python-compute-the-frequency-of-words-after-removing-stop-words-and-stemming/?ref=rp\n",
        "\n",
        "hotel3_aft_review_no_punctuations = []\n",
        "\n",
        "\n",
        "for review in H3_aft_review:\n",
        "    hotel3_aft_review_no_punctuations.append( re.sub('[^a-zA-Z ]+', '', str(review)))\n",
        "    \n",
        "    \n",
        "# tokenize\n",
        "#nltk.download('punkt')\n",
        "#from nltk.tokenize import word_tokenize\n",
        "hotel3_review_aft_tokenizing = []\n",
        "for review in hotel3_aft_review_no_punctuations:\n",
        "    hotel3_review_aft_tokenizing.append(word_tokenize(review))\n",
        "\n",
        "# remove stop words\n",
        "#from nltk.corpus import stopwords\n",
        "#nltk.download('stopwords')\n",
        "#nltk_stop_words = stopwords.words('english')\n",
        "\n",
        "hotel3_review_aft_without_stopword = []\n",
        "\n",
        "for review in hotel3_review_aft_tokenizing :\n",
        "    for text in review:\n",
        "        if text.lower() not in nltk_stop_words :\n",
        "            hotel3_review_aft_without_stopword.append(text)\n",
        "        \n",
        "# stemming \n",
        "#from nltk.stem.porter import PorterStemmer\n",
        "#stemmer = PorterStemmer()\n",
        "hotel3_review_aft_after_stemming = []\n",
        "\n",
        "#for review in hotel1_review_without_stopword:\n",
        "#    hotel1_review_after_stemming.append(stemmer.stem(review))\n",
        "\n",
        "# ref:https://www.analyticsvidhya.com/blog/2020/11/text-cleaning-nltk-library/\n",
        "#nltk.download('wordnet')\n",
        "#wn = nltk.WordNetLemmatizer()\n",
        "for review in hotel3_review_aft_without_stopword:\n",
        "    hotel3_review_aft_after_stemming.append(wn.lemmatize(review))\n",
        "\n",
        "\n",
        "    \n",
        "# pos-tagging\n",
        "# ref : https://thinkinfi.com/extract-custom-keywords-using-nltk-pos-tagger-in-python/\n",
        "#from nltk import pos_tag\n",
        "#nltk.download('averaged_perceptron_tagger')\n",
        "hotel3_review_aft_pos_tagging = pos_tag(hotel3_review_aft_after_stemming)\n",
        "hotel3_N_aft = [word for word,pos in hotel3_review_aft_pos_tagging \\\n",
        "            if (pos == 'NN' or pos == 'NNP' or pos == 'NNS' or pos == 'NNPS')]\n",
        "hotel3_adj_aft = [word for word,pos in hotel3_review_aft_pos_tagging \\\n",
        "            if (pos == 'JJ' or pos == 'JJR' or pos == 'JJS' )]\n",
        "hotel3_verb_aft = [word for word,pos in hotel3_review_aft_pos_tagging \\\n",
        "            if (pos == 'VB' or pos == 'VBD' or pos == 'VBG' or pos == 'VBN'or pos == 'VBP'or pos == 'VBZ')]\n",
        "h3_aft_NADJ = [word for word,pos in hotel3_review_aft_pos_tagging \\\n",
        "            if (pos == 'NN' or pos == 'NNP' or pos == 'NNS' or pos == 'NNPS'or pos == 'JJ' or pos == 'JJR' or pos == 'JJS' )]\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "with open('hotel3_aft_all_word2.txt', 'w') as file:\n",
        "    file.writelines(\"%s\\n\" % line for line in hotel3_review_aft_after_stemming)\n",
        "with open('H3_aft_noun2.txt', 'w') as file:\n",
        "    file.writelines(\"%s\\n\" % line for line in hotel3_N_aft )\n",
        "with open('H3_aft_adj2.txt', 'w') as file:\n",
        "    file.writelines(\"%s\\n\" % line for line in hotel3_adj_aft )\n",
        "with open('H3_aft_ver2.txt', 'w') as file:\n",
        "    file.writelines(\"%s\\n\" % line for line in hotel3_verb_aft)\n",
        "with open('H3_aft_NADJ2.txt', 'w') as file:\n",
        "    file.writelines(\"%s\\n\" % line for line in h3_aft_NADJ)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84df23c6",
      "metadata": {
        "id": "84df23c6",
        "outputId": "b9aa4c07-b338-46de-8d19-02d8b45cfa68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 1 20  1 ...  2  1  1]]\n"
          ]
        }
      ],
      "source": [
        "# Hotel 3aft : TFIDF\n",
        "# turn after prepocessing word into a sentence again\n",
        "H3_aft_NADJ = [' '.join([str(c) for c in h3_aft_NADJ])]\n",
        "\n",
        "#from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "cv= CountVectorizer(analyzer = \"word\",stop_words =['time','hotel','square','squar','york'],lowercase=True)\n",
        "# convert the documents into a document-term matrix\n",
        "TermFreq_Matrix = cv.fit_transform(H3_aft_NADJ)\n",
        "print(TermFreq_Matrix.todense())\n",
        "\n",
        "#shape of count vector: 2 docs and 11 unique words (columns)!\n",
        "#print(TermFreq_Matrix.shape)\n",
        "# (2, 11)\n",
        "\n",
        "tokens = cv.get_feature_names()\n",
        "# print(tokens)\n",
        "\n",
        "# ['also', 'football', 'game', 'john', 'likes', 'mary', 'match', 'movies', 'to', 'too', 'watch']\n",
        "\n",
        "# create an index for each row\n",
        "doc_names = ['Doc{:d}'.format(idx) for idx, _ in enumerate(TermFreq_Matrix)]\n",
        "df_frequency = pd.DataFrame(data=TermFreq_Matrix.toarray(), index=doc_names,\n",
        "                  columns=tokens)\n",
        "#print(df)\n",
        "\n",
        "\n",
        "# TF-IDF\n",
        "#from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True)\n",
        "tfidf_transformer.fit(TermFreq_Matrix)\n",
        "\n",
        "#TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)\n",
        "\n",
        "# print idf values\n",
        "df_idf_aft= pd.DataFrame(tfidf_transformer.idf_, index=tokens,columns=[\"idf_weights\"])\n",
        "\n",
        "#df_idf\n",
        " \n",
        "# tf-idf scores\n",
        "tf_idf_vector=tfidf_transformer.transform(TermFreq_Matrix)\n",
        " \n",
        "#get tfidf vector for first document\n",
        "first_document_vector=tf_idf_vector[0]\n",
        " \n",
        "#print the scores\n",
        "df_tfidf_h3_NADJ = pd.DataFrame(first_document_vector.T.todense(), index=tokens, columns=[\"tf-idf\"])\n",
        "df_tfidf_h3_NADJ = df_tfidf_h3_NADJ.sort_values(by=[\"tf-idf\"],ascending=False)\n",
        "\n",
        "# dataframe clean\n",
        "df_frequency2 = df_frequency.transpose()\n",
        "df_frequency2['term'] = df_frequency2.index\n",
        "df_frequency2.reset_index(drop=True, inplace=True)\n",
        "df_idf2 = df_idf_aft.copy()\n",
        "df_idf2['term'] = df_idf_aft.index\n",
        "df_idf2.reset_index(drop=True, inplace=True)\n",
        "df_tfidf_h3_NADJ2=df_tfidf_h3_NADJ.sort_index()\n",
        "\n",
        "df_tfidf_h3_NADJ2['term']  = df_tfidf_h3_NADJ2.index\n",
        "df_tfidf_h3_NADJ2.reset_index(drop=True, inplace=True)\n",
        "\n",
        "H3_aft_result = pd.concat([df_frequency2,df_idf2,df_tfidf_h3_NADJ2],axis = 1,ignore_index = True)\n",
        "H3_aft_result2 = H3_aft_result.copy()\n",
        "\n",
        "\n",
        "H3_aft_result2  = H3_aft_result2.rename(columns={0: \"Frequency\",\n",
        "                                 1:\"term\",2:\"IDF\",3:\"term2\",4:\"TF-IDF(Normalized)\",5:\"term3\"})\n",
        "H3_aft_result3 = H3_aft_result2.drop(columns = ['term2','term3'])\n",
        "# relocate columns\n",
        "H3_aft_result4 = H3_aft_result3 [['term', 'Frequency', 'IDF', 'TF-IDF(Normalized)']]\n",
        "#H1_result4 \n",
        "H3_aft_result5 = H3_aft_result4.sort_values('TF-IDF(Normalized)',ascending = False)\n",
        "H3_aft_result5['Rank_TFIDF'] = H3_aft_result5['TF-IDF(Normalized)'].rank(ascending=False,method='max')\n",
        "\n",
        "H3_aft_result5.to_csv('Hotel3_aft_Ters2.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5fd60a1a",
      "metadata": {
        "id": "5fd60a1a"
      },
      "outputs": [],
      "source": [
        "# hotel4 pre review pre-processing\n",
        "# These block treat a hotel brand as one document\n",
        "# remove number and punctuation\n",
        "# ref : https://www.geeksforgeeks.org/python-compute-the-frequency-of-words-after-removing-stop-words-and-stemming/?ref=rp\n",
        "\n",
        "hotel4_pre_review_no_punctuations = []\n",
        "\n",
        "\n",
        "for review in H4_pre_review:\n",
        "    hotel4_pre_review_no_punctuations.append( re.sub('[^a-zA-Z ]+', '', str(review)))\n",
        "    \n",
        "    \n",
        "# tokenize\n",
        "#nltk.download('punkt')\n",
        "#from nltk.tokenize import word_tokenize\n",
        "hotel4_review_tokenizing = []\n",
        "for review in hotel4_pre_review_no_punctuations:\n",
        "    hotel4_review_tokenizing.append(word_tokenize(review))\n",
        "\n",
        "# remove stop words\n",
        "#from nltk.corpus import stopwords\n",
        "#nltk.download('stopwords')\n",
        "#nltk_stop_words = stopwords.words('english')\n",
        "\n",
        "hotel4_review_without_stopword = []\n",
        "\n",
        "for review in hotel4_review_tokenizing :\n",
        "    for text in review:\n",
        "        if text.lower() not in nltk_stop_words :\n",
        "            hotel4_review_without_stopword.append(text)\n",
        "        \n",
        "# stemming \n",
        "#from nltk.stem.porter import PorterStemmer\n",
        "#stemmer = PorterStemmer()\n",
        "hotel4_review_after_stemming = []\n",
        "\n",
        "#for review in hotel1_review_without_stopword:\n",
        "#    hotel1_review_after_stemming.append(stemmer.stem(review))\n",
        "\n",
        "# ref:https://www.analyticsvidhya.com/blog/2020/11/text-cleaning-nltk-library/\n",
        "#nltk.download('wordnet')\n",
        "#wn = nltk.WordNetLemmatizer()\n",
        "for review in hotel4_review_without_stopword:\n",
        "    hotel4_review_after_stemming.append(wn.lemmatize(review))\n",
        "\n",
        "\n",
        "    \n",
        "# pos-tagging\n",
        "# ref : https://thinkinfi.com/extract-custom-keywords-using-nltk-pos-tagger-in-python/\n",
        "#from nltk import pos_tag\n",
        "#nltk.download('averaged_perceptron_tagger')\n",
        "hotel4_review_pos_tagging = pos_tag(hotel4_review_after_stemming)\n",
        "hotel4_N = [word for word,pos in hotel4_review_pos_tagging \\\n",
        "            if (pos == 'NN' or pos == 'NNP' or pos == 'NNS' or pos == 'NNPS')]\n",
        "hotel4_adj = [word for word,pos in hotel4_review_pos_tagging \\\n",
        "            if (pos == 'JJ' or pos == 'JJR' or pos == 'JJS' )]\n",
        "hotel4_verb = [word for word,pos in hotel4_review_pos_tagging \\\n",
        "            if (pos == 'VB' or pos == 'VBD' or pos == 'VBG' or pos == 'VBN'or pos == 'VBP'or pos == 'VBZ')]\n",
        "h4_pre_NADJ = [word for word,pos in hotel4_review_pos_tagging \\\n",
        "            if (pos == 'NN' or pos == 'NNP' or pos == 'NNS' or pos == 'NNPS'or pos == 'JJ' or pos == 'JJR' or pos == 'JJS' )]\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "with open('hotel4_pre_all_word2.txt', 'w') as file:\n",
        "    file.writelines(\"%s\\n\" % line for line in hotel4_review_after_stemming)\n",
        "with open('H4_pre_noun2.txt', 'w') as file:\n",
        "    file.writelines(\"%s\\n\" % line for line in hotel4_N )\n",
        "with open('H4_pre_adj2.txt', 'w') as file:\n",
        "    file.writelines(\"%s\\n\" % line for line in hotel4_adj )\n",
        "with open('H4_pre_ver2.txt', 'w') as file:\n",
        "    file.writelines(\"%s\\n\" % line for line in hotel4_verb)\n",
        "with open('H4_pre_NADJ2.txt', 'w') as file:\n",
        "    file.writelines(\"%s\\n\" % line for line in h4_pre_NADJ)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7eeb4975",
      "metadata": {
        "id": "7eeb4975",
        "outputId": "db5f763b-61d2-4b86-97ca-31d1c0f0d66b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 3  1  1 ...  1 13  1]]\n"
          ]
        }
      ],
      "source": [
        "# Hotel 4 pre : TFIDF\n",
        "# turn after prepocessing word into a sentence again\n",
        "H4_pre_NADJ = [' '.join([str(c) for c in h4_pre_NADJ])]\n",
        "\n",
        "#from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "cv= CountVectorizer(analyzer = \"word\",stop_words = ['time','hotel','square','squar','york'],lowercase=True)\n",
        "# convert the documents into a document-term matrix\n",
        "TermFreq_Matrix = cv.fit_transform(H3_pre_NADJ)\n",
        "print(TermFreq_Matrix.todense())\n",
        "\n",
        "#shape of count vector: 2 docs and 11 unique words (columns)!\n",
        "#print(TermFreq_Matrix.shape)\n",
        "# (2, 11)\n",
        "\n",
        "tokens = cv.get_feature_names()\n",
        "# print(tokens)\n",
        "\n",
        "# ['also', 'football', 'game', 'john', 'likes', 'mary', 'match', 'movies', 'to', 'too', 'watch']\n",
        "\n",
        "# create an index for each row\n",
        "doc_names = ['Doc{:d}'.format(idx) for idx, _ in enumerate(TermFreq_Matrix)]\n",
        "df_frequency = pd.DataFrame(data=TermFreq_Matrix.toarray(), index=doc_names,\n",
        "                  columns=tokens)\n",
        "#print(df)\n",
        "\n",
        "\n",
        "# TF-IDF\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True)\n",
        "tfidf_transformer.fit(TermFreq_Matrix)\n",
        "\n",
        "#TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)\n",
        "\n",
        "# print idf values\n",
        "df_idf_pre = pd.DataFrame(tfidf_transformer.idf_, index=tokens,columns=[\"idf_weights\"])\n",
        "\n",
        "#df_idf\n",
        " \n",
        "# tf-idf scores\n",
        "tf_idf_vector=tfidf_transformer.transform(TermFreq_Matrix)\n",
        " \n",
        "#get tfidf vector for first document\n",
        "first_document_vector=tf_idf_vector[0]\n",
        " \n",
        "#print the scores\n",
        "df_tfidf_h4_NADJ = pd.DataFrame(first_document_vector.T.todense(), index=tokens, columns=[\"tf-idf\"])\n",
        "df_tfidf_h4_NADJ = df_tfidf_h4_NADJ.sort_values(by=[\"tf-idf\"],ascending=False)\n",
        "\n",
        "# dataframe clean\n",
        "df_frequency2 = df_frequency.transpose()\n",
        "df_frequency2['term'] = df_frequency2.index\n",
        "df_frequency2.reset_index(drop=True, inplace=True)\n",
        "df_idf2 = df_idf_pre.copy()\n",
        "df_idf2['term'] = df_idf_pre.index\n",
        "df_idf2.reset_index(drop=True, inplace=True)\n",
        "df_tfidf_h4_NADJ2=df_tfidf_h4_NADJ.sort_index()\n",
        "#df_tfidf_h1_NADJ2 = df_tfidf_h1_NADJ2.sort_index()\n",
        "df_tfidf_h4_NADJ2['term']  = df_tfidf_h4_NADJ2.index\n",
        "df_tfidf_h4_NADJ2.reset_index(drop=True, inplace=True)\n",
        "\n",
        "H4_pre_result = pd.concat([df_frequency2,df_idf2,df_tfidf_h4_NADJ2],axis = 1,ignore_index = True)\n",
        "H4_pre_result2 = H4_pre_result.copy()\n",
        "\n",
        "\n",
        "H4_pre_result2  = H4_pre_result2.rename(columns={0: \"Frequency\",\n",
        "                                 1:\"term\",2:\"IDF\",3:\"term2\",4:\"TF-IDF(Normalized)\",5:\"term3\"})\n",
        "H4_pre_result3 = H4_pre_result2.drop(columns = ['term2','term3'])\n",
        "# relocate columns\n",
        "H4_pre_result4 = H4_pre_result3 [['term', 'Frequency', 'IDF', 'TF-IDF(Normalized)']]\n",
        "#H1_result4 \n",
        "H4_pre_result5 = H4_pre_result4.sort_values('TF-IDF(Normalized)',ascending = False)\n",
        "H4_pre_result5['Rank_TFIDF'] = H4_pre_result5['TF-IDF(Normalized)'].rank(ascending=False,method='max')\n",
        "\n",
        "H4_pre_result5.to_csv('Hotel4_pre_Terms.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f809288",
      "metadata": {
        "id": "1f809288"
      },
      "outputs": [],
      "source": [
        "# hotel4 aft review pre-processing\n",
        "# These block treat a hotel brand as one document\n",
        "# remove number and punctuation\n",
        "# ref : https://www.geeksforgeeks.org/python-compute-the-frequency-of-words-after-removing-stop-words-and-stemming/?ref=rp\n",
        "\n",
        "hotel4_aft_review_no_punctuations = []\n",
        "\n",
        "\n",
        "for review in H4_aft_review:\n",
        "    hotel4_aft_review_no_punctuations.append( re.sub('[^a-zA-Z ]+', '', str(review)))\n",
        "    \n",
        "    \n",
        "# tokenize\n",
        "#nltk.download('punkt')\n",
        "#from nltk.tokenize import word_tokenize\n",
        "hotel4_review_aft_tokenizing = []\n",
        "for review in hotel4_aft_review_no_punctuations:\n",
        "    hotel4_review_aft_tokenizing.append(word_tokenize(review))\n",
        "\n",
        "# remove stop words\n",
        "#from nltk.corpus import stopwords\n",
        "#nltk.download('stopwords')\n",
        "#nltk_stop_words = stopwords.words('english')\n",
        "\n",
        "hotel4_review_aft_without_stopword = []\n",
        "\n",
        "for review in hotel4_review_aft_tokenizing :\n",
        "    for text in review:\n",
        "        if text.lower() not in nltk_stop_words :\n",
        "            hotel4_review_aft_without_stopword.append(text)\n",
        "        \n",
        "# stemming \n",
        "#from nltk.stem.porter import PorterStemmer\n",
        "#stemmer = PorterStemmer()\n",
        "hotel4_review_aft_after_stemming = []\n",
        "\n",
        "#for review in hotel1_review_without_stopword:\n",
        "#    hotel1_review_after_stemming.append(stemmer.stem(review))\n",
        "\n",
        "# ref:https://www.analyticsvidhya.com/blog/2020/11/text-cleaning-nltk-library/\n",
        "#nltk.download('wordnet')\n",
        "#wn = nltk.WordNetLemmatizer()\n",
        "for review in hotel4_review_aft_without_stopword:\n",
        "    hotel4_review_aft_after_stemming.append(wn.lemmatize(review))\n",
        "\n",
        "\n",
        "    \n",
        "# pos-tagging\n",
        "# ref : https://thinkinfi.com/extract-custom-keywords-using-nltk-pos-tagger-in-python/\n",
        "#from nltk import pos_tag\n",
        "#nltk.download('averaged_perceptron_tagger')\n",
        "hotel4_review_aft_pos_tagging = pos_tag(hotel4_review_aft_after_stemming)\n",
        "hotel4_N_aft = [word for word,pos in hotel4_review_aft_pos_tagging \\\n",
        "            if (pos == 'NN' or pos == 'NNP' or pos == 'NNS' or pos == 'NNPS')]\n",
        "hotel4_adj_aft = [word for word,pos in hotel4_review_aft_pos_tagging \\\n",
        "            if (pos == 'JJ' or pos == 'JJR' or pos == 'JJS' )]\n",
        "hotel4_verb_aft = [word for word,pos in hotel4_review_aft_pos_tagging \\\n",
        "            if (pos == 'VB' or pos == 'VBD' or pos == 'VBG' or pos == 'VBN'or pos == 'VBP'or pos == 'VBZ')]\n",
        "h4_aft_NADJ = [word for word,pos in hotel4_review_aft_pos_tagging \\\n",
        "            if (pos == 'NN' or pos == 'NNP' or pos == 'NNS' or pos == 'NNPS'or pos == 'JJ' or pos == 'JJR' or pos == 'JJS' )]\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "with open('hotel4_aft_all_word2.txt', 'w') as file:\n",
        "    file.writelines(\"%s\\n\" % line for line in hotel4_review_aft_after_stemming)\n",
        "with open('H4_aft_noun2.txt', 'w') as file:\n",
        "    file.writelines(\"%s\\n\" % line for line in hotel4_N_aft )\n",
        "with open('H4_aft_adj2.txt', 'w') as file:\n",
        "    file.writelines(\"%s\\n\" % line for line in hotel4_adj_aft )\n",
        "with open('H4_aft_ver2.txt', 'w') as file:\n",
        "    file.writelines(\"%s\\n\" % line for line in hotel4_verb_aft)\n",
        "with open('H4_aft_NADJ2.txt', 'w') as file:\n",
        "    file.writelines(\"%s\\n\" % line for line in h4_aft_NADJ)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49ac7222",
      "metadata": {
        "id": "49ac7222",
        "outputId": "f5acdb4a-f648-4923-a854-87f0640b5993"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 1 13  1 ...  1  1  1]]\n"
          ]
        }
      ],
      "source": [
        "# Hotel 4 aft : TFIDF\n",
        "# turn after prepocessing word into a sentence again\n",
        "H4_aft_NADJ = [' '.join([str(c) for c in h4_aft_NADJ])]\n",
        "\n",
        "#from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "cv= CountVectorizer(analyzer = \"word\",stop_words =['time','hotel','square','squar','york'],lowercase=True)\n",
        "# convert the documents into a document-term matrix\n",
        "TermFreq_Matrix = cv.fit_transform(H4_aft_NADJ)\n",
        "print(TermFreq_Matrix.todense())\n",
        "\n",
        "#shape of count vector: 2 docs and 11 unique words (columns)!\n",
        "#print(TermFreq_Matrix.shape)\n",
        "# (2, 11)\n",
        "\n",
        "tokens = cv.get_feature_names()\n",
        "# print(tokens)\n",
        "\n",
        "# ['also', 'football', 'game', 'john', 'likes', 'mary', 'match', 'movies', 'to', 'too', 'watch']\n",
        "\n",
        "# create an index for each row\n",
        "doc_names = ['Doc{:d}'.format(idx) for idx, _ in enumerate(TermFreq_Matrix)]\n",
        "df_frequency = pd.DataFrame(data=TermFreq_Matrix.toarray(), index=doc_names,\n",
        "                  columns=tokens)\n",
        "#print(df)\n",
        "\n",
        "\n",
        "# TF-IDF\n",
        "#from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True)\n",
        "tfidf_transformer.fit(TermFreq_Matrix)\n",
        "\n",
        "#TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)\n",
        "\n",
        "# print idf values\n",
        "df_idf_aft= pd.DataFrame(tfidf_transformer.idf_, index=tokens,columns=[\"idf_weights\"])\n",
        "\n",
        "#df_idf\n",
        " \n",
        "# tf-idf scores\n",
        "tf_idf_vector=tfidf_transformer.transform(TermFreq_Matrix)\n",
        " \n",
        "#get tfidf vector for first document\n",
        "first_document_vector=tf_idf_vector[0]\n",
        " \n",
        "#print the scores\n",
        "df_tfidf_h4_NADJ = pd.DataFrame(first_document_vector.T.todense(), index=tokens, columns=[\"tf-idf\"])\n",
        "df_tfidf_h4_NADJ = df_tfidf_h4_NADJ.sort_values(by=[\"tf-idf\"],ascending=False)\n",
        "\n",
        "# dataframe clean\n",
        "df_frequency2 = df_frequency.transpose()\n",
        "df_frequency2['term'] = df_frequency2.index\n",
        "df_frequency2.reset_index(drop=True, inplace=True)\n",
        "df_idf2 = df_idf_aft.copy()\n",
        "df_idf2['term'] = df_idf_aft.index\n",
        "df_idf2.reset_index(drop=True, inplace=True)\n",
        "df_tfidf_h4_NADJ2=df_tfidf_h4_NADJ.sort_index()\n",
        "df_tfidf_h4_NADJ2['term']  = df_tfidf_h4_NADJ2.index\n",
        "df_tfidf_h4_NADJ2.reset_index(drop=True, inplace=True)\n",
        "\n",
        "H4_aft_result = pd.concat([df_frequency2,df_idf2,df_tfidf_h4_NADJ2],axis = 1,ignore_index = True)\n",
        "H4_aft_result2 = H4_aft_result.copy()\n",
        "\n",
        "\n",
        "H4_aft_result2  = H4_aft_result2.rename(columns={0: \"Frequency\",\n",
        "                                 1:\"term\",2:\"IDF\",3:\"term2\",4:\"TF-IDF(Normalized)\",5:\"term3\"})\n",
        "H4_aft_result3 = H4_aft_result2.drop(columns = ['term2','term3'])\n",
        "# relocate columns\n",
        "H4_aft_result4 = H4_aft_result3 [['term', 'Frequency', 'IDF', 'TF-IDF(Normalized)']]\n",
        "#H1_result4 \n",
        "H4_aft_result5 = H4_aft_result4.sort_values('TF-IDF(Normalized)',ascending = False)\n",
        "H4_aft_result5['Rank_TFIDF'] = H4_aft_result5['TF-IDF(Normalized)'].rank(ascending=False,method='max')\n",
        "\n",
        "H4_aft_result5.to_csv('Hotel4_aft_Terms.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ebe17cfe",
      "metadata": {
        "id": "ebe17cfe"
      },
      "outputs": [],
      "source": [
        "# hotel5 pre review pre-processing\n",
        "# These block treat a hotel brand as one document\n",
        "# remove number and punctuation\n",
        "# ref : https://www.geeksforgeeks.org/python-compute-the-frequency-of-words-after-removing-stop-words-and-stemming/?ref=rp\n",
        "\n",
        "hotel5_pre_review_no_punctuations = []\n",
        "\n",
        "\n",
        "for review in H5_pre_review:\n",
        "    hotel5_pre_review_no_punctuations.append( re.sub('[^a-zA-Z ]+', '', str(review)))\n",
        "    \n",
        "    \n",
        "# tokenize\n",
        "#nltk.download('punkt')\n",
        "#from nltk.tokenize import word_tokenize\n",
        "hotel5_review_tokenizing = []\n",
        "for review in hotel5_pre_review_no_punctuations:\n",
        "    hotel5_review_tokenizing.append(word_tokenize(review))\n",
        "\n",
        "# remove stop words\n",
        "#from nltk.corpus import stopwords\n",
        "#nltk.download('stopwords')\n",
        "#nltk_stop_words = stopwords.words('english')\n",
        "\n",
        "hotel5_review_without_stopword = []\n",
        "\n",
        "for review in hotel5_review_tokenizing :\n",
        "    for text in review:\n",
        "        if text.lower() not in nltk_stop_words :\n",
        "            hotel5_review_without_stopword.append(text)\n",
        "        \n",
        "# stemming \n",
        "#from nltk.stem.porter import PorterStemmer\n",
        "#stemmer = PorterStemmer()\n",
        "hotel5_review_after_stemming = []\n",
        "\n",
        "#for review in hotel1_review_without_stopword:\n",
        "#    hotel1_review_after_stemming.append(stemmer.stem(review))\n",
        "\n",
        "# ref:https://www.analyticsvidhya.com/blog/2020/11/text-cleaning-nltk-library/\n",
        "#nltk.download('wordnet')\n",
        "#wn = nltk.WordNetLemmatizer()\n",
        "for review in hotel5_review_without_stopword:\n",
        "    hotel5_review_after_stemming.append(wn.lemmatize(review))\n",
        "\n",
        "\n",
        "    \n",
        "# pos-tagging\n",
        "# ref : https://thinkinfi.com/extract-custom-keywords-using-nltk-pos-tagger-in-python/\n",
        "#from nltk import pos_tag\n",
        "#nltk.download('averaged_perceptron_tagger')\n",
        "hotel5_review_pos_tagging = pos_tag(hotel5_review_after_stemming)\n",
        "hotel5_N = [word for word,pos in hotel5_review_pos_tagging \\\n",
        "            if (pos == 'NN' or pos == 'NNP' or pos == 'NNS' or pos == 'NNPS')]\n",
        "hotel5_adj = [word for word,pos in hotel5_review_pos_tagging \\\n",
        "            if (pos == 'JJ' or pos == 'JJR' or pos == 'JJS' )]\n",
        "hotel5_verb = [word for word,pos in hotel5_review_pos_tagging \\\n",
        "            if (pos == 'VB' or pos == 'VBD' or pos == 'VBG' or pos == 'VBN'or pos == 'VBP'or pos == 'VBZ')]\n",
        "h5_pre_NADJ = [word for word,pos in hotel5_review_pos_tagging \\\n",
        "            if (pos == 'NN' or pos == 'NNP' or pos == 'NNS' or pos == 'NNPS'or pos == 'JJ' or pos == 'JJR' or pos == 'JJS' )]\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "with open('hotel5_pre_all_word2.txt', 'w') as file:\n",
        "    file.writelines(\"%s\\n\" % line for line in hotel5_review_after_stemming)\n",
        "with open('H5_pre_noun2.txt', 'w') as file:\n",
        "    file.writelines(\"%s\\n\" % line for line in hotel5_N )\n",
        "with open('H5_pre_adj2.txt', 'w') as file:\n",
        "    file.writelines(\"%s\\n\" % line for line in hotel5_adj )\n",
        "with open('H5_pre_ver2.txt', 'w') as file:\n",
        "    file.writelines(\"%s\\n\" % line for line in hotel5_verb)\n",
        "with open('H5_pre_NADJ2.txt', 'w') as file:\n",
        "    file.writelines(\"%s\\n\" % line for line in h5_pre_NADJ)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f112ade4",
      "metadata": {
        "id": "f112ade4",
        "outputId": "ee4ad73a-41f5-4f98-c1cf-5b8bb9439306"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[2 1 1 ... 3 1 5]]\n"
          ]
        }
      ],
      "source": [
        "# Hotel 5 pre : TFIDF\n",
        "# turn after prepocessing word into a sentence again\n",
        "H5_pre_NADJ = [' '.join([str(c) for c in h5_pre_NADJ])]\n",
        "\n",
        "#from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "cv= CountVectorizer(analyzer = \"word\",stop_words = ['time','hotel','square','squar','york'],lowercase=True)\n",
        "# convert the documents into a document-term matrix\n",
        "TermFreq_Matrix = cv.fit_transform(H5_pre_NADJ)\n",
        "print(TermFreq_Matrix.todense())\n",
        "\n",
        "#shape of count vector: 2 docs and 11 unique words (columns)!\n",
        "#print(TermFreq_Matrix.shape)\n",
        "# (2, 11)\n",
        "\n",
        "tokens = cv.get_feature_names()\n",
        "# print(tokens)\n",
        "\n",
        "# ['also', 'football', 'game', 'john', 'likes', 'mary', 'match', 'movies', 'to', 'too', 'watch']\n",
        "\n",
        "# create an index for each row\n",
        "doc_names = ['Doc{:d}'.format(idx) for idx, _ in enumerate(TermFreq_Matrix)]\n",
        "df_frequency = pd.DataFrame(data=TermFreq_Matrix.toarray(), index=doc_names,\n",
        "                  columns=tokens)\n",
        "#print(df)\n",
        "\n",
        "\n",
        "# TF-IDF\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True)\n",
        "tfidf_transformer.fit(TermFreq_Matrix)\n",
        "\n",
        "#TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)\n",
        "\n",
        "# print idf values\n",
        "df_idf_pre = pd.DataFrame(tfidf_transformer.idf_, index=tokens,columns=[\"idf_weights\"])\n",
        "\n",
        "#df_idf\n",
        " \n",
        "# tf-idf scores\n",
        "tf_idf_vector=tfidf_transformer.transform(TermFreq_Matrix)\n",
        " \n",
        "#get tfidf vector for first document\n",
        "first_document_vector=tf_idf_vector[0]\n",
        " \n",
        "#print the scores\n",
        "df_tfidf_h5_NADJ = pd.DataFrame(first_document_vector.T.todense(), index=tokens, columns=[\"tf-idf\"])\n",
        "df_tfidf_h5_NADJ = df_tfidf_h5_NADJ.sort_values(by=[\"tf-idf\"],ascending=False)\n",
        "\n",
        "# dataframe clean\n",
        "df_frequency2 = df_frequency.transpose()\n",
        "df_frequency2['term'] = df_frequency2.index\n",
        "df_frequency2.reset_index(drop=True, inplace=True)\n",
        "df_idf2 = df_idf_pre.copy()\n",
        "df_idf2['term'] = df_idf_pre.index\n",
        "df_idf2.reset_index(drop=True, inplace=True)\n",
        "df_tfidf_h5_NADJ2=df_tfidf_h5_NADJ.sort_index()\n",
        "#df_tfidf_h1_NADJ2 = df_tfidf_h1_NADJ2.sort_index()\n",
        "df_tfidf_h5_NADJ2['term']  = df_tfidf_h5_NADJ2.index\n",
        "df_tfidf_h5_NADJ2.reset_index(drop=True, inplace=True)\n",
        "\n",
        "H5_pre_result = pd.concat([df_frequency2,df_idf2,df_tfidf_h5_NADJ2],axis = 1,ignore_index = True)\n",
        "H5_pre_result2 = H5_pre_result.copy()\n",
        "\n",
        "\n",
        "H5_pre_result2  = H5_pre_result2.rename(columns={0: \"Frequency\",\n",
        "                                 1:\"term\",2:\"IDF\",3:\"term2\",4:\"TF-IDF(Normalized)\",5:\"term3\"})\n",
        "H5_pre_result3 = H5_pre_result2.drop(columns = ['term2','term3'])\n",
        "# relocate columns\n",
        "H5_pre_result4 = H5_pre_result3 [['term', 'Frequency', 'IDF', 'TF-IDF(Normalized)']]\n",
        "#H1_result4 \n",
        "H5_pre_result5 = H5_pre_result4.sort_values('TF-IDF(Normalized)',ascending = False)\n",
        "H5_pre_result5['Rank_TFIDF'] = H5_pre_result5['TF-IDF(Normalized)'].rank(ascending=False,method='max')\n",
        "\n",
        "H5_pre_result5.to_csv('Hotel5_pre_Terms.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b28171db",
      "metadata": {
        "id": "b28171db"
      },
      "outputs": [],
      "source": [
        "# hotel5 aft review pre-processing\n",
        "# These block treat a hotel brand as one document\n",
        "# remove number and punctuation\n",
        "# ref : https://www.geeksforgeeks.org/python-compute-the-frequency-of-words-after-removing-stop-words-and-stemming/?ref=rp\n",
        "\n",
        "hotel5_aft_review_no_punctuations = []\n",
        "\n",
        "\n",
        "for review in H5_aft_review:\n",
        "    hotel5_aft_review_no_punctuations.append( re.sub('[^a-zA-Z ]+', '', str(review)))\n",
        "    \n",
        "    \n",
        "# tokenize\n",
        "#nltk.download('punkt')\n",
        "#from nltk.tokenize import word_tokenize\n",
        "hotel5_review_aft_tokenizing = []\n",
        "for review in hotel5_aft_review_no_punctuations:\n",
        "    hotel5_review_aft_tokenizing.append(word_tokenize(review))\n",
        "\n",
        "# remove stop words\n",
        "#from nltk.corpus import stopwords\n",
        "#nltk.download('stopwords')\n",
        "#nltk_stop_words = stopwords.words('english')\n",
        "\n",
        "hotel5_review_aft_without_stopword = []\n",
        "\n",
        "for review in hotel5_review_aft_tokenizing :\n",
        "    for text in review:\n",
        "        if text.lower() not in nltk_stop_words :\n",
        "            hotel5_review_aft_without_stopword.append(text)\n",
        "        \n",
        "# stemming \n",
        "#from nltk.stem.porter import PorterStemmer\n",
        "#stemmer = PorterStemmer()\n",
        "hotel5_review_aft_after_stemming = []\n",
        "\n",
        "#for review in hotel1_review_without_stopword:\n",
        "#    hotel1_review_after_stemming.append(stemmer.stem(review))\n",
        "\n",
        "# ref:https://www.analyticsvidhya.com/blog/2020/11/text-cleaning-nltk-library/\n",
        "#nltk.download('wordnet')\n",
        "#wn = nltk.WordNetLemmatizer()\n",
        "for review in hotel5_review_aft_without_stopword:\n",
        "    hotel5_review_aft_after_stemming.append(wn.lemmatize(review))\n",
        "\n",
        "\n",
        "    \n",
        "# pos-tagging\n",
        "# ref : https://thinkinfi.com/extract-custom-keywords-using-nltk-pos-tagger-in-python/\n",
        "#from nltk import pos_tag\n",
        "#nltk.download('averaged_perceptron_tagger')\n",
        "hotel5_review_aft_pos_tagging = pos_tag(hotel5_review_aft_after_stemming)\n",
        "hotel5_N_aft = [word for word,pos in hotel5_review_aft_pos_tagging \\\n",
        "            if (pos == 'NN' or pos == 'NNP' or pos == 'NNS' or pos == 'NNPS')]\n",
        "hotel5_adj_aft = [word for word,pos in hotel5_review_aft_pos_tagging \\\n",
        "            if (pos == 'JJ' or pos == 'JJR' or pos == 'JJS' )]\n",
        "hotel5_verb_aft = [word for word,pos in hotel5_review_aft_pos_tagging \\\n",
        "            if (pos == 'VB' or pos == 'VBD' or pos == 'VBG' or pos == 'VBN'or pos == 'VBP'or pos == 'VBZ')]\n",
        "h5_aft_NADJ = [word for word,pos in hotel5_review_aft_pos_tagging \\\n",
        "            if (pos == 'NN' or pos == 'NNP' or pos == 'NNS' or pos == 'NNPS'or pos == 'JJ' or pos == 'JJR' or pos == 'JJS' )]\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "with open('hotel5_aft_all_word2.txt', 'w') as file:\n",
        "    file.writelines(\"%s\\n\" % line for line in hotel5_review_aft_after_stemming)\n",
        "with open('H5_aft_noun2.txt', 'w') as file:\n",
        "    file.writelines(\"%s\\n\" % line for line in hotel5_N_aft )\n",
        "with open('H5_aft_adj2.txt', 'w') as file:\n",
        "    file.writelines(\"%s\\n\" % line for line in hotel5_adj_aft )\n",
        "with open('H5_aft_ver2.txt', 'w') as file:\n",
        "    file.writelines(\"%s\\n\" % line for line in hotel5_verb_aft)\n",
        "with open('H5_aft_NADJ2.txt', 'w') as file:\n",
        "    file.writelines(\"%s\\n\" % line for line in h5_aft_NADJ)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3528aea5",
      "metadata": {
        "id": "3528aea5",
        "outputId": "7c56ee30-4e4c-4cb2-fc5c-011d70be3e53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[7 1 3 ... 4 1 1]]\n"
          ]
        }
      ],
      "source": [
        "# Hotel 5 aft : TFIDF\n",
        "# turn after prepocessing word into a sentence again\n",
        "H5_aft_NADJ = [' '.join([str(c) for c in h5_aft_NADJ])]\n",
        "\n",
        "#from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "cv= CountVectorizer(analyzer = \"word\",stop_words =['time','hotel','square','squar','york'],lowercase=True)\n",
        "# convert the documents into a document-term matrix\n",
        "TermFreq_Matrix = cv.fit_transform(H5_aft_NADJ)\n",
        "print(TermFreq_Matrix.todense())\n",
        "\n",
        "#shape of count vector: 2 docs and 11 unique words (columns)!\n",
        "#print(TermFreq_Matrix.shape)\n",
        "# (2, 11)\n",
        "\n",
        "tokens = cv.get_feature_names()\n",
        "# print(tokens)\n",
        "\n",
        "# ['also', 'football', 'game', 'john', 'likes', 'mary', 'match', 'movies', 'to', 'too', 'watch']\n",
        "\n",
        "# create an index for each row\n",
        "doc_names = ['Doc{:d}'.format(idx) for idx, _ in enumerate(TermFreq_Matrix)]\n",
        "df_frequency = pd.DataFrame(data=TermFreq_Matrix.toarray(), index=doc_names,\n",
        "                  columns=tokens)\n",
        "#print(df)\n",
        "\n",
        "\n",
        "# TF-IDF\n",
        "#from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True)\n",
        "tfidf_transformer.fit(TermFreq_Matrix)\n",
        "\n",
        "#TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)\n",
        "\n",
        "# print idf values\n",
        "df_idf_aft= pd.DataFrame(tfidf_transformer.idf_, index=tokens,columns=[\"idf_weights\"])\n",
        "\n",
        "#df_idf\n",
        " \n",
        "# tf-idf scores\n",
        "tf_idf_vector=tfidf_transformer.transform(TermFreq_Matrix)\n",
        " \n",
        "#get tfidf vector for first document\n",
        "first_document_vector=tf_idf_vector[0]\n",
        " \n",
        "#print the scores\n",
        "df_tfidf_h5_NADJ = pd.DataFrame(first_document_vector.T.todense(), index=tokens, columns=[\"tf-idf\"])\n",
        "df_tfidf_h5_NADJ = df_tfidf_h5_NADJ.sort_values(by=[\"tf-idf\"],ascending=False)\n",
        "\n",
        "# dataframe clean\n",
        "df_frequency2 = df_frequency.transpose()\n",
        "df_frequency2['term'] = df_frequency2.index\n",
        "df_frequency2.reset_index(drop=True, inplace=True)\n",
        "df_idf2 = df_idf_aft.copy()\n",
        "df_idf2['term'] = df_idf_aft.index\n",
        "df_idf2.reset_index(drop=True, inplace=True)\n",
        "df_tfidf_h5_NADJ2=df_tfidf_h5_NADJ.sort_index()\n",
        "df_tfidf_h5_NADJ2['term']  = df_tfidf_h5_NADJ2.index\n",
        "df_tfidf_h5_NADJ2.reset_index(drop=True, inplace=True)\n",
        "\n",
        "H5_aft_result = pd.concat([df_frequency2,df_idf2,df_tfidf_h5_NADJ2],axis = 1,ignore_index = True)\n",
        "H5_aft_result2 = H5_aft_result.copy()\n",
        "\n",
        "\n",
        "H5_aft_result2  = H5_aft_result2.rename(columns={0: \"Frequency\",\n",
        "                                 1:\"term\",2:\"IDF\",3:\"term2\",4:\"TF-IDF(Normalized)\",5:\"term3\"})\n",
        "H5_aft_result3 = H5_aft_result2.drop(columns = ['term2','term3'])\n",
        "# relocate columns\n",
        "H5_aft_result4 = H5_aft_result3 [['term', 'Frequency', 'IDF', 'TF-IDF(Normalized)']]\n",
        "#H1_result4 \n",
        "H5_aft_result5 = H5_aft_result4.sort_values('TF-IDF(Normalized)',ascending = False)\n",
        "H5_aft_result5['Rank_TFIDF'] = H5_aft_result5['TF-IDF(Normalized)'].rank(ascending=False,method='max')\n",
        "\n",
        "H5_aft_result5.to_csv('Hotel5_aft_Terms.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9659589",
      "metadata": {
        "id": "c9659589"
      },
      "outputs": [],
      "source": [
        "# hotel6 pre review pre-processing\n",
        "# These block treat a hotel brand as one document\n",
        "# remove number and punctuation\n",
        "# ref : https://www.geeksforgeeks.org/python-compute-the-frequency-of-words-after-removing-stop-words-and-stemming/?ref=rp\n",
        "\n",
        "hotel6_pre_review_no_punctuations = []\n",
        "\n",
        "\n",
        "for review in H6_pre_review:\n",
        "    hotel6_pre_review_no_punctuations.append( re.sub('[^a-zA-Z ]+', '', str(review)))\n",
        "    \n",
        "    \n",
        "# tokenize\n",
        "#nltk.download('punkt')\n",
        "#from nltk.tokenize import word_tokenize\n",
        "hotel6_review_tokenizing = []\n",
        "for review in hotel6_pre_review_no_punctuations:\n",
        "    hotel6_review_tokenizing.append(word_tokenize(review))\n",
        "\n",
        "# remove stop words\n",
        "#from nltk.corpus import stopwords\n",
        "#nltk.download('stopwords')\n",
        "#nltk_stop_words = stopwords.words('english')\n",
        "\n",
        "hotel6_review_without_stopword = []\n",
        "\n",
        "for review in hotel6_review_tokenizing :\n",
        "    for text in review:\n",
        "        if text.lower() not in nltk_stop_words :\n",
        "            hotel6_review_without_stopword.append(text)\n",
        "        \n",
        "# stemming \n",
        "#from nltk.stem.porter import PorterStemmer\n",
        "#stemmer = PorterStemmer()\n",
        "hotel6_review_after_stemming = []\n",
        "\n",
        "#for review in hotel1_review_without_stopword:\n",
        "#    hotel1_review_after_stemming.append(stemmer.stem(review))\n",
        "\n",
        "# ref:https://www.analyticsvidhya.com/blog/2020/11/text-cleaning-nltk-library/\n",
        "#nltk.download('wordnet')\n",
        "#wn = nltk.WordNetLemmatizer()\n",
        "for review in hotel6_review_without_stopword:\n",
        "    hotel6_review_after_stemming.append(wn.lemmatize(review))\n",
        "\n",
        "\n",
        "    \n",
        "# pos-tagging\n",
        "# ref : https://thinkinfi.com/extract-custom-keywords-using-nltk-pos-tagger-in-python/\n",
        "#from nltk import pos_tag\n",
        "#nltk.download('averaged_perceptron_tagger')\n",
        "hotel6_review_pos_tagging = pos_tag(hotel6_review_after_stemming)\n",
        "hotel6_N = [word for word,pos in hotel6_review_pos_tagging \\\n",
        "            if (pos == 'NN' or pos == 'NNP' or pos == 'NNS' or pos == 'NNPS')]\n",
        "hotel6_adj = [word for word,pos in hotel6_review_pos_tagging \\\n",
        "            if (pos == 'JJ' or pos == 'JJR' or pos == 'JJS' )]\n",
        "hotel6_verb = [word for word,pos in hotel6_review_pos_tagging \\\n",
        "            if (pos == 'VB' or pos == 'VBD' or pos == 'VBG' or pos == 'VBN'or pos == 'VBP'or pos == 'VBZ')]\n",
        "h6_pre_NADJ = [word for word,pos in hotel6_review_pos_tagging \\\n",
        "            if (pos == 'NN' or pos == 'NNP' or pos == 'NNS' or pos == 'NNPS'or pos == 'JJ' or pos == 'JJR' or pos == 'JJS' )]\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "with open('hotel6_pre_all_word2.txt', 'w') as file:\n",
        "    file.writelines(\"%s\\n\" % line for line in hotel6_review_after_stemming)\n",
        "with open('H6_pre_noun2.txt', 'w') as file:\n",
        "    file.writelines(\"%s\\n\" % line for line in hotel6_N )\n",
        "with open('H6_pre_adj2.txt', 'w') as file:\n",
        "    file.writelines(\"%s\\n\" % line for line in hotel6_adj )\n",
        "with open('H6_pre_ver2.txt', 'w') as file:\n",
        "    file.writelines(\"%s\\n\" % line for line in hotel6_verb)\n",
        "with open('H6_pre_NADJ2.txt', 'w') as file:\n",
        "    file.writelines(\"%s\\n\" % line for line in h6_pre_NADJ)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da013ef0",
      "metadata": {
        "id": "da013ef0",
        "outputId": "eb625483-4a4f-429f-def7-db23c3f8dfa0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[5 1 1 ... 1 1 1]]\n"
          ]
        }
      ],
      "source": [
        "# Hotel 6 pre : TFIDF\n",
        "# turn after prepocessing word into a sentence again\n",
        "H6_pre_NADJ = [' '.join([str(c) for c in h6_pre_NADJ])]\n",
        "\n",
        "#from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "cv= CountVectorizer(analyzer = \"word\",stop_words = ['time','hotel','square','squar','york'],lowercase=True)\n",
        "# convert the documents into a document-term matrix\n",
        "TermFreq_Matrix = cv.fit_transform(H6_pre_NADJ)\n",
        "print(TermFreq_Matrix.todense())\n",
        "\n",
        "#shape of count vector: 2 docs and 11 unique words (columns)!\n",
        "#print(TermFreq_Matrix.shape)\n",
        "# (2, 11)\n",
        "\n",
        "tokens = cv.get_feature_names()\n",
        "# print(tokens)\n",
        "\n",
        "# ['also', 'football', 'game', 'john', 'likes', 'mary', 'match', 'movies', 'to', 'too', 'watch']\n",
        "\n",
        "# create an index for each row\n",
        "doc_names = ['Doc{:d}'.format(idx) for idx, _ in enumerate(TermFreq_Matrix)]\n",
        "df_frequency = pd.DataFrame(data=TermFreq_Matrix.toarray(), index=doc_names,\n",
        "                  columns=tokens)\n",
        "#print(df)\n",
        "\n",
        "\n",
        "# TF-IDF\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True)\n",
        "tfidf_transformer.fit(TermFreq_Matrix)\n",
        "\n",
        "#TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)\n",
        "\n",
        "# print idf values\n",
        "df_idf_pre = pd.DataFrame(tfidf_transformer.idf_, index=tokens,columns=[\"idf_weights\"])\n",
        "\n",
        "#df_idf\n",
        " \n",
        "# tf-idf scores\n",
        "tf_idf_vector=tfidf_transformer.transform(TermFreq_Matrix)\n",
        " \n",
        "#get tfidf vector for first document\n",
        "first_document_vector=tf_idf_vector[0]\n",
        " \n",
        "#print the scores\n",
        "df_tfidf_h6_NADJ = pd.DataFrame(first_document_vector.T.todense(), index=tokens, columns=[\"tf-idf\"])\n",
        "df_tfidf_h6_NADJ = df_tfidf_h6_NADJ.sort_values(by=[\"tf-idf\"],ascending=False)\n",
        "\n",
        "# dataframe clean\n",
        "df_frequency2 = df_frequency.transpose()\n",
        "df_frequency2['term'] = df_frequency2.index\n",
        "df_frequency2.reset_index(drop=True, inplace=True)\n",
        "df_idf2 = df_idf_pre.copy()\n",
        "df_idf2['term'] = df_idf_pre.index\n",
        "df_idf2.reset_index(drop=True, inplace=True)\n",
        "df_tfidf_h6_NADJ2=df_tfidf_h6_NADJ.sort_index()\n",
        "#df_tfidf_h1_NADJ2 = df_tfidf_h1_NADJ2.sort_index()\n",
        "df_tfidf_h6_NADJ2['term']  = df_tfidf_h6_NADJ2.index\n",
        "df_tfidf_h6_NADJ2.reset_index(drop=True, inplace=True)\n",
        "\n",
        "H6_pre_result = pd.concat([df_frequency2,df_idf2,df_tfidf_h6_NADJ2],axis = 1,ignore_index = True)\n",
        "H6_pre_result2 = H6_pre_result.copy()\n",
        "\n",
        "\n",
        "H6_pre_result2  = H6_pre_result2.rename(columns={0: \"Frequency\",\n",
        "                                 1:\"term\",2:\"IDF\",3:\"term2\",4:\"TF-IDF(Normalized)\",5:\"term3\"})\n",
        "H6_pre_result3 = H6_pre_result2.drop(columns = ['term2','term3'])\n",
        "# relocate columns\n",
        "H6_pre_result4 = H6_pre_result3 [['term', 'Frequency', 'IDF', 'TF-IDF(Normalized)']]\n",
        "#H1_result4 \n",
        "H6_pre_result5 = H6_pre_result4.sort_values('TF-IDF(Normalized)',ascending = False)\n",
        "H6_pre_result5['Rank_TFIDF'] = H6_pre_result5['TF-IDF(Normalized)'].rank(ascending=False,method='max')\n",
        "\n",
        "H6_pre_result5.to_csv('Hotel6_pre_Terms.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2c3a80a",
      "metadata": {
        "id": "e2c3a80a"
      },
      "outputs": [],
      "source": [
        "# hotel6 aft review pre-processing\n",
        "# These block treat a hotel brand as one document\n",
        "# remove number and punctuation\n",
        "# ref : https://www.geeksforgeeks.org/python-compute-the-frequency-of-words-after-removing-stop-words-and-stemming/?ref=rp\n",
        "\n",
        "hotel6_aft_review_no_punctuations = []\n",
        "\n",
        "\n",
        "for review in H6_aft_review:\n",
        "    hotel6_aft_review_no_punctuations.append( re.sub('[^a-zA-Z ]+', '', str(review)))\n",
        "    \n",
        "    \n",
        "# tokenize\n",
        "#nltk.download('punkt')\n",
        "#from nltk.tokenize import word_tokenize\n",
        "hotel6_review_aft_tokenizing = []\n",
        "for review in hotel6_aft_review_no_punctuations:\n",
        "    hotel6_review_aft_tokenizing.append(word_tokenize(review))\n",
        "\n",
        "# remove stop words\n",
        "#from nltk.corpus import stopwords\n",
        "#nltk.download('stopwords')\n",
        "#nltk_stop_words = stopwords.words('english')\n",
        "\n",
        "hotel6_review_aft_without_stopword = []\n",
        "\n",
        "for review in hotel6_review_aft_tokenizing :\n",
        "    for text in review:\n",
        "        if text.lower() not in nltk_stop_words :\n",
        "            hotel6_review_aft_without_stopword.append(text)\n",
        "        \n",
        "# stemming \n",
        "#from nltk.stem.porter import PorterStemmer\n",
        "#stemmer = PorterStemmer()\n",
        "hotel6_review_aft_after_stemming = []\n",
        "\n",
        "#for review in hotel1_review_without_stopword:\n",
        "#    hotel1_review_after_stemming.append(stemmer.stem(review))\n",
        "\n",
        "# ref:https://www.analyticsvidhya.com/blog/2020/11/text-cleaning-nltk-library/\n",
        "#nltk.download('wordnet')\n",
        "#wn = nltk.WordNetLemmatizer()\n",
        "for review in hotel6_review_aft_without_stopword:\n",
        "    hotel6_review_aft_after_stemming.append(wn.lemmatize(review))\n",
        "\n",
        "\n",
        "    \n",
        "# pos-tagging\n",
        "# ref : https://thinkinfi.com/extract-custom-keywords-using-nltk-pos-tagger-in-python/\n",
        "#from nltk import pos_tag\n",
        "#nltk.download('averaged_perceptron_tagger')\n",
        "hotel6_review_aft_pos_tagging = pos_tag(hotel6_review_aft_after_stemming)\n",
        "hotel6_N_aft = [word for word,pos in hotel6_review_aft_pos_tagging \\\n",
        "            if (pos == 'NN' or pos == 'NNP' or pos == 'NNS' or pos == 'NNPS')]\n",
        "hotel6_adj_aft = [word for word,pos in hotel6_review_aft_pos_tagging \\\n",
        "            if (pos == 'JJ' or pos == 'JJR' or pos == 'JJS' )]\n",
        "hotel6_verb_aft = [word for word,pos in hotel6_review_aft_pos_tagging \\\n",
        "            if (pos == 'VB' or pos == 'VBD' or pos == 'VBG' or pos == 'VBN'or pos == 'VBP'or pos == 'VBZ')]\n",
        "h6_aft_NADJ = [word for word,pos in hotel6_review_aft_pos_tagging \\\n",
        "            if (pos == 'NN' or pos == 'NNP' or pos == 'NNS' or pos == 'NNPS'or pos == 'JJ' or pos == 'JJR' or pos == 'JJS' )]\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "with open('hotel6_aft_all_word2.txt', 'w') as file:\n",
        "    file.writelines(\"%s\\n\" % line for line in hotel6_review_aft_after_stemming)\n",
        "with open('H6_aft_noun2.txt', 'w') as file:\n",
        "    file.writelines(\"%s\\n\" % line for line in hotel6_N_aft )\n",
        "with open('H6_aft_adj2.txt', 'w') as file:\n",
        "    file.writelines(\"%s\\n\" % line for line in hotel6_adj_aft )\n",
        "with open('H6_aft_ver2.txt', 'w') as file:\n",
        "    file.writelines(\"%s\\n\" % line for line in hotel6_verb_aft)\n",
        "with open('H6_aft_NADJ2.txt', 'w') as file:\n",
        "    file.writelines(\"%s\\n\" % line for line in h6_aft_NADJ)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30deb62b",
      "metadata": {
        "id": "30deb62b",
        "outputId": "f0de24d4-c0f4-4c72-d24e-864da356d511"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>aaa</th>\n",
              "      <th>aand</th>\n",
              "      <th>aarp</th>\n",
              "      <th>abd</th>\n",
              "      <th>abe</th>\n",
              "      <th>aberration</th>\n",
              "      <th>ability</th>\n",
              "      <th>able</th>\n",
              "      <th>aboard</th>\n",
              "      <th>abode</th>\n",
              "      <th>...</th>\n",
              "      <th>yum</th>\n",
              "      <th>yummy</th>\n",
              "      <th>yup</th>\n",
              "      <th>zero</th>\n",
              "      <th>ziegfeld</th>\n",
              "      <th>zip</th>\n",
              "      <th>zipped</th>\n",
              "      <th>zoo</th>\n",
              "      <th>zuckers</th>\n",
              "      <th>zzzzz</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Doc0</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>77</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1 rows × 6706 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      aaa  aand  aarp  abd  abe  aberration  ability  able  aboard  abode  \\\n",
              "Doc0    5     1     1    1    1           1        1    77       1      1   \n",
              "\n",
              "      ...  yum  yummy  yup  zero  ziegfeld  zip  zipped  zoo  zuckers  zzzzz  \n",
              "Doc0  ...    1      4    1     2         1    1       1    1        1      1  \n",
              "\n",
              "[1 rows x 6706 columns]"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_frequency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "baf4ebb5",
      "metadata": {
        "id": "baf4ebb5",
        "outputId": "f93a5115-441a-48ff-c5a3-02b481b46a76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1 1 8 ... 1 1 1]]\n"
          ]
        }
      ],
      "source": [
        "# Hotel 6 aft : TFIDF\n",
        "# turn after prepocessing word into a sentence again\n",
        "H6_aft_NADJ = [' '.join([str(c) for c in h6_aft_NADJ])]\n",
        "\n",
        "#from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "cv= CountVectorizer(analyzer = \"word\",stop_words =['time','hotel','square','squar','york'],lowercase=True)\n",
        "# convert the documents into a document-term matrix\n",
        "TermFreq_Matrix = cv.fit_transform(H6_aft_NADJ)\n",
        "print(TermFreq_Matrix.todense())\n",
        "\n",
        "#shape of count vector: 2 docs and 11 unique words (columns)!\n",
        "#print(TermFreq_Matrix.shape)\n",
        "# (2, 11)\n",
        "\n",
        "tokens = cv.get_feature_names()\n",
        "# print(tokens)\n",
        "\n",
        "# ['also', 'football', 'game', 'john', 'likes', 'mary', 'match', 'movies', 'to', 'too', 'watch']\n",
        "\n",
        "# create an index for each row\n",
        "doc_names = ['Doc{:d}'.format(idx) for idx, _ in enumerate(TermFreq_Matrix)]\n",
        "df_frequency = pd.DataFrame(data=TermFreq_Matrix.toarray(), index=doc_names,\n",
        "                  columns=tokens)\n",
        "#print(df)\n",
        "\n",
        "\n",
        "# TF-IDF\n",
        "#from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True)\n",
        "tfidf_transformer.fit(TermFreq_Matrix)\n",
        "\n",
        "#TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)\n",
        "\n",
        "# print idf values\n",
        "df_idf_aft= pd.DataFrame(tfidf_transformer.idf_, index=tokens,columns=[\"idf_weights\"])\n",
        "\n",
        "#df_idf\n",
        " \n",
        "# tf-idf scores\n",
        "tf_idf_vector=tfidf_transformer.transform(TermFreq_Matrix)\n",
        " \n",
        "#get tfidf vector for first document\n",
        "first_document_vector=tf_idf_vector[0]\n",
        " \n",
        "#print the scores\n",
        "df_tfidf_h6_NADJ = pd.DataFrame(first_document_vector.T.todense(), index=tokens, columns=[\"tf-idf\"])\n",
        "df_tfidf_h6_NADJ = df_tfidf_h6_NADJ.sort_values(by=[\"tf-idf\"],ascending=False)\n",
        "\n",
        "# dataframe clean\n",
        "df_frequency2 = df_frequency.transpose()\n",
        "df_frequency2['term'] = df_frequency2.index\n",
        "df_frequency2.reset_index(drop=True, inplace=True)\n",
        "df_idf2 = df_idf_aft.copy()\n",
        "df_idf2['term'] = df_idf_aft.index\n",
        "df_idf2.reset_index(drop=True, inplace=True)\n",
        "df_tfidf_h6_NADJ2=df_tfidf_h6_NADJ.sort_index()\n",
        "df_tfidf_h6_NADJ2['term']  = df_tfidf_h6_NADJ2.index\n",
        "df_tfidf_h6_NADJ2.reset_index(drop=True, inplace=True)\n",
        "\n",
        "H6_aft_result = pd.concat([df_frequency2,df_idf2,df_tfidf_h6_NADJ2],axis = 1,ignore_index = True)\n",
        "H6_aft_result2 = H5_aft_result.copy()\n",
        "\n",
        "\n",
        "H6_aft_result2  = H6_aft_result2.rename(columns={0: \"Frequency\",\n",
        "                                 1:\"term\",2:\"IDF\",3:\"term2\",4:\"TF-IDF(Normalized)\",5:\"term3\"})\n",
        "H6_aft_result3 = H6_aft_result2.drop(columns = ['term2','term3'])\n",
        "# relocate columns\n",
        "H6_aft_result4 = H6_aft_result3 [['term', 'Frequency', 'IDF', 'TF-IDF(Normalized)']]\n",
        "#H1_result4 \n",
        "H6_aft_result5 = H6_aft_result4.sort_values('TF-IDF(Normalized)',ascending = False)\n",
        "H6_aft_result5['Rank_TFIDF'] = H6_aft_result5['TF-IDF(Normalized)'].rank(ascending=False,method='max')\n",
        "\n",
        "H6_aft_result5.to_csv('Hotel6_aft_Terms.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89946fc9",
      "metadata": {
        "id": "89946fc9",
        "outputId": "d9e8c4de-b434-45ad-a789-37e2d7ae10ef"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<1x1654 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 1654 stored elements in Compressed Sparse Row format>"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "TermFreq_Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "efc73a8e",
      "metadata": {
        "id": "efc73a8e",
        "outputId": "fd0b96c6-0b62-4289-d950-b1b4e075edec"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>term</th>\n",
              "      <th>Frequency</th>\n",
              "      <th>IDF</th>\n",
              "      <th>TF-IDF(Normalized)</th>\n",
              "      <th>Rank_TFIDF</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1202</th>\n",
              "      <td>room</td>\n",
              "      <td>240</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.494933</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>840</th>\n",
              "      <td>location</td>\n",
              "      <td>134</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.276337</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>266</th>\n",
              "      <td>clean</td>\n",
              "      <td>90</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.185600</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1243</th>\n",
              "      <td>service</td>\n",
              "      <td>37</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.076302</td>\n",
              "      <td>23.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>464</th>\n",
              "      <td>elevator</td>\n",
              "      <td>32</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.065991</td>\n",
              "      <td>26.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          term  Frequency  IDF  TF-IDF(Normalized)  Rank_TFIDF\n",
              "1202      room        240  1.0            0.494933         1.0\n",
              "840   location        134  1.0            0.276337         4.0\n",
              "266      clean         90  1.0            0.185600         6.0\n",
              "1243   service         37  1.0            0.076302        23.0\n",
              "464   elevator         32  1.0            0.065991        26.0"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "H6_text = H6_aft_result5.loc[(H6_aft_result5['term'] =='room')|\n",
        "                   (H6_aft_result5['term'] =='elevator')|(\n",
        "                       H6_aft_result5['term'] =='location')|\n",
        "                   (H6_aft_result5['term'] =='clean')|(H6_aft_result5['term'] =='service')] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d136f045",
      "metadata": {
        "id": "d136f045"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55a9b9c8",
      "metadata": {
        "id": "55a9b9c8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39d63848",
      "metadata": {
        "id": "39d63848"
      },
      "outputs": [],
      "source": [
        "# PCA\n",
        "# Import TfidfVectorizer\n",
        "#from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Create a TfidfVectorizer: tfidf\n",
        "tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True)\n",
        "csr_mat= tfidf_transformer.fit_transform(TermFreq_Matrix)\n",
        "\n",
        "# to get the words:\n",
        "cv= CountVectorizer(analyzer = \"word\",stop_words =['time','hotel','square','squar','york'],lowercase=True)\n",
        "# convert the documents into a document-term matrix\n",
        "TermFreq_Matrix = cv.fit_transform(H6_aft_NADJ)\n",
        "\n",
        "#shape of count vector: 2 docs and 11 unique words (columns)!\n",
        "#print(TermFreq_Matrix.shape)\n",
        "\n",
        "\n",
        "# Get the words: words\n",
        "words = cv.get_feature_names()\n",
        "\n",
        "# Print words\n",
        "\n",
        "#print(words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d756704b",
      "metadata": {
        "id": "d756704b",
        "outputId": "eecaa927-a3fe-4432-f7d8-c362deef017b"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'pipeline' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-53dd5127b9ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Fit the pipeline to articles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsr_mat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Calculate the cluster labels: labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pipeline' is not defined"
          ]
        }
      ],
      "source": [
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# Create a pipeline: pipeline\n",
        "pipeline = make_pipeline(svd, kmeans)\n",
        "\n",
        "# Fit the pipeline to articles\n",
        "pipeline.fit(csr_mat)\n",
        "\n",
        "# Calculate the cluster labels: labels\n",
        "labels = pipeline.predict(csr_mat)\n",
        "\n",
        "# Create a DataFrame aligning labels and titles: df\n",
        "df = pd.DataFrame({'label': labels, 'article': range(1,616)})\n",
        "\n",
        "# Display df sorted by cluster label\n",
        "print(df.sort_values('label').head())\n",
        "df['label'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68648547",
      "metadata": {
        "id": "68648547"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ce4ed0f",
      "metadata": {
        "id": "2ce4ed0f"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}